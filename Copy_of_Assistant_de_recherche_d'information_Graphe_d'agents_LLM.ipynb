{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jitaross/tp_colabFct/blob/main/Copy_of_Assistant_de_recherche_d'information_Graphe_d'agents_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e0a5763f-5f45-4b8f-b3e2-480f46c5721b",
      "metadata": {
        "id": "e0a5763f-5f45-4b8f-b3e2-480f46c5721b"
      },
      "source": [
        "# Objectif: créer un assistant de recherche\n",
        "# NOTE:\n",
        "- 40% Task 1 à 5 (+ phase implémentation XP de Task 6) - Collaboration classe acceptée\n",
        "- 20% XP individuelle\n",
        "- 40% XP équipe\n",
        "\n",
        "Nous allons aborder quelques grands thèmes de LangGraph :  \n",
        "\n",
        "- **Collaboration d'agents**  \n",
        "- **Mémoire**  \n",
        "- **Humain dans la boucle (HITL: Human-in-the-loop)**  \n",
        "- **Contrôlabilité**  \n",
        "\n",
        "Nous visons une application populaires et ambitieuse de l'IA : l'automatisation de la recherche.\n",
        "\n",
        "Testez et analysez d'abord ce graph d'agents LLM, puis réaliser les différentes évolutions du TODO en bas du notebook.\n",
        "\n",
        "La recherche est souvent un travail laborieux confié à des analystes. L'IA a un potentiel considérable pour aider dans ce domaine.  \n",
        "\n",
        "Cependant, la recherche nécessite une personnalisation : les résultats bruts des modèles LLM sont souvent mal adaptés aux flux de travail réels de prise de décision.  \n",
        "\n",
        "Des flux de travail personnalisés, basés sur l'IA, pour la recherche et la génération de rapports sont une solution prometteuse à ce problème.  \n",
        "\n",
        "### Objectif  \n",
        "Notre objectif est de construire un système léger, multi-agent, basé sur des modèles de chat qui personnalise le processus de recherche.  \n",
        "\n",
        "### Sélection des sources  \n",
        "- Les utilisateurs peuvent choisir n'importe quel ensemble de sources d'entrée pour leur recherche.  \n",
        "\n",
        "### Planification  \n",
        "- Les utilisateurs fournissent un sujet, et le système propose/génère une équipe d'analystes IA, chacun se concentrant sur un sous-sujet ou point de vue différent.  \n",
        "- L'approche \"humain dans la boucle\" sera utilisée pour affiner ces sous-sujets avant de commencer la recherche.  \n",
        "\n",
        "### Utilisation des LLM  \n",
        "- Chaque analyste mènera des entretiens approfondis avec une IA experte en utilisant les sources sélectionnées.  \n",
        "- L'entretien sera une conversation en plusieurs tours pour extraire des informations détaillées, comme indiqué dans le document STORM.  \n",
        "- Ces entretiens seront capturés à l'aide de sous-graphes avec leur état interne.  \n",
        "\n",
        "### Processus de recherche  \n",
        "- Les experts collecteront des informations pour répondre aux questions des analystes en parallèle.  \n",
        "- Tous les entretiens seront menés simultanément via une approche map-reduce.  \n",
        "\n",
        "### Format de sortie  \n",
        "- Les informations recueillies lors de chaque entretien seront synthétisées dans un rapport final.  \n",
        "- Nous utiliserons des invites personnalisables pour le rapport, permettant un format de sortie flexible.  \n",
        "\n",
        "Ressources:\n",
        "- Batter than RAG: AI-based research report generation workflows with standard operating procedures (SOP): https://jxnl.co/writing/2024/06/05/predictions-for-the-future-of-rag/#reports-over-rag\n",
        "- Sources: multi-turn langchain STORM (a regardé car mis à jour https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/storm/storm.ipynb, cours LangGraph https://github.com/langchain-ai/langchain-academy/blob/main/module-4/research-assistant.ipynb\n",
        "\n",
        "![Final Research Paper](https://drive.google.com/uc?id=1rLxBY-tUdn_W0QT55vECkww_N9cPaZvU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f23991e9-51b3-4e9f-86a0-dec16aa7d1e6",
      "metadata": {
        "id": "f23991e9-51b3-4e9f-86a0-dec16aa7d1e6",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install --quiet -U langgraph langchain_openai langchain_community langchain_core tavily-python wikipedia\n",
        "%pip install --quiet langchain-core openai>=1.26.0 tiktoken>=0.7 langchain-community arxiv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ma4uAQRlHQ8o",
      "metadata": {
        "id": "ma4uAQRlHQ8o"
      },
      "outputs": [],
      "source": [
        "# Nous remplaçons l'utilisation d'OpenAI par OpenRouter qui donne accès à plus de 200 modèles\n",
        "\n",
        "import os\n",
        "#os.environ['LANGCHAIN_API_KEY'] = '....'\n",
        "#! export LANGCHAIN_TRACING_V2 = true\n",
        "os.environ['TAVILY_API_KEY'] = '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'\n",
        "os.environ['OPENAI_API_KEY'] = '...'\n",
        "os.environ['OPENAI_BASE_URL'] = 'https://api.openai.com/v1'\n",
        "\n",
        "#os.environ['OPENAI_BASE_URL'] = \"https://openrouter.ai/api/v1\"\n",
        "#os.environ['OPENROUTER_API_KEY'] = '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' # Nous testerons aussi \"deepseek/deepseek-chat\" qui est plus puissant et moins cher mais pour l'instant n'a pas la génération controlée\n",
        "#os.environ['OPENAI_API_KEY'] = os.environ['OPENROUTER_API_KEY']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99a1c01d-87e1-4723-b83e-ebcf937fe914",
      "metadata": {
        "id": "99a1c01d-87e1-4723-b83e-ebcf937fe914"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba917800-10e4-4e2a-8e9e-30893b731e97",
      "metadata": {
        "id": "ba917800-10e4-4e2a-8e9e-30893b731e97"
      },
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe9ff57-0826-4669-b88b-4d0501a509f5",
      "metadata": {
        "id": "afe9ff57-0826-4669-b88b-4d0501a509f5"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0) # quand on utilise directement le serveur openai\n",
        "#llm = ChatOpenAI(model=\"openai/gpt-4o-mini\", temperature=0)#google/gemini-2.0-flash-exp:free google/gemini-exp-1206:free google/gemini-2.0-flash-thinking-exp:free meta-llama/llama-3.2-3b-instruct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3419257b-2c6b-4d68-ae38-4a266cc02982",
      "metadata": {
        "id": "3419257b-2c6b-4d68-ae38-4a266cc02982"
      },
      "source": [
        "Nous pouvons optionnellement utiliser [LangSmith](https://docs.smith.langchain.com/) pour [tracer les étapes / tracing](https://docs.smith.langchain.com/concepts/tracing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5102cf2e-0ca9-465b-9499-67abb8132e5d",
      "metadata": {
        "id": "5102cf2e-0ca9-465b-9499-67abb8132e5d"
      },
      "outputs": [],
      "source": [
        "#=_set_env(\"LANGCHAIN_API_KEY\")\n",
        "#os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "#os.environ[\"LANGCHAIN_PROJECT\"] = \"TP-LLM-AGENTS-M2-UTLN\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8fe5d93-e353-44bb-be3e-434654bcb7ea",
      "metadata": {
        "id": "f8fe5d93-e353-44bb-be3e-434654bcb7ea"
      },
      "source": [
        "## Génération des analystes: Human-In-The-Loop\n",
        "\n",
        "Créez des analystes et examinez-les en utilisant la possibilité d'un feedback (human-in-the-loop)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eee8e60-e548-49b1-88ec-a4f3aef2174e",
      "metadata": {
        "id": "1eee8e60-e548-49b1-88ec-a4f3aef2174e"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class Analyst(BaseModel):\n",
        "    affiliation: str = Field(\n",
        "        description=\"Primary affiliation of the analyst.\",\n",
        "    )\n",
        "    name: str = Field(\n",
        "        description=\"Name of the analyst.\"\n",
        "    )\n",
        "    role: str = Field(\n",
        "        description=\"Role of the analyst in the context of the topic.\",\n",
        "    )\n",
        "    description: str = Field(\n",
        "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
        "    )\n",
        "    @property\n",
        "    def persona(self) -> str:\n",
        "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
        "\n",
        "class Perspectives(BaseModel):\n",
        "    analysts: List[Analyst] = Field(\n",
        "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
        "    )\n",
        "\n",
        "class GenerateAnalystsState(TypedDict):\n",
        "    topic: str # Research topic\n",
        "    max_analysts: int # Number of analysts\n",
        "    human_analyst_feedback: str # Human feedback\n",
        "    analysts: List[Analyst] # Analyst asking questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd088ff5-4c75-412c-85f0-04afd0900bfc",
      "metadata": {
        "id": "fd088ff5-4c75-412c-85f0-04afd0900bfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "b866965e-2220-4127-fc4f-5cc9bafa91ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "\n",
        "analyst_instructions=\"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
        "\n",
        "1. First, review the research topic:\n",
        "{topic}\n",
        "\n",
        "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
        "\n",
        "{human_analyst_feedback}\n",
        "\n",
        "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
        "\n",
        "4. Pick the top {max_analysts} themes.\n",
        "\n",
        "5. Assign one analyst to each theme.\"\"\"\n",
        "\n",
        "def create_analysts(state: GenerateAnalystsState):\n",
        "\n",
        "    \"\"\" Create analysts \"\"\"\n",
        "\n",
        "    topic=state['topic']\n",
        "    max_analysts=state['max_analysts']\n",
        "    human_analyst_feedback=state.get('human_analyst_feedback', '')\n",
        "\n",
        "    # Enforce structured output\n",
        "    structured_llm = llm.with_structured_output(Perspectives)\n",
        "\n",
        "    # System message\n",
        "    system_message = analyst_instructions.format(topic=topic,\n",
        "                                                            human_analyst_feedback=human_analyst_feedback,\n",
        "                                                            max_analysts=max_analysts)\n",
        "\n",
        "    # Generate question\n",
        "    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate the set of analysts.\")])\n",
        "\n",
        "    # Write the list of analysis to state\n",
        "    return {\"analysts\": analysts.analysts}\n",
        "\n",
        "def human_feedback(state: GenerateAnalystsState):\n",
        "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
        "    pass\n",
        "\n",
        "def should_continue(state: GenerateAnalystsState):\n",
        "    \"\"\" Return the next node to execute \"\"\"\n",
        "\n",
        "    # Check if human feedback\n",
        "    human_analyst_feedback=state.get('human_analyst_feedback', None)\n",
        "    if human_analyst_feedback:\n",
        "        return \"create_analysts\"\n",
        "\n",
        "    # Otherwise end\n",
        "    return END\n",
        "\n",
        "# Add nodes and edges\n",
        "builder = StateGraph(GenerateAnalystsState)\n",
        "builder.add_node(\"create_analysts\", create_analysts)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "builder.add_edge(START, \"create_analysts\")\n",
        "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
        "builder.add_conditional_edges(\"human_feedback\", should_continue, [\"create_analysts\", END])\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)\n",
        "\n",
        "# View\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c22cb05-c436-4358-8f7a-72d722f9b5cc",
      "metadata": {
        "id": "6c22cb05-c436-4358-8f7a-72d722f9b5cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b5e6c98-b7e6-4e15-e84a-4f3c6a369456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Dr. Alice Martin\n",
            "Affiliation: Toulon University\n",
            "Role: Educational Technology Specialist\n",
            "Description: Dr. Martin focuses on the integration of technology in higher education. She is particularly interested in how a research assistant framework can enhance student learning and engagement, streamline research processes, and improve academic outcomes.\n",
            "--------------------------------------------------\n",
            "Name: Prof. John Smith\n",
            "Affiliation: Toulon University\n",
            "Role: Research Methodologist\n",
            "Description: Prof. Smith specializes in research methodologies and is concerned with the effectiveness and efficiency of research practices. He aims to explore how a structured research assistant framework can facilitate better data collection, analysis, and collaboration among researchers.\n",
            "--------------------------------------------------\n",
            "Name: Ms. Clara Lopez\n",
            "Affiliation: Toulon University\n",
            "Role: Student Representative\n",
            "Description: Ms. Lopez represents the student body and advocates for student needs and perspectives. She is focused on how the research assistant framework can provide students with valuable skills, enhance their employability, and foster a supportive research environment.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Input\n",
        "max_analysts = 3\n",
        "topic = \"The benefits of developing a research assistant framework at Toulon University\"\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Run the graph until the first interruption\n",
        "for event in graph.stream({\"topic\":topic,\"max_analysts\":max_analysts,}, thread, stream_mode=\"values\"):\n",
        "    # Review\n",
        "    analysts = event.get('analysts', '')\n",
        "    if analysts:\n",
        "        for analyst in analysts:\n",
        "            print(f\"Name: {analyst.name}\")\n",
        "            print(f\"Affiliation: {analyst.affiliation}\")\n",
        "            print(f\"Role: {analyst.role}\")\n",
        "            print(f\"Description: {analyst.description}\")\n",
        "            print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f81ad23-5656-43e6-b50a-0d7a4f69a60a",
      "metadata": {
        "id": "2f81ad23-5656-43e6-b50a-0d7a4f69a60a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faedfd11-956c-4488-929e-68b2200c15d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('human_feedback',)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Get state and look at next node\n",
        "state = graph.get_state(thread)\n",
        "state.next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b2a402-fd10-4f26-9a32-3e3c0d4aaf76",
      "metadata": {
        "id": "72b2a402-fd10-4f26-9a32-3e3c0d4aaf76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3408705-a0bd-4a95-e673-9641eb7cc3d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efdbef9-11de-68ec-8002-82b5ff3c3b58'}}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# We now update the state as if we are the human_feedback node\n",
        "graph.update_state(thread, {\"human_analyst_feedback\":\n",
        "                            \"Add in someone from a startup to add an entrepreneur perspective\"}, as_node=\"human_feedback\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8816eb9-9906-441b-b552-be71107db14f",
      "metadata": {
        "id": "b8816eb9-9906-441b-b552-be71107db14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b24e9762-b759-47a1-d948-5e4992775e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Dr. Alice Martin\n",
            "Affiliation: Toulon University\n",
            "Role: Educational Technology Specialist\n",
            "Description: Dr. Martin focuses on the integration of technology in higher education. She is particularly interested in how a research assistant framework can enhance student learning and engagement, streamline research processes, and improve academic outcomes.\n",
            "--------------------------------------------------\n",
            "Name: Prof. John Smith\n",
            "Affiliation: Toulon University\n",
            "Role: Research Methodologist\n",
            "Description: Prof. Smith specializes in research methodologies and is concerned with the effectiveness and efficiency of research practices. He aims to explore how a structured research assistant framework can facilitate better data collection, analysis, and collaboration among researchers.\n",
            "--------------------------------------------------\n",
            "Name: Ms. Clara Lopez\n",
            "Affiliation: Toulon University\n",
            "Role: Student Representative\n",
            "Description: Ms. Lopez represents the student body and advocates for student needs and perspectives. She is focused on how the research assistant framework can provide students with valuable skills, enhance their employability, and foster a supportive research environment.\n",
            "--------------------------------------------------\n",
            "Name: Dr. Marie Dupont\n",
            "Affiliation: Toulon University\n",
            "Role: Academic Researcher\n",
            "Description: Dr. Dupont focuses on the integration of research assistant frameworks in academic settings, emphasizing the enhancement of student learning and research productivity. She is concerned with how such frameworks can support faculty and improve the overall research output of the university.\n",
            "--------------------------------------------------\n",
            "Name: Prof. Jean-Pierre Martin\n",
            "Affiliation: Toulon University\n",
            "Role: Technology Integration Specialist\n",
            "Description: Prof. Martin specializes in the technological aspects of research frameworks. His focus is on how digital tools and platforms can be leveraged to create efficient research assistant systems that facilitate collaboration and data management among researchers.\n",
            "--------------------------------------------------\n",
            "Name: Sophie Leclerc\n",
            "Affiliation: TechStart Innovations\n",
            "Role: Startup Entrepreneur\n",
            "Description: Sophie Leclerc brings an entrepreneurial perspective, focusing on the potential for research assistant frameworks to foster innovation and collaboration between academia and industry. She is interested in how such frameworks can create opportunities for startups and enhance the commercialization of research outcomes.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Continue the graph execution\n",
        "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
        "    # Review\n",
        "    analysts = event.get('analysts', '')\n",
        "    if analysts:\n",
        "        for analyst in analysts:\n",
        "            print(f\"Name: {analyst.name}\")\n",
        "            print(f\"Affiliation: {analyst.affiliation}\")\n",
        "            print(f\"Role: {analyst.role}\")\n",
        "            print(f\"Description: {analyst.description}\")\n",
        "            print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43ac322-5926-4932-8653-68206fec0d2c",
      "metadata": {
        "id": "a43ac322-5926-4932-8653-68206fec0d2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62aefd27-e788-4677-d9e6-536f2f27f16f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efdbef9-23cb-635e-8004-58b6020e7986'}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# If we are satisfied, then we simply supply no feedback\n",
        "further_feedack = None\n",
        "graph.update_state(thread, {\"human_analyst_feedback\":\n",
        "                            further_feedack}, as_node=\"human_feedback\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab034e65-aeee-4723-8d6d-74541b548425",
      "metadata": {
        "id": "ab034e65-aeee-4723-8d6d-74541b548425"
      },
      "outputs": [],
      "source": [
        "# Continue the graph execution to end\n",
        "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
        "    print(\"--Node--\")\n",
        "    node_name = next(iter(event.keys()))\n",
        "    print(node_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f204e8a-285c-4e46-8223-a695caec7764",
      "metadata": {
        "id": "2f204e8a-285c-4e46-8223-a695caec7764"
      },
      "outputs": [],
      "source": [
        "final_state = graph.get_state(thread)\n",
        "analysts = final_state.values.get('analysts')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59704086-cb3b-42e9-8395-37be6f0d44e9",
      "metadata": {
        "id": "59704086-cb3b-42e9-8395-37be6f0d44e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad9bdc8d-b527-421d-c3b2-cb67349b03a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "final_state.next"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95717ba3-aa00-48d6-bbb7-5fe4db5919bf",
      "metadata": {
        "id": "95717ba3-aa00-48d6-bbb7-5fe4db5919bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ac8aca-e7b5-4171-c152-68f71e852cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Dr. Marie Dupont\n",
            "Affiliation: Toulon University\n",
            "Role: Academic Researcher\n",
            "Description: Dr. Dupont focuses on the integration of research assistant frameworks in academic settings, emphasizing the enhancement of student learning and research productivity. She is concerned with how such frameworks can support faculty and improve the overall research output of the university.\n",
            "--------------------------------------------------\n",
            "Name: Prof. Jean-Pierre Martin\n",
            "Affiliation: Toulon University\n",
            "Role: Technology Integration Specialist\n",
            "Description: Prof. Martin specializes in the technological aspects of research frameworks. His focus is on how digital tools and platforms can be leveraged to create efficient research assistant systems that facilitate collaboration and data management among researchers.\n",
            "--------------------------------------------------\n",
            "Name: Sophie Leclerc\n",
            "Affiliation: TechStart Innovations\n",
            "Role: Startup Entrepreneur\n",
            "Description: Sophie Leclerc brings an entrepreneurial perspective, focusing on the potential for research assistant frameworks to foster innovation and collaboration between academia and industry. She is interested in how such frameworks can create opportunities for startups and enhance the commercialization of research outcomes.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for analyst in analysts:\n",
        "    print(f\"Name: {analyst.name}\")\n",
        "    print(f\"Affiliation: {analyst.affiliation}\")\n",
        "    print(f\"Role: {analyst.role}\")\n",
        "    print(f\"Description: {analyst.description}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d2498e4-20ae-4503-9dd0-a4165132b7a7",
      "metadata": {
        "id": "7d2498e4-20ae-4503-9dd0-a4165132b7a7"
      },
      "source": [
        "## Réaliser les Interviews\n",
        "\n",
        "### Generate Question\n",
        "\n",
        "The analyst will ask questions to the expert."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5d5f559-f42e-442b-87cd-dbf0a91abf9c",
      "metadata": {
        "id": "e5d5f559-f42e-442b-87cd-dbf0a91abf9c"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import  Annotated\n",
        "from langgraph.graph import MessagesState\n",
        "\n",
        "class InterviewState(MessagesState):\n",
        "    max_num_turns: int # Number turns of conversation\n",
        "    context: Annotated[list, operator.add] # Source docs\n",
        "    analyst: Analyst # Analyst asking questions\n",
        "    interview: str # Interview transcript\n",
        "    sections: list # Final key we duplicate in outer state for Send() API\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    search_query: str = Field(None, description=\"Search query for retrieval.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c2e71eb-07ad-4bea-aabc-dbaf551408c0",
      "metadata": {
        "id": "1c2e71eb-07ad-4bea-aabc-dbaf551408c0"
      },
      "outputs": [],
      "source": [
        "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
        "\n",
        "Your goal is boil down to interesting and specific insights related to your topic.\n",
        "\n",
        "1. Interesting: Insights that people will find surprising or non-obvious.\n",
        "\n",
        "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
        "\n",
        "Here is your topic of focus and set of goals: {goals}\n",
        "\n",
        "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
        "\n",
        "Continue to ask questions to drill down and refine your understanding of the topic.\n",
        "\n",
        "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
        "\n",
        "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
        "\n",
        "def generate_question(state: InterviewState):\n",
        "    \"\"\" Node to generate a question \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    analyst = state[\"analyst\"]\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Generate question\n",
        "    system_message = question_instructions.format(goals=analyst.persona)\n",
        "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
        "\n",
        "    # Write messages to state\n",
        "    return {\"messages\": [question]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be2ff33a-6232-4a79-8a82-882a645394f5",
      "metadata": {
        "id": "be2ff33a-6232-4a79-8a82-882a645394f5"
      },
      "source": [
        "### Generate Answer: Parallelization\n",
        "\n",
        "The expert will gather information from multiple sources in parallel to answer questions.\n",
        "\n",
        "For example, we can use:\n",
        "\n",
        "* Specific web sites e.g., via [`WebBaseLoader`](https://python.langchain.com/v0.2/docs/integrations/document_loaders/web_base/)\n",
        "* Indexed documents e.g., via [RAG](https://python.langchain.com/v0.2/docs/tutorials/rag/)\n",
        "* Web search\n",
        "* Wikipedia search\n",
        "\n",
        "You can try different web search tools, like [Tavily](https://tavily.com/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "606ea95b-e811-4299-8b66-835d4016c338",
      "metadata": {
        "id": "606ea95b-e811-4299-8b66-835d4016c338"
      },
      "outputs": [],
      "source": [
        "def _set_env(var: str):\n",
        "    if not os.environ.get(var):\n",
        "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
        "\n",
        "_set_env(\"TAVILY_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c61ae74a-f838-4e97-8bd5-48ccd15b7789",
      "metadata": {
        "id": "c61ae74a-f838-4e97-8bd5-48ccd15b7789"
      },
      "outputs": [],
      "source": [
        "# Web search tool\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "tavily_search = TavilySearchResults(max_results=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d8f760b-5a1a-4fa9-a014-d3fb02bec51c",
      "metadata": {
        "id": "2d8f760b-5a1a-4fa9-a014-d3fb02bec51c"
      },
      "outputs": [],
      "source": [
        "# Wikipedia search tool\n",
        "from langchain_community.document_loaders import WikipediaLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06cb1603",
      "metadata": {
        "id": "06cb1603"
      },
      "source": [
        "Now, we create nodes to search the web and wikipedia.\n",
        "\n",
        "We'll also create a node to answer analyst questions.\n",
        "\n",
        "Finally, we'll create nodes to save the full interview and to write a summary (\"section\") of the interview."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c863768-2278-415b-aef1-96fd18c1b1cb",
      "metadata": {
        "id": "9c863768-2278-415b-aef1-96fd18c1b1cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "3a2ffc5f-48f6-4fb8-8f28-2a7eff8aafb1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_core.messages import get_buffer_string\n",
        "\n",
        "# Search query writing\n",
        "search_instructions = \"\"\"You will be given a conversation between an analyst and an expert.\n",
        "\n",
        "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
        "\n",
        "First, analyze the full conversation.\n",
        "\n",
        "Pay particular attention to the final question posed by the analyst.\n",
        "\n",
        "Convert this final question into a well-structured web search query\"\"\"\n",
        "def search_web(state: InterviewState):\n",
        "\n",
        "    \"\"\" Retrieve docs from web search \"\"\"\n",
        "\n",
        "    # Search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
        "\n",
        "    # Search\n",
        "    search_docs = tavily_search.invoke(search_query.search_query)\n",
        "    print(f\"search_docs : {search_docs}\")\n",
        "\n",
        "     # Format\n",
        "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
        "        [\n",
        "            f'<Document href=\"{doc[\"url\"]}\"/>\\n{doc[\"content\"]}\\n</Document>'\n",
        "            for doc in search_docs\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return {\"context\": [formatted_search_docs]}\n",
        "\n",
        "def search_wikipedia(state: InterviewState):\n",
        "\n",
        "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
        "\n",
        "    # Search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
        "\n",
        "    # Search\n",
        "    search_docs = WikipediaLoader(query=search_query.search_query,\n",
        "                                  load_max_docs=2).load()\n",
        "\n",
        "     # Format\n",
        "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
        "        [\n",
        "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
        "            for doc in search_docs\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return {\"context\": [formatted_search_docs]}\n",
        "\n",
        "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
        "\n",
        "Here is analyst area of focus: {goals}.\n",
        "\n",
        "You goal is to answer a question posed by the interviewer.\n",
        "\n",
        "To answer question, use this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "When answering questions, follow these guidelines:\n",
        "\n",
        "1. Use only the information provided in the context.\n",
        "\n",
        "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
        "\n",
        "3. The context contain sources at the topic of each individual document.\n",
        "\n",
        "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
        "\n",
        "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
        "\n",
        "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
        "\n",
        "[1] assistant/docs/llama3_1.pdf, page 7\n",
        "\n",
        "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
        "\n",
        "def generate_answer(state: InterviewState):\n",
        "\n",
        "    \"\"\" Node to answer a question \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    analyst = state[\"analyst\"]\n",
        "    messages = state[\"messages\"]\n",
        "    context = state[\"context\"]\n",
        "\n",
        "    # Answer question\n",
        "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
        "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
        "\n",
        "    # Name the message as coming from the expert\n",
        "    answer.name = \"expert\"\n",
        "\n",
        "    # Append it to state\n",
        "    return {\"messages\": [answer]}\n",
        "\n",
        "def save_interview(state: InterviewState):\n",
        "\n",
        "    \"\"\" Save interviews \"\"\"\n",
        "\n",
        "    # Get messages\n",
        "    messages = state[\"messages\"]\n",
        "\n",
        "    # Convert interview to a string\n",
        "    interview = get_buffer_string(messages)\n",
        "\n",
        "    # Save to interviews key\n",
        "    return {\"interview\": interview}\n",
        "\n",
        "def route_messages(state: InterviewState,\n",
        "                   name: str = \"expert\"):\n",
        "\n",
        "    \"\"\" Route between question and answer \"\"\"\n",
        "\n",
        "    # Get messages\n",
        "    messages = state[\"messages\"]\n",
        "    max_num_turns = state.get('max_num_turns',2)\n",
        "\n",
        "    # Check the number of expert answers\n",
        "    num_responses = len(\n",
        "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
        "    )\n",
        "\n",
        "    # End if expert has answered more than the max turns\n",
        "    if num_responses >= max_num_turns:\n",
        "        return 'save_interview'\n",
        "\n",
        "    # This router is run after each question - answer pair\n",
        "    # Get the last question asked to check if it signals the end of discussion\n",
        "    last_question = messages[-2]\n",
        "\n",
        "    if \"Thank you so much for your help\" in last_question.content:\n",
        "        return 'save_interview'\n",
        "    return \"ask_question\"\n",
        "\n",
        "section_writer_instructions = \"\"\"You are an expert technical writer.\n",
        "\n",
        "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
        "\n",
        "1. Analyze the content of the source documents:\n",
        "- The name of each source document is at the start of the document, with the <Document tag.\n",
        "\n",
        "2. Create a report structure using markdown formatting:\n",
        "- Use ## for the section title\n",
        "- Use ### for sub-section headers\n",
        "\n",
        "3. Write the report following this structure:\n",
        "a. Title (## header)\n",
        "b. Summary (### header)\n",
        "c. Sources (### header)\n",
        "\n",
        "4. Make your title engaging based upon the focus area of the analyst:\n",
        "{focus}\n",
        "\n",
        "5. For the summary section:\n",
        "- Set up summary with general background / context related to the focus area of the analyst\n",
        "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
        "- Create a numbered list of source documents, as you use them\n",
        "- Do not mention the names of interviewers or experts\n",
        "- Aim for approximately 400 words maximum\n",
        "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
        "\n",
        "6. In the Sources section:\n",
        "- Include all sources used in your report\n",
        "- Provide full links to relevant websites or specific document paths\n",
        "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
        "- It will look like:\n",
        "\n",
        "### Sources\n",
        "[1] Link or Document name\n",
        "[2] Link or Document name\n",
        "\n",
        "7. Be sure to combine sources. For example this is not correct:\n",
        "\n",
        "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "\n",
        "There should be no redundant sources. It should simply be:\n",
        "\n",
        "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
        "\n",
        "8. Final review:\n",
        "- Ensure the report follows the required structure\n",
        "- Include no preamble before the title of the report\n",
        "- Check that all guidelines have been followed\"\"\"\n",
        "\n",
        "def write_section(state: InterviewState):\n",
        "\n",
        "    \"\"\" Node to answer a question \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    interview = state[\"interview\"]\n",
        "    context = state[\"context\"]\n",
        "    analyst = state[\"analyst\"]\n",
        "\n",
        "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
        "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
        "    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write your section: {context}\")])\n",
        "\n",
        "    # Append it to state\n",
        "    return {\"sections\": [section.content]}\n",
        "\n",
        "# Add nodes and edges\n",
        "interview_builder = StateGraph(InterviewState)\n",
        "interview_builder.add_node(\"ask_question\", generate_question)\n",
        "interview_builder.add_node(\"search_web\", search_web)\n",
        "interview_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
        "interview_builder.add_node(\"answer_question\", generate_answer)\n",
        "interview_builder.add_node(\"save_interview\", save_interview)\n",
        "interview_builder.add_node(\"write_section\", write_section)\n",
        "\n",
        "# Flow\n",
        "interview_builder.add_edge(START, \"ask_question\")\n",
        "interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
        "interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
        "interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
        "interview_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
        "interview_builder.add_conditional_edges(\"answer_question\", route_messages,['ask_question','save_interview'])\n",
        "interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
        "interview_builder.add_edge(\"write_section\", END)\n",
        "\n",
        "# Interview\n",
        "memory = MemorySaver()\n",
        "interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")\n",
        "\n",
        "# View\n",
        "display(Image(interview_graph.get_graph().draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50f382f1-6e93-48d0-a44a-1094d26ccb1e",
      "metadata": {
        "id": "50f382f1-6e93-48d0-a44a-1094d26ccb1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b1aba35-0935-475f-d5f8-ef057f2d9d0c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Analyst(affiliation='Toulon University', name='Dr. Marie Dupont', role='Academic Researcher', description='Dr. Dupont focuses on the integration of research assistant frameworks in academic settings, emphasizing the enhancement of student learning and research productivity. She is concerned with how such frameworks can support faculty and improve the overall research output of the university.')"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Pick one analyst\n",
        "analysts[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3750ac4f-f458-4b2d-8bad-32ce34895758",
      "metadata": {
        "id": "3750ac4f-f458-4b2d-8bad-32ce34895758"
      },
      "source": [
        "Here, we run the interview passing an index of the llama3.1 paper, which is related to our topic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2242d4e-8430-4de9-8cf7-3ad2f9a22b28",
      "metadata": {
        "id": "b2242d4e-8430-4de9-8cf7-3ad2f9a22b28"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "messages = [HumanMessage(f\"So you said you were writing an article on {topic}?\")]\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "#interview = interview_graph.invoke({\"analyst\": analysts[0], \"messages\": messages, \"max_num_turns\": 2}, thread)\n",
        "#Markdown(interview['sections'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b739e87-68bb-4e96-a86a-704e84240a6c",
      "metadata": {
        "id": "3b739e87-68bb-4e96-a86a-704e84240a6c"
      },
      "source": [
        "### Parallelze interviews: Map-Reduce\n",
        "\n",
        "We parallelize the interviews via the `Send()` API, a map step.\n",
        "\n",
        "We combine them into the report body in a reduce step.\n",
        "\n",
        "### Finalize\n",
        "\n",
        "We add a final step to write an intro and conclusion to the final report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a0042f9-5b9f-441a-9e8d-7d8189f44140",
      "metadata": {
        "id": "6a0042f9-5b9f-441a-9e8d-7d8189f44140"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import List, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "\n",
        "class ResearchGraphState(TypedDict):\n",
        "    topic: str # Research topic\n",
        "    max_analysts: int # Number of analysts\n",
        "    human_analyst_feedback: str # Human feedback\n",
        "    analysts: List[Analyst] # Analyst asking questions\n",
        "    sections: Annotated[list, operator.add] # Send() API key\n",
        "    introduction: str # Introduction for the final report\n",
        "    content: str # Content for the final report\n",
        "    conclusion: str # Conclusion for the final report\n",
        "    final_report: str # Final report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2224592-d2ff-469d-97bd-928809f896d7",
      "metadata": {
        "id": "c2224592-d2ff-469d-97bd-928809f896d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f5d6a454-0c00-4a7f-ec60-7e6fa04c18b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from langgraph.constants import Send\n",
        "\n",
        "def initiate_all_interviews(state: ResearchGraphState):\n",
        "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\"\n",
        "\n",
        "    # Check if human feedback\n",
        "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
        "    if human_analyst_feedback:\n",
        "        # Return to create_analysts\n",
        "        return \"create_analysts\"\n",
        "\n",
        "    # Otherwise kick off interviews in parallel via Send() API\n",
        "    else:\n",
        "        topic = state[\"topic\"]\n",
        "        return [Send(\"conduct_interview\", {\"analyst\": analyst,\n",
        "                                           \"messages\": [HumanMessage(\n",
        "                                               content=f\"So you said you were writing an article on {topic}?\"\n",
        "                                           )\n",
        "                                                       ]}) for analyst in state[\"analysts\"]]\n",
        "\n",
        "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic:\n",
        "\n",
        "{topic}\n",
        "\n",
        "You have a team of analysts. Each analyst has done two things:\n",
        "\n",
        "1. They conducted an interview with an expert on a specific sub-topic.\n",
        "2. They write up their finding into a memo.\n",
        "\n",
        "Your task:\n",
        "\n",
        "1. You will be given a collection of memos from your analysts.\n",
        "2. Think carefully about the insights from each memo.\n",
        "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\n",
        "4. Summarize the central points in each memo into a cohesive single narrative.\n",
        "\n",
        "To format your report:\n",
        "\n",
        "1. Use markdown formatting.\n",
        "2. Include no pre-amble for the report.\n",
        "3. Use no sub-heading.\n",
        "4. Start your report with a single title header: ## Insights\n",
        "5. Do not mention any analyst names in your report.\n",
        "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
        "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
        "8. List your sources in order and do not repeat.\n",
        "\n",
        "[1] Source 1\n",
        "[2] Source 2\n",
        "\n",
        "Here are the memos from your analysts to build your report from:\n",
        "\n",
        "{context}\"\"\"\n",
        "\n",
        "def write_report(state: ResearchGraphState):\n",
        "    # Full set of sections\n",
        "    sections = state[\"sections\"]\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # Concat all sections together\n",
        "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
        "\n",
        "    # Summarize the sections into a final report\n",
        "    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\n",
        "    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Write a report based upon these memos.\")])\n",
        "    return {\"content\": report.content}\n",
        "\n",
        "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
        "\n",
        "You will be given all of the sections of the report.\n",
        "\n",
        "You job is to write a crisp and compelling introduction or conclusion section.\n",
        "\n",
        "The user will instruct you whether to write the introduction or conclusion.\n",
        "\n",
        "Include no pre-amble for either section.\n",
        "\n",
        "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
        "\n",
        "Use markdown formatting.\n",
        "\n",
        "For your introduction, create a compelling title and use the # header for the title.\n",
        "\n",
        "For your introduction, use ## Introduction as the section header.\n",
        "\n",
        "For your conclusion, use ## Conclusion as the section header.\n",
        "\n",
        "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
        "\n",
        "def write_introduction(state: ResearchGraphState):\n",
        "    # Full set of sections\n",
        "    sections = state[\"sections\"]\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # Concat all sections together\n",
        "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
        "\n",
        "    # Summarize the sections into a final report\n",
        "\n",
        "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
        "    intro = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report introduction\")])\n",
        "    return {\"introduction\": intro.content}\n",
        "\n",
        "def write_conclusion(state: ResearchGraphState):\n",
        "    # Full set of sections\n",
        "    sections = state[\"sections\"]\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # Concat all sections together\n",
        "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
        "\n",
        "    # Summarize the sections into a final report\n",
        "\n",
        "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
        "    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report conclusion\")])\n",
        "    return {\"conclusion\": conclusion.content}\n",
        "\n",
        "def finalize_report(state: ResearchGraphState):\n",
        "    \"\"\" The is the \"reduce\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion \"\"\"\n",
        "    # Save full final report\n",
        "    content = state[\"content\"]\n",
        "    if content.startswith(\"## Insights\"):\n",
        "        content = content.strip(\"## Insights\")\n",
        "    if \"## Sources\" in content:\n",
        "        try:\n",
        "            content, sources = content.split(\"\\n## Sources\\n\")\n",
        "        except:\n",
        "            sources = None\n",
        "    else:\n",
        "        sources = None\n",
        "\n",
        "    final_report = state[\"introduction\"] + \"\\n\\n---\\n\\n\" + content + \"\\n\\n---\\n\\n\" + state[\"conclusion\"]\n",
        "    if sources is not None:\n",
        "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
        "    return {\"final_report\": final_report}\n",
        "\n",
        "# Add nodes and edges\n",
        "builder = StateGraph(ResearchGraphState)\n",
        "builder.add_node(\"create_analysts\", create_analysts)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
        "builder.add_node(\"write_report\",write_report)\n",
        "builder.add_node(\"write_introduction\",write_introduction)\n",
        "builder.add_node(\"write_conclusion\",write_conclusion)\n",
        "builder.add_node(\"finalize_report\",finalize_report)\n",
        "\n",
        "# Logic\n",
        "builder.add_edge(START, \"create_analysts\")\n",
        "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
        "builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
        "builder.add_edge(\"conduct_interview\", \"write_report\")\n",
        "builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
        "builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
        "builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
        "builder.add_edge(\"finalize_report\", END)\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b64ba9a-2b5e-40e1-a778-0f635aa3f6d0",
      "metadata": {
        "id": "1b64ba9a-2b5e-40e1-a778-0f635aa3f6d0"
      },
      "source": [
        "Let's ask an open-ended question about LangGraph."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "362932ee-4106-4a2d-a32d-b812eafcf9df",
      "metadata": {
        "id": "362932ee-4106-4a2d-a32d-b812eafcf9df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aebdbe63-59dc-4be5-9b79-a4fdb01dd0d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Dr. Emily Carter\n",
            "Affiliation: Tech Innovations Inc.\n",
            "Role: AI Framework Specialist\n",
            "Description: Dr. Carter focuses on the technical advantages of adopting LangGraph, emphasizing its scalability and integration capabilities with existing systems. She is motivated by the potential for LangGraph to enhance AI performance and streamline workflows.\n",
            "--------------------------------------------------\n",
            "Name: Mr. James Liu\n",
            "Affiliation: Future AI Research Group\n",
            "Role: AI Ethics Analyst\n",
            "Description: Mr. Liu examines the ethical implications of using LangGraph as an agent framework. He is particularly concerned with data privacy, bias in AI decision-making, and the transparency of AI processes, advocating for responsible AI development.\n",
            "--------------------------------------------------\n",
            "Name: Ms. Sarah Thompson\n",
            "Affiliation: Business Solutions Consultancy\n",
            "Role: Business Strategy Consultant\n",
            "Description: Ms. Thompson analyzes the business benefits of adopting LangGraph, focusing on cost-effectiveness, improved productivity, and competitive advantage. She aims to help organizations understand how LangGraph can drive innovation and enhance customer experiences.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Inputs\n",
        "max_analysts = 3\n",
        "topic = \"The benefits of adopting LangGraph as an agent framework\"\n",
        "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
        "\n",
        "# Run the graph until the first interruption\n",
        "for event in graph.stream({\"topic\":topic,\n",
        "                           \"max_analysts\":max_analysts},\n",
        "                          thread,\n",
        "                          stream_mode=\"values\"):\n",
        "\n",
        "    analysts = event.get('analysts', '')\n",
        "    if analysts:\n",
        "        for analyst in analysts:\n",
        "            print(f\"Name: {analyst.name}\")\n",
        "            print(f\"Affiliation: {analyst.affiliation}\")\n",
        "            print(f\"Role: {analyst.role}\")\n",
        "            print(f\"Description: {analyst.description}\")\n",
        "            print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac521a5f-5a4f-44f9-8af9-d05228e20882",
      "metadata": {
        "id": "ac521a5f-5a4f-44f9-8af9-d05228e20882",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "801e3ccc-5412-44b7-d710-b27e62e48509"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efdbef9-483e-6b63-8002-c2c25712c944'}}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# We now update the state as if we are the human_feedback node\n",
        "graph.update_state(thread, {\"human_analyst_feedback\":\n",
        "                                \"Add in the CEO of gen ai native startup\"}, as_node=\"human_feedback\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3be311f-62ee-49e7-b037-75c53d8960a8",
      "metadata": {
        "id": "a3be311f-62ee-49e7-b037-75c53d8960a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a282ea48-b0d2-4469-a5f6-9df1a9244226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: Dr. Emily Carter\n",
            "Affiliation: Tech Innovations Inc.\n",
            "Role: AI Framework Specialist\n",
            "Description: Dr. Carter focuses on the technical advantages of adopting LangGraph, emphasizing its scalability and integration capabilities with existing systems. She is motivated by the potential for LangGraph to enhance AI performance and streamline workflows.\n",
            "--------------------------------------------------\n",
            "Name: Mr. James Liu\n",
            "Affiliation: Future AI Research Group\n",
            "Role: AI Ethics Analyst\n",
            "Description: Mr. Liu examines the ethical implications of using LangGraph as an agent framework. He is particularly concerned with data privacy, bias in AI decision-making, and the transparency of AI processes, advocating for responsible AI development.\n",
            "--------------------------------------------------\n",
            "Name: Ms. Sarah Thompson\n",
            "Affiliation: Business Solutions Consultancy\n",
            "Role: Business Strategy Consultant\n",
            "Description: Ms. Thompson analyzes the business benefits of adopting LangGraph, focusing on cost-effectiveness, improved productivity, and competitive advantage. She aims to help organizations understand how LangGraph can drive innovation and enhance customer experiences.\n",
            "--------------------------------------------------\n",
            "Name: Alexandra Chen\n",
            "Affiliation: Gen AI Native Startup\n",
            "Role: CEO\n",
            "Description: As the CEO of a Gen AI native startup, Alexandra focuses on the strategic implementation of AI frameworks like LangGraph. She is particularly interested in how adopting such frameworks can enhance operational efficiency and drive innovation in AI applications.\n",
            "--------------------------------------------------\n",
            "Name: Dr. Samuel Patel\n",
            "Affiliation: Tech Research Institute\n",
            "Role: Lead AI Researcher\n",
            "Description: Dr. Patel specializes in AI frameworks and their impact on development processes. His research emphasizes the technical advantages of LangGraph, including its scalability and integration capabilities, and how these can benefit startups and established companies alike.\n",
            "--------------------------------------------------\n",
            "Name: Maria Lopez\n",
            "Affiliation: Business Innovation Consultancy\n",
            "Role: Senior Business Analyst\n",
            "Description: Maria analyzes market trends and business strategies related to AI adoption. She is keen on exploring the economic benefits of LangGraph, including cost savings, improved productivity, and competitive advantages for businesses that implement this agent framework.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Check\n",
        "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
        "    analysts = event.get('analysts', '')\n",
        "    if analysts:\n",
        "        for analyst in analysts:\n",
        "            print(f\"Name: {analyst.name}\")\n",
        "            print(f\"Affiliation: {analyst.affiliation}\")\n",
        "            print(f\"Role: {analyst.role}\")\n",
        "            print(f\"Description: {analyst.description}\")\n",
        "            print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0af41f54-88d9-4597-98b0-444c08322095",
      "metadata": {
        "id": "0af41f54-88d9-4597-98b0-444c08322095",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fc8f6f6-6b88-416e-8b12-f5cd61a08805"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'configurable': {'thread_id': '1',\n",
              "  'checkpoint_ns': '',\n",
              "  'checkpoint_id': '1efdbef9-594e-6f5f-8004-7eeafd1ebf8f'}}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# Confirm we are happy\n",
        "graph.update_state(thread, {\"human_analyst_feedback\":\n",
        "                            None}, as_node=\"human_feedback\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37123ca7-c20b-43c1-9a71-39ba344e7ca6",
      "metadata": {
        "id": "37123ca7-c20b-43c1-9a71-39ba344e7ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b5dfbfce-704c-4a48-db6c-26d97ed3639c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# Continue\\nfor event in graph.stream(None, thread, stream_mode=\"updates\"):\\n    print(\"--Node--\")\\n    node_name = next(iter(event.keys()))\\n    print(node_name)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "\"\"\"# Continue\n",
        "for event in graph.stream(None, thread, stream_mode=\"updates\"):\n",
        "    print(\"--Node--\")\n",
        "    node_name = next(iter(event.keys()))\n",
        "    print(node_name)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f66ad8-80fd-4eb2-96b6-6ae9dffd060c",
      "metadata": {
        "id": "f8f66ad8-80fd-4eb2-96b6-6ae9dffd060c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a527a996-fc7b-4031-e688-88d38638aa3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "final_state = graph.get_state(thread)\n",
        "report = final_state.values.get('final_report')\n",
        "Markdown(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9bf8edd-fb42-496c-9bdb-3f5d7b4d79d3",
      "metadata": {
        "id": "e9bf8edd-fb42-496c-9bdb-3f5d7b4d79d3"
      },
      "source": [
        "We can look at the trace:\n",
        "\n",
        "https://smith.langchain.com/public/2933a7bb-bcef-4d2d-9b85-cc735b22ca0c/r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808bd094",
      "metadata": {
        "id": "808bd094"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "AI5T9icqfyuX",
      "metadata": {
        "id": "AI5T9icqfyuX"
      },
      "source": [
        "## TODO (s'aider de ChatGPT ou Co-pilot ou Deepseek V3 en téléchargeant le code du notebook au format python pour le mettre dans le contexte de la question)\n",
        "\n",
        "## HOWTO lancer l'expérience learn.py: https://colab.research.google.com/drive/1I_XNDwBULZG-aHyh0byss-x77wkgaGpp?usp=sharing\n",
        "\n",
        "## Choisir 2+ sujets d'article de test parmis le dataset https://github.com/doxav/document_embedding_analysis/tree/main/output/latex\n",
        "\n",
        "ATTENTION: aucune fonction ne doit être spécialisée pour un article, c'est pour cela que l'on choisi au moins 2 sujets de test\n",
        "\n",
        "## Reco coordination équipe\n",
        "\n",
        "1.   Equipier 1 de chaque groupe: Task 1\n",
        "2.   Equipier 2 de chaque groupe: Task 2, puis Task 4\n",
        "3.   Equipier 3 de chaque groupe: Task 3\n",
        "4.   Equipier 4 de chaque groupe: Task 5, puis implémentation pour expérimentation\n",
        "5.   Chacun fait son XP solo\n",
        "6.   Chaque équipe: réalise les différents modes de l'expérimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CeUHK-0BgwvM",
      "metadata": {
        "id": "CeUHK-0BgwvM"
      },
      "source": [
        "# Task 1. Remplacer l'utilisation de l'API Tavili par 2 nouvelles recherches:\n",
        "- OBLIGATOIRE une recherche sur Arxiv des contenus (pas seulement le titre & abstract)\n",
        "- AU CHOIX une recherche sur https://www.semanticscholar.org/product/api\n",
        "- AU CHOIX une recherche RAG locale en indexant les ressources utilisées dans ce survey (pour votre usage personnel, l'idéal est de faire une hybridation RAG avec ajout de recherches web dont le contenu des résultats est indexé localement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lGsUGwKGgxIS",
      "metadata": {
        "id": "lGsUGwKGgxIS"
      },
      "outputs": [],
      "source": [
        "import arxiv\n",
        "import requests\n",
        "\n",
        "def search_web_arxiv(state: InterviewState):\n",
        "\n",
        "    \"\"\" Retrieve docs from arxiv search \"\"\"\n",
        "\n",
        "    # Search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
        "\n",
        "    # Arxiv search\n",
        "    search_results = arxiv.Search(\n",
        "        query=search_query.search_query,\n",
        "        max_results=3,\n",
        "        sort_by=arxiv.SortCriterion.Relevance\n",
        "    )\n",
        "\n",
        "    formatted_results = []\n",
        "    for result in search_results.results():\n",
        "\n",
        "      url = f\"https://ar5iv.labs.arxiv.org/html/{result.entry_id}\"\n",
        "      response = requests.get(url)\n",
        "\n",
        "      formatted_results.append(\n",
        "            f'<Document href=\"{result.entry_id}\">\\n'\n",
        "            f'Title: {result.title}\\n'\n",
        "            f'Authors: {\", \".join(author.name for author in result.authors)}\\n'\n",
        "            f'Abstract: {result.summary}\\n'\n",
        "            f'Content: {response.text}'\n",
        "            f'</Document>'\n",
        "      )\n",
        "\n",
        "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(formatted_results)\n",
        "\n",
        "    return {\"context\": [formatted_search_docs]}\n",
        "\n",
        "import requests\n",
        "\n",
        "def search_semantic_scholar(state: InterviewState):\n",
        "    \"\"\"  Searches Semantic Scholar using their API. \"\"\"\n",
        "    # Search query\n",
        "    structured_llm = llm.with_structured_output(SearchQuery)\n",
        "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
        "\n",
        "    base_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
        "    params = {\"query\": search_query, \"limit\": 3, \"fields\": \"url,title,abstract,authors\"}\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params)\n",
        "        response.raise_for_status()  # Raise an exception for bad status codes (4xx or 5xx)\n",
        "        formatted_results = []\n",
        "\n",
        "        for data in response.json()[\"data\"]:\n",
        "            formatted_results.append(\n",
        "            f'<Document url=\"{data[\"url\"]}\">\\n'\n",
        "            f'Title: {data[\"title\"]}\\n'\n",
        "            f'Authors: {\", \".join(author[\"name\"] for author in data[\"authors\"])}\\n'\n",
        "            f'Abstract: {data[\"abstract\"]}\\n'\n",
        "            f'</Document>'\n",
        "            )\n",
        "\n",
        "        formatted_search_docs = \"\\n\\n---\\n\\n\".join(formatted_results)\n",
        "        return {\"context\": [formatted_search_docs]}\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error during API request: {e}\")\n",
        "        return {\"error\": str(e)} #return error information\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return {\"error\": str(e)} #return error information"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L9pu3-uBgxQ6",
      "metadata": {
        "id": "L9pu3-uBgxQ6"
      },
      "source": [
        "# Task 2. Ajouter un agent de génération du plan des sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yZnjgUdlgxY1",
      "metadata": {
        "id": "yZnjgUdlgxY1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2075d27a-38ba-4764-da27-bd534317beb6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "class ResearchGraphState(TypedDict):\n",
        "    topic: str # Research topic\n",
        "    max_analysts: int # Number of analysts\n",
        "    human_analyst_feedback: str # Human feedback\n",
        "    analysts: List[Analyst] # Analyst asking questions\n",
        "    plan: str # Plan for the section of the report\n",
        "    sections: Annotated[list, operator.add] # Send() API key\n",
        "    introduction: str # Introduction for the final report\n",
        "    content: str # Content for the final report\n",
        "    conclusion: str # Conclusion for the final report\n",
        "    final_report: str # Final report\n",
        "\n",
        "plan_writer_instructions = \"\"\"\n",
        "You are a technical writer tasked with drafting a **structured plan** for a report. This report will consolidate insights derived from memos written by analysts, each summarizing interviews with experts on specific sub-topics.\n",
        "\n",
        "**Overall Topic:**\n",
        "{topic}\n",
        "\n",
        "**Your Task:**\n",
        "1. Carefully review the provided memos.\n",
        "2. Identify the key themes, central points, and recurring ideas from the memos.\n",
        "3. Develop a **structured plan or outline** for the report that organizes these insights logically.\n",
        "\n",
        "**Guidelines:**\n",
        "1. Focus on creating a **detailed plan** or outline for the report. Do not write the report itself.\n",
        "2. Organize the plan into the following sections:\n",
        "    - **Introduction:** Briefly outline the report's purpose and its scope based on the memos.\n",
        "    - **Key Themes:** Highlight the main themes or topics emerging from the memos, in bullet points.\n",
        "    - **Structure:** Propose a logical structure for the report, with sections and subsections as necessary.\n",
        "    - **Sources:** List references or citations mentioned in the memos, annotated as [1], [2], etc., to ensure they're included in the final report.\n",
        "\n",
        "**Output Format:**\n",
        "- Use Markdown formatting.\n",
        "- Present the plan in a **bullet-point outline**, organized under clear headings (e.g., Introduction, Key Themes, Structure, Sources).\n",
        "- Do **not** write the report itself. Focus exclusively on the plan.\n",
        "\n",
        "**Example Output:**\n",
        "### Introduction\n",
        "- Purpose: To consolidate insights on [topic] based on analyst memos.\n",
        "- Scope: This report will address [scope of the report].\n",
        "\n",
        "### Key Themes\n",
        "- Theme 1: [Brief description]\n",
        "- Theme 2: [Brief description]\n",
        "- Theme 3: [Brief description]\n",
        "\n",
        "### Structure\n",
        "1. Introduction\n",
        "    - Purpose and scope\n",
        "2. Section 1: [Main topic]\n",
        "    - Subsection 1.1: [Details]\n",
        "    - Subsection 1.2: [Details]\n",
        "3. Section 2: [Main topic]\n",
        "    - Subsection 2.1: [Details]\n",
        "    - Subsection 2.2: [Details]\n",
        "\n",
        "### Sources\n",
        "- [1] Reference 1\n",
        "- [2] Reference 2\n",
        "- [3] Reference 3\n",
        "\n",
        "**Provided Context:**\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "def write_plan(state: ResearchGraphState):\n",
        "    # Full set of sections\n",
        "    sections = state[\"sections\"]\n",
        "    topic = state[\"topic\"]\n",
        "\n",
        "    # Concat all sections together\n",
        "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
        "\n",
        "    # Write a plan structure for the report\n",
        "    system_message = plan_writer_instructions.format(topic=topic, context=formatted_str_sections)\n",
        "    plan = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Create a Plan for the Report Based on Memos\")])\n",
        "    return {\"plan\": plan.content}\n",
        "\n",
        "\n",
        "# Add nodes and edges\n",
        "builder = StateGraph(ResearchGraphState)\n",
        "builder.add_node(\"create_analysts\", create_analysts)\n",
        "builder.add_node(\"human_feedback\", human_feedback)\n",
        "builder.add_node(\"conduct_interview\", interview_builder.compile())\n",
        "builder.add_node(\"write_plan\",write_plan)\n",
        "builder.add_node(\"write_report\",write_report)\n",
        "builder.add_node(\"write_introduction\",write_introduction)\n",
        "builder.add_node(\"write_conclusion\",write_conclusion)\n",
        "builder.add_node(\"finalize_report\",finalize_report)\n",
        "\n",
        "# Logic\n",
        "builder.add_edge(START, \"create_analysts\")\n",
        "builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
        "builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
        "builder.add_edge(\"conduct_interview\",\"write_plan\")\n",
        "builder.add_edge(\"write_plan\", \"write_report\")\n",
        "builder.add_edge(\"write_plan\", \"write_introduction\")\n",
        "builder.add_edge(\"write_plan\", \"write_conclusion\")\n",
        "builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
        "builder.add_edge(\"finalize_report\", END)\n",
        "\n",
        "# Compile\n",
        "memory = MemorySaver()\n",
        "graph = builder.compile(interrupt_before=['human_feedback'], checkpointer=memory)\n",
        "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QidEdwWbgxhp",
      "metadata": {
        "id": "QidEdwWbgxhp"
      },
      "source": [
        "# Task 3. Suivre le plan et ecrire section par section (avec recherche de texte), enrichir la section avec des nouvelles ressources (rechercher, citer) ou la liste de ressources existantes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mH8Wen8rgxyL",
      "metadata": {
        "id": "mH8Wen8rgxyL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "55c03afc-f513-4277-cdb2-b9b559ccbb0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Introduction - Recherche sur Arxiv\n\n### Article 1\n**Titre :** A Survey on Federated Learning for the Healthcare Metaverse: Concepts,\n  Applications, Challenges, and Future Directions\n\n**Auteurs :** Ali Kashif Bashir, Nancy Victor, Sweta Bhattacharya, Thien Huynh-The, Rajeswari Chengoden, Gokul Yenduri, Praveen Kumar Reddy Maddikunta, Quoc-Viet Pham, Thippa Reddy Gadekallu, Madhusanka Liyanage\n\n**Résumé :** Recent technological advancements have considerately improved healthcare\nsystems to provide various intelligent healthcare services and improve the\nquality of life. Federated learning (FL), a new branch of artificial\nintelligence (AI), opens opportunities to deal with privacy issues in\nhealthcare systems and exploit data and computing resources available at\ndistributed devices. Additionally, the Metaverse, through integrating emerging\ntechnologies, such as AI, cloud edge computing, Internet of Things (IoT),\nblockchain, and semantic communications, has transformed many vertical domains\nin general and the healthcare sector in particular. Obviously, FL shows many\nbenefits and provides new opportunities for conventional and Metaverse\nhealthcare, motivating us to provide a survey on the usage of FL for Metaverse\nhealthcare systems. First, we present preliminaries to IoT-based healthcare\nsystems, FL in conventional healthcare, and Metaverse healthcare. The benefits\nof FL in Metaverse healthcare are then discussed, from improved privacy and\nscalability, better interoperability, better data management, and extra\nsecurity to automation and low-latency healthcare services. Subsequently, we\ndiscuss several applications pertaining to FL-enabled Metaverse healthcare,\nincluding medical diagnosis, patient monitoring, medical education, infectious\ndisease, and drug discovery. Finally, we highlight significant challenges and\npotential solutions toward the realization of FL in Metaverse healthcare.\n\n[Lien vers l'article](http://arxiv.org/abs/2304.00524v2)\n\n### Article 2\n**Titre :** Natural Language Processing for Smart Healthcare\n\n**Auteurs :** Binggui Zhou, Guanghua Yang, Zheng Shi, Shaodan Ma\n\n**Résumé :** Smart healthcare has achieved significant progress in recent years. Emerging\nartificial intelligence (AI) technologies enable various smart applications\nacross various healthcare scenarios. As an essential technology powered by AI,\nnatural language processing (NLP) plays a key role in smart healthcare due to\nits capability of analysing and understanding human language. In this work, we\nreview existing studies that concern NLP for smart healthcare from the\nperspectives of technique and application. We first elaborate on different NLP\napproaches and the NLP pipeline for smart healthcare from the technical point\nof view. Then, in the context of smart healthcare applications employing NLP\ntechniques, we introduce representative smart healthcare scenarios, including\nclinical practice, hospital management, personal care, public health, and drug\ndevelopment. We further discuss two specific medical issues, i.e., the\ncoronavirus disease 2019 (COVID-19) pandemic and mental health, in which\nNLP-driven smart healthcare plays an important role. Finally, we discuss the\nlimitations of current works and identify the directions for future works.\n\n[Lien vers l'article](http://arxiv.org/abs/2110.15803v3)\n\n### Article 3\n**Titre :** Reliable and Resilient AI and IoT-based Personalised Healthcare\n  Services: A Survey\n\n**Auteurs :** Najma Taimoor, Semeen Rehman\n\n**Résumé :** Recent technological and economic developments have transformed the\nhealthcare sector towards more personalized and IoT-based healthcare services.\nThese services are realized through control and monitoring applications that\nare typically developed using artificial intelligence/machine learning-based\nalgorithms, which play a significant role in highlighting the efficiency of\ntraditional healthcare systems. Current personalized healthcare services are\ndedicated to a specific environment to support technological personalization.\nHowever, they are unable to consider different interrelated health conditions,\nleading to inappropriate diagnoses and affecting sustainability and the\nlong-term health of patients. To this end, current Healthcare 5.0 technology\nhas evolved that supersede previous healthcare technologies. The goal of\nhealthcare 5.0 is to achieve an autonomous healthcare service, that takes into\naccount the interdependent effect of different health conditions of a patient.\nThis paper conducts a comprehensive survey on personalized healthcare services.\nIn particular, we first present an overview of key requirements of\ncomprehensive personalized healthcare services in modern healthcare Internet of\nThings (HIoT), including the definition of personalization and an example use\ncase scenario as a representative for modern HIoT. Second, we explored a\nfundamental three-layer architecture for IoT-based healthcare systems using AI\nand non-AI-based approaches, considering key requirements for CPHS followed by\ntheir strengths and weaknesses in the frame of personalized healthcare\nservices. Third, we highlighted different security threats against each layer\nof IoT architecture along with the possible AI and non-AI-based solutions.\nFinally, we propose a methodology to develop reliable, resilient, and\npersonalized healthcare services that address the identified weaknesses of\nexisting approaches.\n\n[Lien vers l'article](http://arxiv.org/abs/2209.05457v1)\n\n### Article 4\n**Titre :** healthAIChain: Improving security and safety using Blockchain Technology\n  applications in AI-based healthcare systems\n\n**Auteurs :** Naresh Kshetri, James Hutson, Revathy G\n\n**Résumé :** Blockchain as a digital ledger for keeping records of digital transactions\nand other information, it is secure and decentralized technology. The globally\ngrowing number of digital population every day possesses a significant threat\nto online data including the medical and patients data. After bitcoin,\nblockchain technology has emerged into a general-purpose technology with\napplications in medical industries and healthcare. Blockchain can promote\nhighly configurable openness while retaining the highest security standards for\ncritical data of medical patients. Referred to as distributed record keeping\nfor healthcare systems which makes digital assets unalterable and transparent\nvia a cryptographic hash and decentralized network. The study delves into the\nsecurity and safety improvement associated with implementing blockchain in\nAI-based healthcare systems. Blockchain-enabled AI tackles the existing issues\nrelated to security, performance efficiencies, and safety in healthcare\nsystems. We have also examined the Artificial Intelligence in healthcare and\nmedical industry, potential areas, open questions concerning the blockchain in\nhealthcare systems. Finally, the article proposed an AI-based healthcare\nblockchain model (healthAIChain) to improve patients data and security.\n\n[Lien vers l'article](http://arxiv.org/abs/2311.00842v1)\n\n### Article 5\n**Titre :** Foundation Model for Advancing Healthcare: Challenges, Opportunities,\n  and Future Directions\n\n**Auteurs :** Yuting He, Fuxiang Huang, Xinrui Jiang, Yuxiang Nie, Minghao Wang, Jiguang Wang, Hao Chen\n\n**Résumé :** Foundation model, which is pre-trained on broad data and is able to adapt to\na wide range of tasks, is advancing healthcare. It promotes the development of\nhealthcare artificial intelligence (AI) models, breaking the contradiction\nbetween limited AI models and diverse healthcare practices. Much more\nwidespread healthcare scenarios will benefit from the development of a\nhealthcare foundation model (HFM), improving their advanced intelligent\nhealthcare services. Despite the impending widespread deployment of HFMs, there\nis currently a lack of clear understanding about how they work in the\nhealthcare field, their current challenges, and where they are headed in the\nfuture. To answer these questions, a comprehensive and deep survey of the\nchallenges, opportunities, and future directions of HFMs is presented in this\nsurvey. It first conducted a comprehensive overview of the HFM including the\nmethods, data, and applications for a quick grasp of the current progress.\nThen, it made an in-depth exploration of the challenges present in data,\nalgorithms, and computing infrastructures for constructing and widespread\napplication of foundation models in healthcare. This survey also identifies\nemerging and promising directions in this field for future development. We\nbelieve that this survey will enhance the community's comprehension of the\ncurrent progress of HFM and serve as a valuable source of guidance for future\ndevelopment in this field. The latest HFM papers and related resources are\nmaintained on our website:\nhttps://github.com/YutingHe-list/Awesome-Foundation-Models-for-Advancing-Healthcare.\n\n[Lien vers l'article](http://arxiv.org/abs/2404.03264v1)\n\n## Introduction - Enrichissement\n\n**Ressources existantes :**\n\n- Livre : Intelligence artificielle et éthique (2020)\n- Article : AI in Healthcare - Opportunities and Risks (2021)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Méthodologie - Recherche sur Arxiv\n\n### Article 1\n**Titre :** Spatial Transfer Learning with Simple MLP\n\n**Auteurs :** Hongjian Yang\n\n**Résumé :** First step to investigate the potential of transfer learning applied to the\nfield of spatial statistics\n\n[Lien vers l'article](http://arxiv.org/abs/2405.03720v1)\n\n### Article 2\n**Titre :** Towards CRISP-ML(Q): A Machine Learning Process Model with Quality\n  Assurance Methodology\n\n**Auteurs :** Stefan Studer, Thanh Binh Bui, Christian Drescher, Alexander Hanuschkin, Ludwig Winkler, Steven Peters, Klaus-Robert Mueller\n\n**Résumé :** Machine learning is an established and frequently used technique in industry\nand academia but a standard process model to improve success and efficiency of\nmachine learning applications is still missing. Project organizations and\nmachine learning practitioners have a need for guidance throughout the life\ncycle of a machine learning application to meet business expectations. We\ntherefore propose a process model for the development of machine learning\napplications, that covers six phases from defining the scope to maintaining the\ndeployed machine learning application. The first phase combines business and\ndata understanding as data availability oftentimes affects the feasibility of\nthe project. The sixth phase covers state-of-the-art approaches for monitoring\nand maintenance of a machine learning applications, as the risk of model\ndegradation in a changing environment is eminent. With each task of the\nprocess, we propose quality assurance methodology that is suitable to adress\nchallenges in machine learning development that we identify in form of risks.\nThe methodology is drawn from practical experience and scientific literature\nand has proven to be general and stable. The process model expands on CRISP-DM,\na data mining process model that enjoys strong industry support but lacks to\naddress machine learning specific tasks. Our work proposes an industry and\napplication neutral process model tailored for machine learning applications\nwith focus on technical tasks for quality assurance.\n\n[Lien vers l'article](http://arxiv.org/abs/2003.05155v2)\n\n### Article 3\n**Titre :** Security of Deep Learning Methodologies: Challenges and Opportunities\n\n**Auteurs :** Shahbaz Rezaei, Xin Liu\n\n**Résumé :** Despite the plethora of studies about security vulnerabilities and defenses\nof deep learning models, security aspects of deep learning methodologies, such\nas transfer learning, have been rarely studied. In this article, we highlight\nthe security challenges and research opportunities of these methodologies,\nfocusing on vulnerabilities and attacks unique to them.\n\n[Lien vers l'article](http://arxiv.org/abs/1912.03735v1)\n\n### Article 4\n**Titre :** Comments on: \"Hybrid Semiparametric Bayesian Networks\"\n\n**Auteurs :** Marco Scutari\n\n**Résumé :** Invited discussion on the paper \"Hybrid Semiparametric Bayesian Networks\" by\nDavid Atienza, Pedro Larranaga and Concha Bielza (TEST, 2022).\n\n[Lien vers l'article](http://arxiv.org/abs/2205.05910v1)\n\n### Article 5\n**Titre :** Empirical and Experimental Insights into Data Mining Techniques for\n  Crime Prediction: A Comprehensive Survey\n\n**Auteurs :** Kamal Taha\n\n**Résumé :** This survey paper presents a comprehensive analysis of crime prediction\nmethodologies, exploring the various techniques and technologies utilized in\nthis area. The paper covers the statistical methods, machine learning\nalgorithms, and deep learning techniques employed to analyze crime data, while\nalso examining their effectiveness and limitations. We propose a methodological\ntaxonomy that classifies crime prediction algorithms into specific techniques.\nThis taxonomy is structured into four tiers, including methodology category,\nmethodology sub-category, methodology techniques, and methodology\nsub-techniques. Empirical and experimental evaluations are provided to rank the\ndifferent techniques. The empirical evaluation assesses the crime prediction\ntechniques based on four criteria, while the experimental evaluation ranks the\nalgorithms that employ the same sub-technique, the different sub-techniques\nthat employ the same technique, the different techniques that employ the same\nmethodology sub-category, the different methodology sub-categories within the\nsame category, and the different methodology categories. The combination of\nmethodological taxonomy, empirical evaluations, and experimental comparisons\nallows for a nuanced and comprehensive understanding of crime prediction\nalgorithms, aiding researchers in making informed decisions. Finally, the paper\nprovides a glimpse into the future of crime prediction techniques, highlighting\npotential advancements and opportunities for further research in this field\n\n[Lien vers l'article](http://arxiv.org/abs/2403.00780v1)\n\n## Méthodologie - Enrichissement\n\n**Ressources existantes :**\n\n- Livre : Intelligence artificielle et éthique (2020)\n- Article : AI in Healthcare - Opportunities and Risks (2021)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Applications de l'IA - Recherche sur Arxiv\n\n### Article 1\n**Titre :** AI Thinking: A framework for rethinking artificial intelligence in\n  practice\n\n**Auteurs :** Denis Newman-Griffis\n\n**Résumé :** Artificial intelligence is transforming the way we work with information\nacross disciplines and practical contexts. A growing range of disciplines are\nnow involved in studying, developing, and assessing the use of AI in practice,\nbut these disciplines often employ conflicting understandings of what AI is and\nwhat is involved in its use. New, interdisciplinary approaches are needed to\nbridge competing conceptualisations of AI in practice and help shape the future\nof AI use. I propose a novel conceptual framework called AI Thinking, which\nmodels key decisions and considerations involved in AI use across disciplinary\nperspectives. The AI Thinking model addresses five practice-based competencies\ninvolved in applying AI in context: motivating AI use in information processes,\nformulating AI methods, assessing available tools and technologies, selecting\nappropriate data, and situating AI in the sociotechnical contexts it is used\nin. A hypothetical case study is provided to illustrate the application of AI\nThinking in practice. This article situates AI Thinking in broader\ncross-disciplinary discourses of AI, including its connections to ongoing\ndiscussions around AI literacy and AI-driven innovation. AI Thinking can help\nto bridge divides between academic disciplines and diverse contexts of AI use,\nand to reshape the future of AI in practice.\n\n[Lien vers l'article](http://arxiv.org/abs/2409.12922v1)\n\n### Article 2\n**Titre :** Towards Enterprise-Ready AI Deployments Minimizing the Risk of Consuming\n  AI Models in Business Applications\n\n**Auteurs :** Aleksander Slominski, Vinod Muthusamy, Vatche Ishakian\n\n**Résumé :** The stochastic nature of artificial intelligence (AI) models introduces risk\nto business applications that use AI models without careful consideration. This\npaper offers an approach to use AI techniques to gain insights on the usage of\nthe AI models and control how they are deployed to a production application.\n  Keywords: artificial intelligence (AI), machine learning, microservices,\nbusiness process\n\n[Lien vers l'article](http://arxiv.org/abs/1906.10418v1)\n\n### Article 3\n**Titre :** AI-in-the-Loop -- The impact of HMI in AI-based Application\n\n**Auteurs :** Julius Schöning, Clemens Westerkamp\n\n**Résumé :** Artificial intelligence (AI) and human-machine interaction (HMI) are two\nkeywords that usually do not fit embedded applications. Within the steps needed\nbefore applying AI to solve a specific task, HMI is usually missing during the\nAI architecture design and the training of an AI model. The human-in-the-loop\nconcept is prevalent in all other steps of developing AI, from data analysis\nvia data selection and cleaning to performance evaluation. During AI\narchitecture design, HMI can immediately highlight unproductive layers of the\narchitecture so that lightweight network architecture for embedded applications\ncan be created easily. We show that by using this HMI, users can instantly\ndistinguish which AI architecture should be trained and evaluated first since a\nhigh accuracy on the task could be expected. This approach reduces the\nresources needed for AI development by avoiding training and evaluating AI\narchitectures with unproductive layers and leads to lightweight AI\narchitectures. These resulting lightweight AI architectures will enable HMI\nwhile running the AI on an edge device. By enabling HMI during an AI uses\ninference, we will introduce the AI-in-the-loop concept that combines AI's and\nhumans' strengths. In our AI-in-the-loop approach, the AI remains the working\nhorse and primarily solves the task. If the AI is unsure whether its inference\nsolves the task correctly, it asks the user to use an appropriate HMI.\nConsequently, AI will become available in many applications soon since HMI will\nmake AI more reliable and explainable.\n\n[Lien vers l'article](http://arxiv.org/abs/2303.11508v1)\n\n### Article 4\n**Titre :** Navigating Fairness: Practitioners' Understanding, Challenges, and\n  Strategies in AI/ML Development\n\n**Auteurs :** Aastha Pant, Rashina Hoda, Chakkrit Tantithamthavorn, Burak Turhan\n\n**Résumé :** The rise in the use of AI/ML applications across industries has sparked more\ndiscussions about the fairness of AI/ML in recent times. While prior research\non the fairness of AI/ML exists, there is a lack of empirical studies focused\non understanding the perspectives and experiences of AI practitioners in\ndeveloping a fair AI/ML system. Understanding AI practitioners' perspectives\nand experiences on the fairness of AI/ML systems are important because they are\ndirectly involved in its development and deployment and their insights can\noffer valuable real-world perspectives on the challenges associated with\nensuring fairness in AI/ML systems. We conducted semi-structured interviews\nwith 22 AI practitioners to investigate their understanding of what a 'fair\nAI/ML' is, the challenges they face in developing a fair AI/ML system, the\nconsequences of developing an unfair AI/ML system, and the strategies they\nemploy to ensure AI/ML system fairness. We developed a framework showcasing the\nrelationship between AI practitioners' understanding of 'fair AI/ML' system and\n(i) their challenges in its development, (ii) the consequences of developing an\nunfair AI/ML system, and (iii) strategies used to ensure AI/ML system fairness.\nBy exploring AI practitioners' perspectives and experiences, this study\nprovides actionable insights to enhance AI/ML fairness, which may promote\nfairer systems, reduce bias, and foster public trust in AI technologies.\nAdditionally, we also identify areas for further investigation and offer\nrecommendations to aid AI practitioners and AI companies in navigating\nfairness.\n\n[Lien vers l'article](http://arxiv.org/abs/2403.15481v2)\n\n### Article 5\n**Titre :** Understanding Mental Models of AI through Player-AI Interaction\n\n**Auteurs :** Jennifer Villareale, Jichen Zhu\n\n**Résumé :** Designing human-centered AI-driven applications require deep understandings\nof how people develop mental models of AI. Currently, we have little knowledge\nof this process and limited tools to study it. This paper presents the position\nthat AI-based games, particularly the player-AI interaction component, offer an\nideal domain to study the process in which mental models evolve. We present a\ncase study to illustrate the benefits of our approach for explainable AI.\n\n[Lien vers l'article](http://arxiv.org/abs/2103.16168v1)\n\n## Applications de l'IA - Enrichissement\n\n**Ressources existantes :**\n\n- Livre : Intelligence artificielle et éthique (2020)\n- Article : AI in Healthcare - Opportunities and Risks (2021)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Enjeux éthiques - Recherche sur Arxiv\n\n### Article 1\n**Titre :** AI Ethics in Smart Homes: Progress, User Requirements and Challenges\n\n**Auteurs :** Liqian You, Jianlong Zhou, Zhiwei Li, Fang Chen\n\n**Résumé :** With the rise of Internet of Things (IoT) technologies in smart homes and the\nintegration of artificial intelligence (AI), ethical concerns have become\nincreasingly significant. This paper explores the ethical implications of\nAI-driven detection technologies in smart homes using the User Requirements\nNotation (URN) framework. In this paper, we thoroughly conduct thousands of\nrelated works from 1985 to 2024 to identify key trends in AI ethics, algorithm\nmethods, and technological advancements. The study presents an overview of\nsmart home and AI ethics, comparing traditional and AI-specific ethical issues,\nand provides guidelines for ethical design across areas like privacy, fairness,\ntransparency, accountability, and user autonomy, offering insights for\ndevelopers and researchers in smart homes.\n\n[Lien vers l'article](http://arxiv.org/abs/2412.09813v1)\n\n### Article 2\n**Titre :** Delegating Responsibilities to Intelligent Autonomous Systems:\n  Challenges and Benefits\n\n**Auteurs :** Gordana Dodig-Crnkovic, Gianfranco Basti, Tobias Holstein\n\n**Résumé :** As AI systems increasingly operate with autonomy and adaptability, the\ntraditional boundaries of moral responsibility in techno-social systems are\nbeing challenged. This paper explores the evolving discourse on the delegation\nof responsibilities to intelligent autonomous agents and the ethical\nimplications of such practices. Synthesizing recent developments in AI ethics,\nincluding concepts of distributed responsibility and ethical AI by design, the\npaper proposes a functionalist perspective as a framework. This perspective\nviews moral responsibility not as an individual trait but as a role within a\nsocio-technical system, distributed among human and artificial agents. As an\nexample of 'AI ethical by design,' we present Basti and Vitiello's\nimplementation. They suggest that AI can act as artificial moral agents by\nlearning ethical guidelines and using Deontic Higher-Order Logic to assess\ndecisions ethically. Motivated by the possible speed and scale beyond human\nsupervision and ethical implications, the paper argues for 'AI ethical by\ndesign', while acknowledging the distributed, shared, and dynamic nature of\nresponsibility. This functionalist approach offers a practical framework for\nnavigating the complexities of AI ethics in a rapidly evolving technological\nlandscape.\n\n[Lien vers l'article](http://arxiv.org/abs/2411.15147v1)\n\n### Article 3\n**Titre :** Ethics of AI: A Systematic Literature Review of Principles and\n  Challenges\n\n**Auteurs :** Arif Ali Khan, Sher Badshah, Peng Liang, Bilal Khan, Muhammad Waseem, Mahmood Niazi, Muhammad Azeem Akbar\n\n**Résumé :** Ethics in AI becomes a global topic of interest for both policymakers and\nacademic researchers. In the last few years, various research organizations,\nlawyers, think tankers and regulatory bodies get involved in developing AI\nethics guidelines and principles. However, there is still debate about the\nimplications of these principles. We conducted a systematic literature review\n(SLR) study to investigate the agreement on the significance of AI principles\nand identify the challenging factors that could negatively impact the adoption\nof AI ethics principles. The results reveal that the global convergence set\nconsists of 22 ethical principles and 15 challenges. Transparency, privacy,\naccountability and fairness are identified as the most common AI ethics\nprinciples. Similarly, lack of ethical knowledge and vague principles are\nreported as the significant challenges for considering ethics in AI. The\nfindings of this study are the preliminary inputs for proposing a maturity\nmodel that assess the ethical capabilities of AI systems and provide best\npractices for further improvements.\n\n[Lien vers l'article](http://arxiv.org/abs/2109.07906v1)\n\n### Article 4\n**Titre :** Survey on AI Ethics: A Socio-technical Perspective\n\n**Auteurs :** Dave Mbiazi, Meghana Bhange, Maryam Babaei, Ivaxi Sheth, Patrik Joslin Kenfack\n\n**Résumé :** The past decade has observed a great advancement in AI with deep\nlearning-based models being deployed in diverse scenarios including\nsafety-critical applications. As these AI systems become deeply embedded in our\nsocietal infrastructure, the repercussions of their decisions and actions have\nsignificant consequences, making the ethical implications of AI deployment\nhighly relevant and important. The ethical concerns associated with AI are\nmultifaceted, including challenging issues of fairness, privacy and data\nprotection, responsibility and accountability, safety and robustness,\ntransparency and explainability, and environmental impact. These principles\ntogether form the foundations of ethical AI considerations that concern every\nstakeholder in the AI system lifecycle. In light of the present ethical and\nfuture x-risk concerns, governments have shown increasing interest in\nestablishing guidelines for the ethical deployment of AI. This work unifies the\ncurrent and future ethical concerns of deploying AI into society. While we\nacknowledge and appreciate the technical surveys for each of the ethical\nprinciples concerned, in this paper, we aim to provide a comprehensive overview\nthat not only addresses each principle from a technical point of view but also\ndiscusses them from a social perspective.\n\n[Lien vers l'article](http://arxiv.org/abs/2311.17228v1)\n\n### Article 5\n**Titre :** Ever heard of ethical AI? Investigating the salience of ethical AI\n  issues among the German population\n\n**Auteurs :** Kimon Kieslich, Marco Lünich, Pero Došenović\n\n**Résumé :** Building and implementing ethical AI systems that benefit the whole society\nis cost-intensive and a multi-faceted task fraught with potential problems.\nWhile computer science focuses mostly on the technical questions to mitigate\nsocial issues, social science addresses citizens' perceptions to elucidate\nsocial and political demands that influence the societal implementation of AI\nsystems. Thus, in this study, we explore the salience of AI issues in the\npublic with an emphasis on ethical criteria to investigate whether it is likely\nthat ethical AI is actively requested by the population. Between May 2020 and\nApril 2021, we conducted 15 surveys asking the German population about the most\nimportant AI-related issues (total of N=14,988 respondents). Our results show\nthat the majority of respondents were not concerned with AI at all. However, it\ncan be seen that general interest in AI and a higher educational level are\npredictive of some engagement with AI. Among those, who reported having thought\nabout AI, specific applications (e.g., autonomous driving) were by far the most\nmentioned topics. Ethical issues are voiced only by a small subset of citizens\nwith fairness, accountability, and transparency being the least mentioned ones.\nThese have been identified in several ethical guidelines (including the EU\nCommission's proposal) as key elements for the development of ethical AI. The\nsalience of ethical issues affects the behavioral intentions of citizens in the\nway that they 1) tend to avoid AI technology and 2) engage in public\ndiscussions about AI. We conclude that the low level of ethical implications\nmay pose a serious problem for the actual implementation of ethical AI for the\nCommon Good and emphasize that those who are presumably most affected by\nethical issues of AI are especially unaware of ethical risks. Yet, once ethical\nAI is top of the mind, there is some potential for activism.\n\n[Lien vers l'article](http://arxiv.org/abs/2207.14086v1)\n\n## Enjeux éthiques - Enrichissement\n\n**Ressources existantes :**\n\n- Livre : Intelligence artificielle et éthique (2020)\n- Article : AI in Healthcare - Opportunities and Risks (2021)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Impact de l'IA sur les métiers - Recherche sur Arxiv\n\n### Article 1\n**Titre :** Towards the Terminator Economy: Assessing Job Exposure to AI through\n  LLMs\n\n**Auteurs :** Emilio Colombo, Fabio Mercorio, Mario Mezzanzanica, Antonio Serino\n\n**Résumé :** The spread and rapid development of AI-related technologies are influencing\nmany aspects of our daily lives, from social to educational, including the\nlabour market. Many researchers have been highlighting the key role AI and\ntechnologies play in reshaping jobs and their related tasks, either by\nautomating or enhancing human capabilities in the workplace. Can we estimate\nif, and to what extent, jobs and related tasks are exposed to the risk of being\nautomatized by state-of-the-art AI-related technologies? Our work tackles this\nquestion through a data-driven approach: (i) developing a reproducible\nframework that exploits a battery of open-source Large Language Models to\nassess current AI and robotics' capabilities in performing job-related tasks;\n(ii) formalising and computing an AI exposure measure by occupation, namely the\nteai (Task Exposure to AI) index. Our results show that about one-third of U.S.\nemployment is highly exposed to AI, primarily in high-skill jobs (aka, white\ncollars). This exposure correlates positively with employment and wage growth\nfrom 2019 to 2023, indicating a beneficial impact of AI on productivity. The\nsource codes and results are publicly available, enabling the whole community\nto benchmark and track AI and technology capabilities over time.\n\n[Lien vers l'article](http://arxiv.org/abs/2407.19204v1)\n\n### Article 2\n**Titre :** Generative AI Impact on Labor Market: Analyzing ChatGPT's Demand in Job\n  Advertisements\n\n**Auteurs :** Mahdi Ahmadi, Neda Khosh Kheslat, Adebola Akintomide\n\n**Résumé :** The rapid advancement of Generative AI (Gen AI) technologies, particularly\ntools like ChatGPT, is significantly impacting the labor market by reshaping\njob roles and skill requirements. This study examines the demand for\nChatGPT-related skills in the U.S. labor market by analyzing job advertisements\ncollected from major job platforms between May and December 2023. Using text\nmining and topic modeling techniques, we extracted and analyzed the Gen\nAI-related skills that employers are hiring for. Our analysis identified five\ndistinct ChatGPT-related skill sets: general familiarity, creative content\ngeneration, marketing, advanced functionalities (such as prompt engineering),\nand product development. In addition, the study provides insights into job\nattributes such as occupation titles, degree requirements, salary ranges, and\nother relevant job characteristics. These findings highlight the increasing\nintegration of Gen AI across various industries, emphasizing the growing need\nfor both foundational knowledge and advanced technical skills. The study offers\nvaluable insights into the evolving demands of the labor market, as employers\nseek candidates equipped to leverage generative AI tools to improve\nproductivity, streamline processes, and drive innovation.\n\n[Lien vers l'article](http://arxiv.org/abs/2412.07042v1)\n\n### Article 3\n**Titre :** The Impact of AI on Perceived Job Decency and Meaningfulness: A Case\n  Study\n\n**Auteurs :** Kuntal Ghosh, Shadan Sadeghian\n\n**Résumé :** The proliferation of Artificial Intelligence (AI) in workplaces stands to\nchange the way humans work, with job satisfaction intrinsically linked to work\nlife. Existing research on human-AI collaboration tends to prioritize\nperformance over the experiential aspects of work. In contrast, this paper\nexplores the impact of AI on job decency and meaningfulness in workplaces.\nThrough interviews in the Information Technology (IT) domain, we not only\nexamined the current work environment, but also explored the perceived\nevolution of the workplace ecosystem with the introduction of an AI. Findings\nfrom the preliminary exploratory study reveal that respondents tend to\nvisualize a workplace where humans continue to play a dominant role, even with\nthe introduction of advanced AIs. In this prospective scenario, AI is seen as\nserving as a complement rather than replacing the human workforce. Furthermore,\nrespondents believe that the introduction of AI will maintain or potentially\nincrease overall job satisfaction.\n\n[Lien vers l'article](http://arxiv.org/abs/2406.14273v2)\n\n### Article 4\n**Titre :** Employee Well-being in the Age of AI: Perceptions, Concerns, Behaviors,\n  and Outcomes\n\n**Auteurs :** Soheila Sadeghi\n\n**Résumé :** The growing integration of Artificial Intelligence (AI) into Human Resources\n(HR) processes has transformed the way organizations manage recruitment,\nperformance evaluation, and employee engagement. While AI offers numerous\nadvantages, such as improved efficiency, reduced bias, and\nhyper-personalization, it raises significant concerns about employee\nwell-being, job security, fairness, and transparency. This study examines how\nAI shapes employee perceptions, job satisfaction, mental health, and retention.\nKey findings reveal that while AI can enhance efficiency and reduce bias, it\nalso raises concerns about job security, fairness, and privacy. Transparency in\nAI systems emerges as a critical factor in fostering trust and positive\nemployee attitudes. AI systems can both support and undermine employee\nwell-being, depending on how they are implemented and perceived. The research\nintroduces an AI-employee well-being Interaction Framework, illustrating how AI\ninfluences employee perceptions, behaviors, and outcomes. Organizational\nstrategies, such as clear communication, upskilling programs, and employee\ninvolvement in AI implementation, are identified as crucial for mitigating\nnegative impacts and enhancing positive outcomes. The study concludes that the\nsuccessful integration of AI in HR requires a balanced approach that\nprioritizes employee well-being, facilitates human-AI collaboration, and\nensures ethical and transparent AI practices alongside technological\nadvancement.\n\n[Lien vers l'article](http://arxiv.org/abs/2412.04796v1)\n\n### Article 5\n**Titre :** The Global Impact of AI-Artificial Intelligence: Recent Advances and\n  Future Directions, A Review\n\n**Auteurs :** Chandregowda Pachegowda\n\n**Résumé :** Artificial intelligence (AI) is an emerging technology that has the potential\nto transform many aspects of society, including the economy, healthcare, and\ntransportation. This article synthesizes recent research literature on the\nglobal impact of AI, exploring its potential benefits and risks. The article\nhighlights the implications of AI, including its impact on economic, ethical,\nsocial, security & privacy, and job displacement aspects. It discusses the\nethical concerns surrounding AI development, including issues of bias,\nsecurity, and privacy violations. To ensure the responsible development and\ndeployment of AI, collaboration between government, industry, and academia is\nessential. The article concludes by emphasizing the importance of public\nengagement and education to promote awareness and understanding of AI's impact\non society at large.\n\n[Lien vers l'article](http://arxiv.org/abs/2401.12223v1)\n\n## Impact de l'IA sur les métiers - Enrichissement\n\n**Ressources existantes :**\n\n- Livre : Intelligence artificielle et éthique (2020)\n- Article : AI in Healthcare - Opportunities and Risks (2021)\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Conclusion - Recherche sur Arxiv\n\n### Article 1\n**Titre :** The case for psychometric artificial general intelligence\n\n**Auteurs :** Mark McPherson\n\n**Résumé :** A short review of the literature on measurement and detection of artificial\ngeneral intelligence is made. Proposed benchmarks and tests for artificial\ngeneral intelligence are critically evaluated against multiple criteria. Based\non the findings, the most promising approaches are identified and some useful\ndirections for future work are proposed.\n\n[Lien vers l'article](http://arxiv.org/abs/2101.02179v1)\n\n### Article 2\n**Titre :** Intelligence of Astronomical Optical Telescope: Present Status and\n  Future Perspectives\n\n**Auteurs :** Kang Huang, Tianzhu Hu, Jingyi Cai, Xiushan Pang, Yonghui Hou, Yong Zhang, Huaiqing Wang, Xiangqun Cui\n\n**Résumé :** Artificial intelligence technology has been widely used in astronomy, and new\nartificial intelligence technologies and application scenarios are constantly\nemerging. There have been a large number of papers reviewing the application of\nartificial intelligence technology in astronomy. However, relevant articles\nseldom mention telescope intelligence separately, and it is difficult to\nunderstand the current development status and research hotspots of telescope\nintelligence from these papers. This paper combines the development history of\nartificial intelligence technology and the difficulties of critical\ntechnologies of telescopes, comprehensively introduces the development and\nresearch hotspots of telescope intelligence, then conducts statistical analysis\non various research directions of telescope intelligence and defines the\nresearch directions' merits. All kinds of research directions are evaluated,\nand the research trend of each telescope's intelligence is pointed out.\nFinally, according to the advantages of artificial intelligence technology and\nthe development trend of telescopes, future research hotspots of telescope\nintelligence are given.\n\n[Lien vers l'article](http://arxiv.org/abs/2306.16834v2)\n\n### Article 3\n**Titre :** Comprehensible Artificial Intelligence on Knowledge Graphs: A survey\n\n**Auteurs :** Simon Schramm, Christoph Wehner, Ute Schmid\n\n**Résumé :** Artificial Intelligence applications gradually move outside the safe walls of\nresearch labs and invade our daily lives. This is also true for Machine\nLearning methods on Knowledge Graphs, which has led to a steady increase in\ntheir application since the beginning of the 21st century. However, in many\napplications, users require an explanation of the Artificial Intelligences\ndecision. This led to increased demand for Comprehensible Artificial\nIntelligence. Knowledge Graphs epitomize fertile soil for Comprehensible\nArtificial Intelligence, due to their ability to display connected data, i.e.\nknowledge, in a human- as well as machine-readable way. This survey gives a\nshort history to Comprehensible Artificial Intelligence on Knowledge Graphs.\nFurthermore, we contribute by arguing that the concept Explainable Artificial\nIntelligence is overloaded and overlapping with Interpretable Machine Learning.\nBy introducing the parent concept Comprehensible Artificial Intelligence, we\nprovide a clear-cut distinction of both concepts while accounting for their\nsimilarities. Thus, we provide in this survey a case for Comprehensible\nArtificial Intelligence on Knowledge Graphs consisting of Interpretable Machine\nLearning on Knowledge Graphs and Explainable Artificial Intelligence on\nKnowledge Graphs. This leads to the introduction of a novel taxonomy for\nComprehensible Artificial Intelligence on Knowledge Graphs. In addition, a\ncomprehensive overview of the research on Comprehensible Artificial\nIntelligence on Knowledge Graphs is presented and put into the context of the\ntaxonomy. Finally, research gaps in the field of Comprehensible Artificial\nIntelligence on Knowledge Graphs are identified for future research.\n\n[Lien vers l'article](http://arxiv.org/abs/2404.03499v1)\n\n### Article 4\n**Titre :** Human-in-the-loop Artificial Intelligence\n\n**Auteurs :** Fabio Massimo Zanzotto\n\n**Résumé :** Little by little, newspapers are revealing the bright future that Artificial\nIntelligence (AI) is building. Intelligent machines will help everywhere.\nHowever, this bright future has a dark side: a dramatic job market contraction\nbefore its unpredictable transformation. Hence, in a near future, large numbers\nof job seekers will need financial support while catching up with these novel\nunpredictable jobs. This possible job market crisis has an antidote inside. In\nfact, the rise of AI is sustained by the biggest knowledge theft of the recent\nyears. Learning AI machines are extracting knowledge from unaware skilled or\nunskilled workers by analyzing their interactions. By passionately doing their\njobs, these workers are digging their own graves.\n  In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI)\nas a fairer paradigm for Artificial Intelligence systems. HIT-AI will reward\naware and unaware knowledge producers with a different scheme: decisions of AI\nsystems generating revenues will repay the legitimate owners of the knowledge\nused for taking those decisions. As modern Robin Hoods, HIT-AI researchers\nshould fight for a fairer Artificial Intelligence that gives back what it\nsteals.\n\n[Lien vers l'article](http://arxiv.org/abs/1710.08191v1)\n\n### Article 5\n**Titre :** Integrating Generative Artificial Intelligence in Intelligent Vehicle\n  Systems\n\n**Auteurs :** Lukas Stappen, Jeremy Dillmann, Serena Striegel, Hans-Jörg Vögel, Nicolas Flores-Herr, Björn W. Schuller\n\n**Résumé :** This paper aims to serve as a comprehensive guide for researchers and\npractitioners, offering insights into the current state, potential\napplications, and future research directions for generative artificial\nintelligence and foundation models within the context of intelligent vehicles.\nAs the automotive industry progressively integrates AI, generative artificial\nintelligence technologies hold the potential to revolutionize user\ninteractions, delivering more immersive, intuitive, and personalised in-car\nexperiences. We provide an overview of current applications of generative\nartificial intelligence in the automotive domain, emphasizing speech, audio,\nvision, and multimodal interactions. We subsequently outline critical future\nresearch areas, including domain adaptability, alignment, multimodal\nintegration and others, as well as, address the challenges and risks associated\nwith ethics. By fostering collaboration and addressing these research areas,\ngenerative artificial intelligence can unlock its full potential, transforming\nthe driving experience and shaping the future of intelligent vehicles.\n\n[Lien vers l'article](http://arxiv.org/abs/2305.17137v1)\n\n## Conclusion - Enrichissement\n\n**Ressources existantes :**\n\n- Livre : Intelligence artificielle et éthique (2020)\n- Article : AI in Healthcare - Opportunities and Risks (2021)\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import requests\n",
        "from xml.etree import ElementTree as ET\n",
        "from IPython.display import Markdown, display\n",
        "\n",
        "# Recherche sur Arxiv\n",
        "def search_arxiv(query, max_results=5):\n",
        "    base_url = \"http://export.arxiv.org/api/query?\"\n",
        "    search_query = f\"search_query={query}&start=0&max_results={max_results}&sortBy=relevance&sortOrder=descending\"\n",
        "    url = base_url + search_query\n",
        "\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        print(\"Erreur lors de la recherche.\")\n",
        "        return None\n",
        "\n",
        "# Fonction pour parser la réponse XML d'Arxiv et extraire les articles\n",
        "def parse_arxiv_response(xml_response):\n",
        "    root = ET.fromstring(xml_response)\n",
        "    entries = root.findall('{http://www.w3.org/2005/Atom}entry')\n",
        "\n",
        "    articles = []\n",
        "    for entry in entries:\n",
        "        title = entry.find('{http://www.w3.org/2005/Atom}title').text.strip()\n",
        "        authors = [author.find('{http://www.w3.org/2005/Atom}name').text.strip() for author in entry.findall('{http://www.w3.org/2005/Atom}author')]\n",
        "        summary = entry.find('{http://www.w3.org/2005/Atom}summary').text.strip()\n",
        "        link = entry.find('{http://www.w3.org/2005/Atom}id').text.strip()\n",
        "\n",
        "        article = {\n",
        "            'title': title,\n",
        "            'authors': authors,\n",
        "            'summary': summary,\n",
        "            'link': link\n",
        "        }\n",
        "        articles.append(article)\n",
        "    return articles\n",
        "\n",
        "# pour avoir une section avec une liste de ressources existantes\n",
        "def enrich_section_with_resources(section_name, existing_resources=None):\n",
        "    markdown = f\"## {section_name} - Enrichissement\\n\\n\"\n",
        "\n",
        "    if existing_resources:\n",
        "        markdown += \"**Ressources existantes :**\\n\\n\"\n",
        "        for resource in existing_resources:\n",
        "            markdown += f\"- {resource}\\n\"\n",
        "    else:\n",
        "        markdown += \"Aucune ressource existante fournie.\\n\\n\"\n",
        "\n",
        "    return markdown\n",
        "\n",
        "# Pour generer une section Markdown\n",
        "def generate_section_markdown(section_name, query, max_results=5, existing_resources=None):\n",
        "    markdown = f\"## {section_name} - Recherche sur Arxiv\\n\\n\"\n",
        "    xml_response = search_arxiv(query, max_results)\n",
        "\n",
        "    if xml_response:\n",
        "        articles = parse_arxiv_response(xml_response)\n",
        "        for i, article in enumerate(articles, 1):\n",
        "            markdown += f\"### Article {i}\\n\"\n",
        "            markdown += f\"**Titre :** {article['title']}\\n\\n\"\n",
        "            markdown += f\"**Auteurs :** {', '.join(article['authors'])}\\n\\n\"\n",
        "            markdown += f\"**Résumé :** {article['summary']}\\n\\n\"\n",
        "            markdown += f\"[Lien vers l'article]({article['link']})\\n\\n\"\n",
        "    else:\n",
        "        markdown += \"Aucun article trouvé.\\n\\n\"\n",
        "\n",
        "    # Ajout dees ressources existantes\n",
        "    markdown += enrich_section_with_resources(section_name, existing_resources)\n",
        "    return markdown\n",
        "\n",
        "\n",
        "sections = {\n",
        "        \"Introduction\": \"artificial intelligence applications healthcare\",\n",
        "        \"Méthodologie\": \"machine learning methodology\",\n",
        "        \"Applications de l'IA\": \"AI applications\",\n",
        "        \"Enjeux éthiques\": \"ethical implications of AI\",\n",
        "        \"Impact de l'IA sur les métiers\": \"impact of AI on jobs\",\n",
        "        \"Conclusion\": \"future of artificial intelligence\"\n",
        "    }\n",
        "\n",
        "existing_resources_example = [\n",
        "        \"Livre : Intelligence artificielle et éthique (2020)\",\n",
        "        \"Article : AI in Healthcare - Opportunities and Risks (2021)\"\n",
        "    ]\n",
        "for section_name, query in sections.items():\n",
        "        markdown_output = generate_section_markdown(section_name, query, existing_resources=existing_resources_example)\n",
        "        display(Markdown(markdown_output))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XkEkHrCLgx6H",
      "metadata": {
        "id": "XkEkHrCLgx6H"
      },
      "source": [
        "# Task 4. Evolution agent de génération du plan: à chaque (n) section validée, évaluer si le plan du document devrait être amélioré sachant la dernière section écrite, si oui l'améliorer, puis continer le développement des sections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "w8gYqRhxgyC0",
      "metadata": {
        "id": "w8gYqRhxgyC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f61abc-0449-4898-c8c9-fb1e63bd99ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Section 1 validée : Introduction\n",
            "\n",
            " Continuer avec la section 2: État de l'art\n",
            "\n",
            " Section 2 validée : État de l'art\n",
            "\n",
            "\n",
            " Réévaluation du plan...\n",
            "Plan mis à jour : {1: 'Introduction', 2: \"État de l'art\", 3: 'Méthodologie', 4: 'Résultats', 5: 'Conclusion'} \n",
            "\n",
            " Continuer avec la section 3: Méthodologie\n",
            "\n",
            " Section 3 validée : Méthodologie\n",
            "\n",
            " Continuer avec la section 4: Résultats\n",
            "\n"
          ]
        }
      ],
      "source": [
        "class DynamicPlanManager:\n",
        "    def __init__(self, initial_plan, eval_interval=3):\n",
        "        self.plan = initial_plan  # Dictionnaire {numéro: titre}\n",
        "        self.sections_written = {}\n",
        "        self.eval_interval = eval_interval\n",
        "\n",
        "    def add_section(self, section_number, content):\n",
        "        \"\"\"Ajoute une section validée et évalue si le plan doit être mis à jour.\"\"\"\n",
        "        self.sections_written[section_number] = content\n",
        "        print(f\" Section {section_number} validée : {self.plan.get(section_number, 'Nouvelle section')}\\n\")\n",
        "\n",
        "        # Vérifier si une réévaluation du plan est nécessaire\n",
        "        if len(self.sections_written) % self.eval_interval == 0:\n",
        "            self.evaluate_plan()\n",
        "\n",
        "        # Continuer l'écriture après évaluation\n",
        "        self.continue_writing()\n",
        "\n",
        "    def evaluate_plan(self):\n",
        "        \"\"\"Évalue et améliore le plan en fonction des sections validées.\"\"\"\n",
        "        print(\"\\n Réévaluation du plan...\")\n",
        "        last_section_num = max(self.sections_written.keys())\n",
        "        last_content = self.sections_written[last_section_num]\n",
        "\n",
        "        # Exemple d'amélioration du plan en fonction du contenu écrit\n",
        "        if \"nouveau sujet\" in last_content.lower():\n",
        "            new_section_num = max(self.plan.keys()) + 1\n",
        "            self.plan[new_section_num] = \"Nouvelle section sur un sujet émergent\"\n",
        "            print(f\" Ajout d'une nouvelle section {new_section_num}: {self.plan[new_section_num]}\")\n",
        "\n",
        "        print(\"Plan mis à jour :\", self.plan, \"\\n\")\n",
        "\n",
        "    def continue_writing(self):\n",
        "        \"\"\"Poursuit le développement des sections en fonction du plan mis à jour.\"\"\"\n",
        "        remaining_sections = [s for s in self.plan.keys() if s not in self.sections_written]\n",
        "        if remaining_sections:\n",
        "            next_section = min(remaining_sections)\n",
        "            print(f\" Continuer avec la section {next_section}: {self.plan[next_section]}\\n\")\n",
        "        else:\n",
        "            print(\"Toutes les sections sont complétées !\")\n",
        "\n",
        "# Exemple d'utilisation\n",
        "initial_plan = {\n",
        "    1: \"Introduction\",\n",
        "    2: \"État de l'art\",\n",
        "    3: \"Méthodologie\",\n",
        "    4: \"Résultats\",\n",
        "    5: \"Conclusion\"\n",
        "}\n",
        "\n",
        "doc_manager = DynamicPlanManager(initial_plan, eval_interval=2)\n",
        "\n",
        "doc_manager.add_section(1, \"Présentation générale du sujet.\")\n",
        "doc_manager.add_section(2, \"Résumé des travaux existants.\")\n",
        "doc_manager.add_section(3, \"Explication de la méthode choisie, introduisant un nouveau sujet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "r3boTA2JgyjA",
      "metadata": {
        "id": "r3boTA2JgyjA"
      },
      "source": [
        "# Task 5. Remplacer le llm par un HumanLLMMonitor et sa méthode CallHumanLLM pour permettre le contrôle humain avant ou après inférence de chaque inférence des agents: intro, chaque section, conclusion...\n",
        "EXEMPLE DE CODE Similaire: https://github.com/doxav/CollabFunctionsGPTCreator/blob/main/tests/testhumanllm.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qN-ROPl0A3J9",
      "metadata": {
        "id": "qN-ROPl0A3J9"
      },
      "outputs": [],
      "source": [
        "import pdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZFiDXJ0ABn8N",
      "metadata": {
        "id": "ZFiDXJ0ABn8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6cba1a9-a5e0-4e4f-dc7e-9de7429e4e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Looks that a private key is already created. If you have already push it to github, no action required.\n",
            " Otherwise, Please go to https://github.com/settings/ssh/new to upload the following key: \n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIKaLTC4prv1LX3xxknKBCL29lglY1YkPrsFcjUsKybDd root@fb86ef43f54a\n",
            "\n",
            "Please use SSH method to clone repo.\n",
            "fatal: destination path 'CollabFunctionsGPTCreator' already exists and is not an empty directory.\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (3.1.44)\n",
            "Collecting openai~=1.43.0 (from -r requirements.txt (line 4))\n",
            "  Using cached openai-1.43.1-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: tiktoken~=0.7.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: requests~=2.31.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (2.31.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (5.9.5)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (0.27.2)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.0.1)\n",
            "Requirement already satisfied: pydantic~=2.8.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: watchdog in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 13)) (6.0.0)\n",
            "Requirement already satisfied: PyYAML~=6.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 14)) (6.0.2)\n",
            "Requirement already satisfied: python-dotenv~=1.0.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 15)) (1.0.1)\n",
            "Requirement already satisfied: scipy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 16)) (1.13.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 19)) (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 20)) (2.5.1+cu121)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 21)) (3.3.1)\n",
            "Requirement already satisfied: scikit-learn~=1.5.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 22)) (1.5.2)\n",
            "Requirement already satisfied: numpy~=1.26.4 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 23)) (1.26.4)\n",
            "Requirement already satisfied: optuna~=3.6.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 24)) (3.6.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 25)) (0.8.0)\n",
            "Requirement already satisfied: pandas~=2.2.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 26)) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 27)) (0.13.2)\n",
            "Requirement already satisfied: wikipedia-api in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 30)) (0.8.1)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 31)) (1.4.0)\n",
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 32)) (2.1.0)\n",
            "Requirement already satisfied: bs4~=0.0.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 33)) (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4~=4.12.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 34)) (4.12.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 37)) (3.2.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 38)) (3.7.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 39)) (3.9.1)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 40)) (6.0.10)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 43)) (3.1.0)\n",
            "Requirement already satisfied: flask_cors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 44)) (5.0.0)\n",
            "Requirement already satisfied: websockets~=11.0.3 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 45)) (11.0.3)\n",
            "Requirement already satisfied: elasticsearch~=8.10.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 48)) (8.10.1)\n",
            "Requirement already satisfied: neo4j~=5.24.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 51)) (5.24.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 54)) (7.7.1)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 55)) (7.34.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 56)) (5.5.6)\n",
            "Requirement already satisfied: jupyter_client in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 57)) (6.1.12)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 58)) (5.10.4)\n",
            "Requirement already satisfied: llama-index==0.11.12 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 61)) (0.11.12)\n",
            "Requirement already satisfied: llama-index-llms-ollama==0.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 62)) (0.3.2)\n",
            "Requirement already satisfied: llama-index-embeddings-ollama==0.3.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 63)) (0.3.1)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 66)) (3.1.5)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 67)) (0.115.7)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 68)) (3.11.11)\n",
            "Requirement already satisfied: starlette in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 69)) (0.45.3)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 70)) (1.6.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 73)) (2.19.1)\n",
            "Requirement already satisfied: python-git in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 74)) (2018.2.1)\n",
            "Collecting langchain==0.3.3 (from -r requirements.txt (line 78))\n",
            "  Using cached langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-community==0.3.2 (from -r requirements.txt (line 79))\n",
            "  Using cached langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langchain-core==0.3.10 (from -r requirements.txt (line 80))\n",
            "  Using cached langchain_core-0.3.10-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: langchain-experimental==0.3.2 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 81)) (0.3.2)\n",
            "Requirement already satisfied: langchain-groq==0.2.0 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 82)) (0.2.0)\n",
            "Collecting langchain-openai==0.2.2 (from -r requirements.txt (line 83))\n",
            "  Using cached langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langchain-text-splitters==0.3.0 (from -r requirements.txt (line 84))\n",
            "  Using cached langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langgraph==0.2.35 (from -r requirements.txt (line 85))\n",
            "  Using cached langgraph-0.2.35-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langgraph-checkpoint==2.0.1 (from -r requirements.txt (line 86))\n",
            "  Using cached langgraph_checkpoint-2.0.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: langsmith==0.1.133 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 87)) (0.1.133)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.4 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.3.4)\n",
            "Requirement already satisfied: llama-index-cli<0.4.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.3.1)\n",
            "Requirement already satisfied: llama-index-core<0.12.0,>=0.11.11 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.11.23)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.2.5)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.6.0)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.9.48.post4)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.9 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.2.16)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.2.3)\n",
            "Requirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.2.0)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.2.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.2.2)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index==0.11.12->-r requirements.txt (line 61)) (0.3.0)\n",
            "Requirement already satisfied: ollama>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-llms-ollama==0.3.2->-r requirements.txt (line 62)) (0.3.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.3->-r requirements.txt (line 78)) (2.0.37)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.3->-r requirements.txt (line 78)) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.2->-r requirements.txt (line 79)) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.3.2->-r requirements.txt (line 79)) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.10->-r requirements.txt (line 80)) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.10->-r requirements.txt (line 80)) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.3.10->-r requirements.txt (line 80)) (4.12.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from langchain-groq==0.2.0->-r requirements.txt (line 82)) (0.15.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint==2.0.1->-r requirements.txt (line 86)) (1.1.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith==0.1.133->-r requirements.txt (line 87)) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith==0.1.133->-r requirements.txt (line 87)) (1.0.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->-r requirements.txt (line 1)) (4.0.12)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai~=1.43.0->-r requirements.txt (line 4)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai~=1.43.0->-r requirements.txt (line 4)) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai~=1.43.0->-r requirements.txt (line 4)) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai~=1.43.0->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai~=1.43.0->-r requirements.txt (line 4)) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken~=0.7.0->-r requirements.txt (line 5)) (2024.11.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests~=2.31.0->-r requirements.txt (line 8)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests~=2.31.0->-r requirements.txt (line 8)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests~=2.31.0->-r requirements.txt (line 8)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.31.0->-r requirements.txt (line 8)) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->-r requirements.txt (line 10)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->-r requirements.txt (line 10)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.8.2->-r requirements.txt (line 12)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.11/dist-packages (from pydantic~=2.8.2->-r requirements.txt (line 12)) (2.20.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (0.27.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 19)) (0.5.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (2024.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 20)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 20)) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 20)) (1.3.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers->-r requirements.txt (line 21)) (11.1.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn~=1.5.1->-r requirements.txt (line 22)) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn~=1.5.1->-r requirements.txt (line 22)) (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna~=3.6.1->-r requirements.txt (line 24)) (1.14.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna~=3.6.1->-r requirements.txt (line 24)) (6.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.2.2->-r requirements.txt (line 26)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.2.2->-r requirements.txt (line 26)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas~=2.2.2->-r requirements.txt (line 26)) (2025.1)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn->-r requirements.txt (line 27)) (3.10.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser->-r requirements.txt (line 40)) (1.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4~=4.12.3->-r requirements.txt (line 34)) (2.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (0.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->-r requirements.txt (line 38)) (3.5.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->-r requirements.txt (line 39)) (8.1.8)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask->-r requirements.txt (line 43)) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask->-r requirements.txt (line 43)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask->-r requirements.txt (line 43)) (1.9.0)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.11/dist-packages (from elasticsearch~=8.10.1->-r requirements.txt (line 48)) (8.17.0)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 54)) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 54)) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 54)) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ipywidgets->-r requirements.txt (line 54)) (3.0.13)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from IPython->-r requirements.txt (line 55)) (4.9.0)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipykernel->-r requirements.txt (line 56)) (6.3.3)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter_client->-r requirements.txt (line 57)) (5.7.2)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.11/dist-packages (from jupyter_client->-r requirements.txt (line 57)) (24.0.1)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.11/dist-packages (from nbformat->-r requirements.txt (line 58)) (2.21.1)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.11/dist-packages (from nbformat->-r requirements.txt (line 58)) (4.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2->-r requirements.txt (line 66)) (3.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 68)) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 68)) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 68)) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 68)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 68)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 68)) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->-r requirements.txt (line 68)) (1.18.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 73)) (17.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 73)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 73)) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 73)) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->-r requirements.txt (line 73)) (0.70.16)\n",
            "Requirement already satisfied: send2trash in /usr/local/lib/python3.11/dist-packages (from python-git->-r requirements.txt (line 74)) (1.8.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna~=3.6.1->-r requirements.txt (line 24)) (1.3.8)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.2->-r requirements.txt (line 79)) (3.26.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.2->-r requirements.txt (line 79)) (0.9.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->-r requirements.txt (line 1)) (5.0.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->IPython->-r requirements.txt (line 55)) (0.8.4)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.3.10->-r requirements.txt (line 80)) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 58)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 58)) (0.36.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=2.6->nbformat->-r requirements.txt (line 58)) (0.22.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter_client->-r requirements.txt (line 57)) (4.3.6)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 38)) (1.3.0)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.11->llama-index==0.11.12->-r requirements.txt (line 61)) (1.2.15)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.11->llama-index==0.11.12->-r requirements.txt (line 61)) (1.0.8)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.11->llama-index==0.11.12->-r requirements.txt (line 61)) (1.2.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.12.0,>=0.11.11->llama-index==0.11.12->-r requirements.txt (line 61)) (1.17.2)\n",
            "Requirement already satisfied: llama-cloud>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index==0.11.12->-r requirements.txt (line 61)) (0.1.10)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.12->-r requirements.txt (line 61)) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index==0.11.12->-r requirements.txt (line 61)) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.3.0->llama-index==0.11.12->-r requirements.txt (line 61)) (0.5.20)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 27)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 27)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 27)) (4.55.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn->-r requirements.txt (line 27)) (1.4.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->IPython->-r requirements.txt (line 55)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->IPython->-r requirements.txt (line 55)) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas~=2.2.2->-r requirements.txt (line 26)) (1.17.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.3->-r requirements.txt (line 78)) (3.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 38)) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy->-r requirements.txt (line 38)) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 38)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 38)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 38)) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 38)) (7.1.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.11/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (6.5.5)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 38)) (1.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (23.1.0)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (7.16.5)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (0.21.1)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.11/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 38)) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.2->-r requirements.txt (line 79)) (1.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 38)) (0.1.2)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (0.2.4)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (0.3.0)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (3.1.0)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (0.10.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (1.5.1)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (0.5.1)\n",
            "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (1.4.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.11/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (2.22)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.11/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 54)) (1.8.0)\n",
            "Using cached langchain-0.3.3-py3-none-any.whl (1.0 MB)\n",
            "Using cached langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n",
            "Using cached langchain_core-0.3.10-py3-none-any.whl (404 kB)\n",
            "Using cached langchain_openai-0.2.2-py3-none-any.whl (49 kB)\n",
            "Using cached langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Using cached langgraph-0.2.35-py3-none-any.whl (108 kB)\n",
            "Using cached langgraph_checkpoint-2.0.1-py3-none-any.whl (22 kB)\n",
            "Using cached openai-1.43.1-py3-none-any.whl (365 kB)\n",
            "Installing collected packages: openai, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-openai, langgraph, langchain, langchain-community\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.60.1\n",
            "    Uninstalling openai-1.60.1:\n",
            "      Successfully uninstalled openai-1.60.1\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.31\n",
            "    Uninstalling langchain-core-0.3.31:\n",
            "      Successfully uninstalled langchain-core-0.3.31\n",
            "  Attempting uninstall: langgraph-checkpoint\n",
            "    Found existing installation: langgraph-checkpoint 2.0.10\n",
            "    Uninstalling langgraph-checkpoint-2.0.10:\n",
            "      Successfully uninstalled langgraph-checkpoint-2.0.10\n",
            "  Attempting uninstall: langchain-text-splitters\n",
            "    Found existing installation: langchain-text-splitters 0.3.5\n",
            "    Uninstalling langchain-text-splitters-0.3.5:\n",
            "      Successfully uninstalled langchain-text-splitters-0.3.5\n",
            "  Attempting uninstall: langchain-openai\n",
            "    Found existing installation: langchain-openai 0.3.2\n",
            "    Uninstalling langchain-openai-0.3.2:\n",
            "      Successfully uninstalled langchain-openai-0.3.2\n",
            "  Attempting uninstall: langgraph\n",
            "    Found existing installation: langgraph 0.2.67\n",
            "    Uninstalling langgraph-0.2.67:\n",
            "      Successfully uninstalled langgraph-0.2.67\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.15\n",
            "    Uninstalling langchain-0.3.15:\n",
            "      Successfully uninstalled langchain-0.3.15\n",
            "  Attempting uninstall: langchain-community\n",
            "    Found existing installation: langchain-community 0.3.15\n",
            "    Uninstalling langchain-community-0.3.15:\n",
            "      Successfully uninstalled langchain-community-0.3.15\n",
            "Successfully installed langchain-0.3.3 langchain-community-0.3.2 langchain-core-0.3.10 langchain-openai-0.2.2 langchain-text-splitters-0.3.0 langgraph-0.2.35 langgraph-checkpoint-2.0.1 openai-1.43.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'npm' is not installed, so not removed\n",
            "The following packages will be REMOVED:\n",
            "  nodejs*\n",
            "0 upgraded, 0 newly installed, 1 to remove and 52 not upgraded.\n",
            "After this operation, 187 MB disk space will be freed.\n",
            "(Reading database ... 129896 files and directories currently installed.)\n",
            "Removing nodejs (18.20.6-1nodesource1) ...\n",
            "dpkg: warning: while removing nodejs, directory '/usr/lib/node_modules' not empty so not removed\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[38;5;79m2025-01-26 14:12:54 - Installing pre-requisites\u001b[0m\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://deb.nodesource.com/node_18.x nodistro InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.20).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "apt-transport-https is already the newest version (2.4.13).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 52 not upgraded.\n",
            "Hit:1 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:7 https://deb.nodesource.com/node_18.x nodistro InRelease\n",
            "Hit:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\u001b[1;34m2025-01-26 14:13:02 - Repository configured successfully.\u001b[0m\n",
            "\u001b[38;5;79m2025-01-26 14:13:02 - To install Node.js, run: apt-get install nodejs -y\u001b[0m\n",
            "\u001b[38;5;79m2025-01-26 14:13:02 - You can use N|solid Runtime as a node.js alternative\u001b[0m\n",
            "\u001b[1;32m2025-01-26 14:13:02 - To install N|solid Runtime, run: apt-get install nsolid -y \n",
            "\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 52 not upgraded.\n",
            "Need to get 29.7 MB of archives.\n",
            "After this operation, 187 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_18.x nodistro/main amd64 nodejs amd64 18.20.6-1nodesource1 [29.7 MB]\n",
            "Fetched 29.7 MB in 1s (39.7 MB/s)\n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 124578 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_18.20.6-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (18.20.6-1nodesource1) ...\n",
            "Setting up nodejs (18.20.6-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "changed 22 packages in 904ms\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0Kconfig.py created successfully!\n",
            "[{'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_8aea68e16738_20-01-2025-15-33-44', 'uuid': 'IrorXYiMSL2smzGgGPuFDw', 'pri': '1', 'rep': '1', 'docs.count': '3', 'docs.deleted': '0', 'store.size': '278.3kb', 'pri.store.size': '139.1kb', 'dataset.size': '139.1kb'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_92ef96158436_15-01-2025-12-27-20', 'uuid': 'PCzYhDhqRjSQvchkeuMFCA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_cbdd2d82f886_20-01-2025-14-56-13', 'uuid': 'M9-MYQasSp68S6_Su13TpA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_cbdd2d82f886_20-01-2025-14-56-13', 'uuid': 'kiU_tXbCTISxjFiR5Fu57g', 'pri': '1', 'rep': '1', 'docs.count': '16', 'docs.deleted': '0', 'store.size': '2mb', 'pri.store.size': '1mb', 'dataset.size': '1mb'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-ml.anomaly-detection.alerts-default-000001', 'uuid': 'WcCEaVz0Swu0ZC3cbo5oKg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-observability.slo.alerts-default-000001', 'uuid': 'F_ycRpyBT_K6OwTj-QxHiQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_92ef96158436_15-01-2025-12-27-20', 'uuid': 'b__OPSCLTGGt_6AlUMAiVQ', 'pri': '1', 'rep': '1', 'docs.count': '2', 'docs.deleted': '0', 'store.size': '177.2kb', 'pri.store.size': '88.6kb', 'dataset.size': '88.6kb'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs', 'uuid': '2Gp1P5FhQEq5Ym9QCvUvJQ', 'pri': '1', 'rep': '1', 'docs.count': '33', 'docs.deleted': '0', 'store.size': '2.5mb', 'pri.store.size': '1.2mb', 'dataset.size': '1.2mb'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_xp_2025_01_15v1_equipe_seb', 'uuid': 'GeziudFgR1ewxDRdcczR9A', 'pri': '1', 'rep': '1', 'docs.count': '11', 'docs.deleted': '0', 'store.size': '1mb', 'pri.store.size': '534.4kb', 'dataset.size': '534.4kb'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_c64ba169751d_20-01-2025-14-46-49', 'uuid': 'Y-0q6XvISviiittfkOJzeg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-observability.metrics.alerts-default-000001', 'uuid': 'iYAm8AQgRp2awOcuo9au0A', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_bd2edb050999_20-01-2025-14-30-03', 'uuid': 's_HNVOiFTzGnhf7_9TnKuQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_8ab6b8a9d39e_19-01-2025-18-01-47', 'uuid': 'mE4vCAyzSxG_2_cm3mAUBA', 'pri': '1', 'rep': '1', 'docs.count': '3', 'docs.deleted': '0', 'store.size': '279.2kb', 'pri.store.size': '139.6kb', 'dataset.size': '139.6kb'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_oui', 'uuid': 'enPm5RedT8-Eh223cv8Plw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_xp_21_12_24', 'uuid': 'FuBjBxVaRy2NYzer1n9eUg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_bd2edb050999_20-01-2025-14-30-03', 'uuid': '7G_GUXOzReu3U4Hu5UnLJQ', 'pri': '1', 'rep': '1', 'docs.count': '7', 'docs.deleted': '0', 'store.size': '627.6kb', 'pri.store.size': '313.8kb', 'dataset.size': '313.8kb'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-stack.alerts-default-000001', 'uuid': 'jgP5fKejQtCGslhq1rEOWg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_92ef96158436_15-01-2025-12-27-20', 'uuid': 'q9K0ABQJQROU7gW5AiIMew', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks', 'uuid': 'dy2UYDArSHSv_RYyokzvgg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-observability.uptime.alerts-default-000001', 'uuid': 'nwltsC9mR6-mOg46OK-RYA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__macroeconomic_effects_of_inflation_targeting_a_survey_of_t_xp_21_12_24', 'uuid': 'KuMonrk3RUWRn1eco_oE4w', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_8ab6b8a9d39e_19-01-2025-18-01-47', 'uuid': '5bdpA3VwSxq8iKyptjiRiw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_oui', 'uuid': 'FwwYL59MSn68ptK4EvxH9Q', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.ds-logs-enterprise_search.api-default-2025.01.24-000003', 'uuid': 'yBS553glTmuk0stu2rojpQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_xp_2025_01_15v1', 'uuid': '-nu8GfEKTBiit_nWxQAmig', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.ds-logs-enterprise_search.api-default-2025.01.17-000002', 'uuid': 'dvTjWFVaQNKI3m4Nca3MKg', 'pri': '1', 'rep': '1', 'docs.count': '2', 'docs.deleted': '0', 'store.size': '39.5kb', 'pri.store.size': '19.7kb', 'dataset.size': '19.7kb'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_xp_equipe_3', 'uuid': 'AwOUI-8gSbajUsHEAIcFpA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__macroeconomic_effects_of_inflation_targeting_a_survey_of_t_xp_solo_team_seb_seb', 'uuid': 'r9bDPnrlS_C1u1QR5sOhig', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '498b', 'pri.store.size': '249b', 'dataset.size': '249b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_xp_equipe_3', 'uuid': 'RvY8xC6nS067kdZlitVoLw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_97e63e0e42a7_15-01-2025-08-18-34', 'uuid': 'APRu3XI9SzKmg3jREvvYgQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_e0899fd25e0a_19-01-2025-17-46-39', 'uuid': '_52n3LFISSG9AgqXtam_HQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_cbdd2d82f886_20-01-2025-15-23-48', 'uuid': 'ifuYapOySpKPyL0E2IdLTA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_e0899fd25e0a_19-01-2025-17-48-58', 'uuid': 'DbaH-yWORdWGq6JrqX1zAg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-observability.threshold.alerts-default-000001', 'uuid': 'Mcf-YoWdQhSuQ5lr7N9UkA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_8ab6b8a9d39e_19-01-2025-18-01-47', 'uuid': 'DFYkUH-dT9ug6ybg5FC-zw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.elastic-connectors-sync-jobs-v1', 'uuid': 'Etc3OJEvSDO_I-dPz1tNrg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '7.6kb', 'pri.store.size': '248b', 'dataset.size': '248b'}, {'health': 'green', 'status': 'open', 'index': 'aa__complex_qa_and_language_models_hybrid_architectures__surve_xp_21_12_24', 'uuid': 'knXyuRgCR5y70fVwO8qZPg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_cbdd2d82f886_20-01-2025-15-23-48', 'uuid': '-PsfKvl8SqOmXRY9r-6dEw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_xp_21_12_24', 'uuid': '6ipKNqDhSWq32f0QSWGYPQ', 'pri': '1', 'rep': '1', 'docs.count': '37', 'docs.deleted': '0', 'store.size': '3.2mb', 'pri.store.size': '1.6mb', 'dataset.size': '1.6mb'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-transform.health.alerts-default-000001', 'uuid': 'cYp--WE6QBeMwCphAqMywg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_cbdd2d82f886_20-01-2025-15-23-48', 'uuid': 'pVZqh_6VTCSGpMXo5LEaVg', 'pri': '1', 'rep': '1', 'docs.count': '8', 'docs.deleted': '0', 'store.size': '1.1mb', 'pri.store.size': '607.5kb', 'dataset.size': '607.5kb'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_xp_2025_01_15v1_equipe_seb', 'uuid': 'g2vd-YrUS8O9RCcDnXmeCg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '498b', 'pri.store.size': '249b', 'dataset.size': '249b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_63a22e55eba1_24-01-2025-18-41-11', 'uuid': 'nUZyH7pcS2KeClSZr4uSSQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_f7451d6cb0b5_14-01-2025-14-23-26', 'uuid': 'i0-cSbMtRcKu9Mz4LfJRFQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__macroeconomic_effects_of_inflation_targeting_a_survey_of_t_xp_equipe_3', 'uuid': 'vGWSwlypQUynBeHgU21-Wg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_xp_solo_team_seb_seb', 'uuid': '872f0-hZQjCZxMWz6mRtUQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '498b', 'pri.store.size': '249b', 'dataset.size': '249b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_e0899fd25e0a_19-01-2025-17-46-39', 'uuid': '-KcBggkdQuKvQD-ZIxzWuQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__complex_qa_and_language_models_hybrid_architectures__surve_xp_equipe_3', 'uuid': 'E-whjXFLQgq_j_CkBNcrxg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_xp_solo_team_seb_seb', 'uuid': 'mt_gw0h2Sgus3jSyMmCMkw', 'pri': '1', 'rep': '1', 'docs.count': '53', 'docs.deleted': '0', 'store.size': '5.9mb', 'pri.store.size': '2.9mb', 'dataset.size': '2.9mb'}, {'health': 'green', 'status': 'open', 'index': 'aa__macroeconomic_effects_of_inflation_targeting_a_survey_of_t_oui', 'uuid': 'ZaKKHccxQvS-Vqt0JVEcGg', 'pri': '1', 'rep': '1', 'docs.count': '1', 'docs.deleted': '0', 'store.size': '78kb', 'pri.store.size': '39kb', 'dataset.size': '39kb'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_e0899fd25e0a_19-01-2025-17-48-58', 'uuid': 'P3O3xnwcSwikNX5wKl3lVw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_oui', 'uuid': 'Fa0SweClSmSbBqxeKChTUA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-observability.apm.alerts-default-000001', 'uuid': 'SmFB3TH8QsCQvfAd9BhQ_A', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_f7451d6cb0b5_14-01-2025-14-23-26', 'uuid': 'xlT7S_WxQ9SLz2dVFV95zg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-default.alerts-default-000001', 'uuid': 'sqNhImvVRCelSuvlRWN4sw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_63a22e55eba1_24-01-2025-18-41-11', 'uuid': 'E26kpiqbRYSjMX_sih3AhA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_xp_solo_team_seb_seb', 'uuid': 'hWHTnuKqQGu3lNhNvGLBzQ', 'pri': '1', 'rep': '1', 'docs.count': '2', 'docs.deleted': '0', 'store.size': '188.9kb', 'pri.store.size': '94.4kb', 'dataset.size': '94.4kb'}, {'health': 'green', 'status': 'open', 'index': '.elastic-connectors-v1', 'uuid': '6pV327YBRqSnOFeFkTDmqw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '7.6kb', 'pri.store.size': '248b', 'dataset.size': '248b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_63a22e55eba1_24-01-2025-18-41-11', 'uuid': 'CF4ArbgPRVS7mnxaMiVOHA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_f7451d6cb0b5_14-01-2025-14-23-26', 'uuid': 'ctMC0ZJgThyZZQdiIgh82w', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_97e63e0e42a7_15-01-2025-08-18-34', 'uuid': 'gfSasha8Rx6BR9sB0w8mMg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_xp_equipe_3', 'uuid': 'se9yUlXRQH26BFJ4L8-nEA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-ml.anomaly-detection-health.alerts-default-000001', 'uuid': 'AWQTyx9aRgirnYSRr4De1g', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_e0899fd25e0a_19-01-2025-17-48-58', 'uuid': '6W8KSTakQamgHq_ZtsF8Ng', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__complex_qa_and_language_models_hybrid_architectures__surve_xp_solo_team_seb_seb', 'uuid': 'JZBwCjOXRP2AA2AJ81tWjA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '498b', 'pri.store.size': '249b', 'dataset.size': '249b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-security.alerts-default-000001', 'uuid': 'Nwr87h6eQjyyGEOGumlcvQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.ds-metrics-fleet_server.agent_versions-default-2025.01.10-000001', 'uuid': 'IoBBIisjRJ6y0Cf1k5G8Yg', 'pri': '1', 'rep': '1', 'docs.count': '22962', 'docs.deleted': '0', 'store.size': '1.4mb', 'pri.store.size': '736.6kb', 'dataset.size': '736.6kb'}, {'health': 'green', 'status': 'open', 'index': 'aa__complex_qa_and_language_models_hybrid_architectures__surve_xp_2025_01_15v1', 'uuid': 'Igtk9ET9S1Ck5q1M2PPdzA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_e0899fd25e0a_19-01-2025-17-46-39', 'uuid': 's4jDKFXmQju3V-81LHDrtQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__complex_qa_and_language_models_hybrid_architectures__surve_xp_2025_01_15v1_equipe_seb', 'uuid': 'hw53D0rLTX-RIgiL6FfsWg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_97e63e0e42a7_15-01-2025-08-18-34', 'uuid': 'EwWone2sSumqAlwu0PP5EA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_97e63e0e42a7_15-01-2025-08-24-19', 'uuid': 'o6wf5cW9TiqTnEhH2tqfhg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.internal.alerts-observability.logs.alerts-default-000001', 'uuid': 'A9om2L2LSVyap9yFLwNulA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.ds-metrics-fleet_server.agent_status-default-2025.01.10-000001', 'uuid': 'ScIwQfVuQymC1S5pg9HMBg', 'pri': '1', 'rep': '1', 'docs.count': '22962', 'docs.deleted': '0', 'store.size': '1.6mb', 'pri.store.size': '822.9kb', 'dataset.size': '822.9kb'}, {'health': 'green', 'status': 'open', 'index': 'aa__macroeconomic_effects_of_inflation_targeting_a_survey_of_t_xp_2025_01_15v1', 'uuid': '1saIWgPGQAG1lYHK0BL8lQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_92ef96158436_15-01-2025-12-19-38', 'uuid': 'KymmFcXNRrSvMSO4KlGIMA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_xp_2025_01_15v1', 'uuid': 'AMRGqGXMToCkXPjCY913mA', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': '.ds-logs-enterprise_search.audit-default-2025.01.10-000001', 'uuid': 'hW6gz-NCR1u2jfI59zGqNw', 'pri': '1', 'rep': '1', 'docs.count': '8', 'docs.deleted': '0', 'store.size': '95.6kb', 'pri.store.size': '47.8kb', 'dataset.size': '47.8kb'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks', 'uuid': '_NziQmv0Que9F0AQD_w-1Q', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_bd2edb050999_20-01-2025-14-30-03', 'uuid': 'fAeh0HNJThW8mIYzdiSVpQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_8aea68e16738_20-01-2025-15-33-44', 'uuid': 'NtI6uVN7R12kMfPmKkZSIw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_c64ba169751d_20-01-2025-14-46-49', 'uuid': 'bhAvQ3loQKurSw23aXcZ6g', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_xp_2025_01_15v1_equipe_seb', 'uuid': 'HKtiElpIT46wUohAaCSXCg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '498b', 'pri.store.size': '249b', 'dataset.size': '249b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_92ef96158436_15-01-2025-12-19-38', 'uuid': 'XFsQUrKNSRag2GaUwUREaQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_8aea68e16738_20-01-2025-15-33-44', 'uuid': 'fFfve0xoRIOdEXlX4v-ygQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_97e63e0e42a7_15-01-2025-08-24-19', 'uuid': '8hGzC1clQlWgEDlwF0_-2Q', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_xp_2025_01_15v1', 'uuid': '95MYhoXoT2iRlaeXfMFAug', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_xp_21_12_24', 'uuid': 'KOVyzMyySQi-2oNHhditlQ', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__macroeconomic_effects_of_inflation_targeting_a_survey_of_t_xp_2025_01_15v1_equipe_seb', 'uuid': 'opGeqiS9Ryi32XYa9a3gMw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'successful_tasks_92ef96158436_15-01-2025-12-19-38', 'uuid': 'InSeg8WqRn6lV-KSzgxwgg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_cbdd2d82f886_20-01-2025-14-56-13', 'uuid': 'N8KsXo44R26nAqOcI06drw', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'aa__complex_qa_and_language_models_hybrid_architectures__surve_oui', 'uuid': 'rjRdxmxGRcOW-Oxcf3IdwA', 'pri': '1', 'rep': '1', 'docs.count': '1', 'docs.deleted': '0', 'store.size': '78kb', 'pri.store.size': '39kb', 'dataset.size': '39kb'}, {'health': 'green', 'status': 'open', 'index': 'failed_tasks_97e63e0e42a7_15-01-2025-08-24-19', 'uuid': 'QicTZvErRNShC6RAxRnENg', 'pri': '1', 'rep': '1', 'docs.count': '0', 'docs.deleted': '0', 'store.size': '499b', 'pri.store.size': '250b', 'dataset.size': '250b'}, {'health': 'green', 'status': 'open', 'index': 'human_llm_monitor_logs_c64ba169751d_20-01-2025-14-46-49', 'uuid': 'eqkjyFqRQF2-UL98d3tlyQ', 'pri': '1', 'rep': '1', 'docs.count': '1', 'docs.deleted': '0', 'store.size': '88kb', 'pri.store.size': '44kb', 'dataset.size': '44kb'}]\n"
          ]
        }
      ],
      "source": [
        "# Definition of parameters to run ColablFunctionsGPTCreator\n",
        "unique_id = 'XP_2025_01_15v1' # None to avoid keeping between learn/run\n",
        "\n",
        "github_repo = \"doxav/CollabFunctionsGPTCreator\"\n",
        "openai_api_key = \"...\"\n",
        "elastic_url_port = 'https://a2d11e78b3ec41bc9b90fbc0f76b852d.us-central1.gcp.cloud.es.io:443' # Cloud account from https://www.elastic.co/cloud/elasticsearch-service/signup => then you need to find the security section to reset the elastic password which is not displayed by default\n",
        "kibana_url_port = 'https://a2d11e78b3ec41bc9b90fbc0f76b852d.us-central1.gcp.cloud.es.io:9243'\n",
        "elastic_user = 'elastic'\n",
        "elastic_password = 'WzmJP69PBWNZe6NA70AHHQJa'\n",
        "\n",
        "# Create SSH key for GitHub\n",
        "!wget -q https://raw.githubusercontent.com/tsunrise/colab-github/main/colab_github.py\n",
        "import colab_github\n",
        "colab_github.github_auth(persistent_key=True)\n",
        "\n",
        "# Get the repo\n",
        "!git clone --depth 1 git@github.com:{github_repo}.git\n",
        "\n",
        "# Set Up environment\n",
        "import os\n",
        "\n",
        "# Change the working directory\n",
        "os.chdir(\"/content/CollabFunctionsGPTCreator\")\n",
        "\n",
        "!pip install -r requirements.txt\n",
        "!apt-get purge -y nodejs npm\n",
        "!curl -fsSL https://deb.nodesource.com/setup_18.x | bash -\n",
        "!apt-get install -y nodejs\n",
        "!npm install -g localtunnel\n",
        "#!lt --port 8000\n",
        "\n",
        "# Config.py\n",
        "config_content = f\"\"\"\n",
        "import os\n",
        "\n",
        "unique_id = '{unique_id}' # set to None to not capitalize between run or set a fixed named of experiments for shared capitalization between experiments - e.g. 'XP_2025_01_15v1'\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = '{openai_api_key}'\n",
        "\n",
        "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']\n",
        "openai_api_key = OPENAI_API_KEY\n",
        "\n",
        "elastic_url_port = '{elastic_url_port}'\n",
        "kibana_url_port = '{kibana_url_port}'\n",
        "elastic_user = '{elastic_user}'\n",
        "elastic_password = '{elastic_password}'\n",
        "PickleCacheActivated = False\n",
        "embedding_function = \"text-embedding-ada-002\"\n",
        "reset_db_indices = True # WARNING: if you change the embedding_function, set this to True\n",
        "\n",
        "MODELS_CONFIG_LIST = {{\n",
        "    \"smart_gpt\": \"gpt-4o-mini\", # \"llama-3.1-70b-versatile\", # \"mixtral-8x7b-32768\", # \"eramax/nxcode-cq-7b-orpo:q6\", #mistral-nemo:12b-instruct-2407-q4_K_M\", #\"llama3:latest\",\n",
        "    \"code_gpt\": \"gpt-4o-mini\", # \"llama-3.1-70b-versatile\", # \"mixtral-8x7b-32768\", # \"gpt-4o-mini\", # \"eramax/nxcode-cq-7b-orpo:q6\", #mistral-nemo:12b-instruct-2407-q4_K_M\", #\"llama3:latest\",\n",
        "    \"basic_gpt\": \"gpt-4o-mini\" # \"llama-3.1-70b-versatile\", # \"mixtral-8x7b-32768\", # \"gpt-4o-mini\" # \"eramax/nxcode-cq-7b-orpo:q6\" #mistral-nemo:12b-instruct-2407-q4_K_M\", #\"llama3:latest\",\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "# Write the content to a config.py file\n",
        "with open(\"/content/CollabFunctionsGPTCreator/config.py\", \"w\") as file:\n",
        "    file.write(config_content)\n",
        "\n",
        "print(\"config.py created successfully!\")\n",
        "\n",
        "# Test Elastico connexion\n",
        "from config import elastic_url_port, elastic_user, elastic_password\n",
        "import requests\n",
        "\n",
        "response = requests.get(f\"{elastic_url_port}/_cat/indices?format=json\", auth=(elastic_user, elastic_password))\n",
        "print(response.json())\n",
        "\n",
        "!cd /content/CollabFunctionsGPTCreator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "B1_Brp53gysm",
      "metadata": {
        "id": "B1_Brp53gysm"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import socket\n",
        "from utils.llm_utils import HumanLLMMonitor, UnifiedVectorDB\n",
        "from config import MODELS_CONFIG_LIST, embedding_function\n",
        "from langchain_core.messages.human import HumanMessage\n",
        "from langchain_core.messages.system import SystemMessage\n",
        "\n",
        "UnifiedVectorDB.db_type = \"elasticsearch\"  # \"elasticsearch\" \"chroma\"\n",
        "UnifiedVectorDB.es_url = elastic_url_port\n",
        "UnifiedVectorDB.es_user = elastic_user\n",
        "UnifiedVectorDB.es_password = elastic_password\n",
        "UnifiedVectorDB.OpenAI_embedding_function_name = \"text-embedding-ada-002\"  # \"nomic-ai/nomic-embed-text-v1\"\n",
        "\n",
        "\n",
        "embedding_function = \"text-embedding-ada-002\" if embedding_function is None else embedding_function  #\"Alibaba-NLP/gte-base-en-v1.5\" UnifiedVectorDB.OpenAI_embedding_function_name # e.g. \"text-embedding-ada-002\" for OpenAI or \"intfloat/e5-base-v2\" or other huggingface models - WARINING: if you change it, set reset_db_indices to True\n",
        "# test if reset_db_indices exists\n",
        "if not 'reset_db_indices' in locals():\n",
        "    reset_db_indices = False  # Set it in your config.py to True if you want to reset \"after changing embeddings\"\n",
        "\n",
        "HumanLLMMonitor.use_websocket = False\n",
        "\n",
        "\n",
        "class AnalystGeneratorAgent:\n",
        "    def __init__(self, llmORchains_list, agent_name=\"AnalystGeneratorAgent\",\n",
        "                 automation=None, skip_rounds=0):\n",
        "        \"\"\"\n",
        "        automation = None => full HITL\n",
        "        skip_rounds => si on veut \"skipper\" N tours\n",
        "        \"\"\"\n",
        "        self.monitor = HumanLLMMonitor(\n",
        "            agent_name=agent_name,\n",
        "            llmORchains_list=llmORchains_list,\n",
        "            automation=automation\n",
        "        )\n",
        "        # Choix du LLM par défaut\n",
        "        self.monitor.set_default_llmORchain(\"default_llm\")\n",
        "\n",
        "    def generate_analysts(self, topic: str, max_analysts: int, feedback: str) -> List[dict]:\n",
        "        \"\"\"\n",
        "        Remplace le code 'create_analysts' du notebook.\n",
        "        \"\"\"\n",
        "        system_prompt = analyst_instructions.format(\n",
        "            topic=topic,\n",
        "            human_analyst_feedback=feedback,\n",
        "            max_analysts=max_analysts\n",
        "        )\n",
        "        # on appelle le moniteur\n",
        "        responses = self.monitor.CallHumanLLM(\n",
        "            original_input_messages=[\n",
        "                SystemMessage(content=system_prompt),\n",
        "                HumanMessage(content=\"Generate the set of analysts.\")\n",
        "            ],\n",
        "            return_message_content_only=False\n",
        "        )\n",
        "        # on suppose qu'on fait un parse \"structured\" ou un JSON, etc.\n",
        "        # ici, on renvoie juste la string\n",
        "        ai_msg = responses[0]\n",
        "        # on parse selon ce que vous faisiez déjà, ex. pydantic\n",
        "        # Ex:\n",
        "        # structured_data = parse_analysts(ai_msg.content)\n",
        "        # return structured_data\n",
        "        # ou on renvoie le content direct:\n",
        "        return [{\"raw_text\": ai_msg.content}]\n",
        "\n",
        "\n",
        "#######################################\n",
        "# 2) Agent pour la recherche de docs\n",
        "#######################################\n",
        "\n",
        "class DocumentSearchAgent:\n",
        "    def __init__(self, llmORchains_list, agent_name=\"DocumentSearchAgent\",\n",
        "                 automation=None, skip_rounds=0):\n",
        "        self.monitor = HumanLLMMonitor(\n",
        "            agent_name=agent_name,\n",
        "            llmORchains_list=llmORchains_list,\n",
        "            automation=automation\n",
        "        )\n",
        "        self.monitor.set_default_llmORchain(\"default_llm\")\n",
        "\n",
        "    def search_web(self, conversation: list) -> str:\n",
        "        \"\"\"\n",
        "        conversation = [HumanMessage(...), AIMessage(...), ...] (ex. l'historique)\n",
        "        Remplace 'search_web' du notebook\n",
        "        \"\"\"\n",
        "        # 1) on appelle un LLM qui génère la query\n",
        "        responses = self.monitor.CallHumanLLM(\n",
        "            original_input_messages=[SystemMessage(content=search_instructions)] + conversation,\n",
        "            return_message_content_only=False\n",
        "        )\n",
        "        # ex. responses[0].content => la \"search query\"\n",
        "        search_query = responses[0].content.strip()\n",
        "\n",
        "        # 2) on fait l'appel \"tavily\" ou autre\n",
        "        # search_docs = tavily_search.invoke(search_query)\n",
        "        # ...\n",
        "        return f\"[Simulé] Search done with query: {search_query}\"\n",
        "\n",
        "    def search_wikipedia(self, conversation: list) -> str:\n",
        "        \"\"\"\n",
        "        Remplace 'search_wikipedia'\n",
        "        \"\"\"\n",
        "        # Idem\n",
        "        responses = self.monitor.CallHumanLLM(\n",
        "            original_input_messages=[SystemMessage(content=search_instructions)] + conversation,\n",
        "            return_message_content_only=False\n",
        "        )\n",
        "        search_query = responses[0].content.strip()\n",
        "        # search_docs = WikipediaLoader(query=search_query, load_max_docs=2).load()\n",
        "        return f\"[Simulé] Wikipedia done with query: {search_query}\"\n",
        "\n",
        "\n",
        "#######################################\n",
        "# 3) Agent pour l'interview (Q / A)\n",
        "#######################################\n",
        "\n",
        "class InterviewAgent:\n",
        "    def __init__(self, llmORchains_list, agent_name=\"InterviewAgent\",\n",
        "                 automation=None, skip_rounds=0):\n",
        "        self.monitor = HumanLLMMonitor(\n",
        "            agent_name=agent_name,\n",
        "            llmORchains_list=llmORchains_list,\n",
        "            automation=automation\n",
        "        )\n",
        "        self.monitor.set_default_llmORchain(\"default_llm\")\n",
        "\n",
        "    def generate_question(self, persona: str, conversation: list):\n",
        "        \"\"\"\n",
        "        Remplace 'generate_question' du notebook\n",
        "        \"\"\"\n",
        "        sys_msg = question_instructions.format(goals=persona)\n",
        "        original_input_messages = [SystemMessage(content=sys_msg)]\n",
        "        if conversation:\n",
        "            original_input_messages.extend(conversation)\n",
        "        else:\n",
        "            original_input_messages.append(HumanMessage(content=\"\"))\n",
        "\n",
        "        responses = self.monitor.CallHumanLLM(\n",
        "            original_input_messages=original_input_messages,\n",
        "            return_message_content_only=False\n",
        "        )\n",
        "        return responses[0]\n",
        "\n",
        "    def generate_answer(self, persona: str, conversation: list, context: str):\n",
        "        \"\"\"\n",
        "        Remplace 'generate_answer'\n",
        "        \"\"\"\n",
        "        sys_msg = answer_instructions.format(goals=persona, context=context)\n",
        "        responses = self.monitor.CallHumanLLM(\n",
        "            original_input_messages=[SystemMessage(content=sys_msg)] + conversation,\n",
        "            return_message_content_only=False\n",
        "        )\n",
        "        # On rename responses[0] .name = \"expert\" si besoin\n",
        "        responses[0].name = \"expert\"\n",
        "        return responses[0]\n",
        "\n",
        "\n",
        "##########################################\n",
        "# 4) Agent pour la rédaction de sections\n",
        "##########################################\n",
        "\n",
        "\n",
        "class SectionWriterAgent:\n",
        "    def __init__(self, llmORchains_list, agent_name=\"SectionWriterAgent\",\n",
        "                 automation=None, skip_rounds=0):\n",
        "        self.monitor = HumanLLMMonitor(\n",
        "            agent_name=agent_name,\n",
        "            llmORchains_list=llmORchains_list,\n",
        "            automation=automation\n",
        "        )\n",
        "        self.monitor.set_default_llmORchain(\"default_llm\")\n",
        "\n",
        "    def write_section(self, interview_text: str, context: str, focus: str):\n",
        "        \"\"\"\n",
        "        Remplace 'write_section' du notebook\n",
        "        \"\"\"\n",
        "        sys_msg = section_writer_instructions.format(focus=focus)\n",
        "        user_msg = f\"Use these docs: {context} to write your section.\\nInterview content: {interview_text}\"\n",
        "        responses = self.monitor.CallHumanLLM(\n",
        "            original_input_messages=[\n",
        "                SystemMessage(content=sys_msg),\n",
        "                HumanMessage(content=user_msg)\n",
        "            ],\n",
        "            return_message_content_only=False\n",
        "        )\n",
        "        return responses[0].content"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "HumanLLMMonitor._check_and_init_vector_db(embedding_function=embedding_function, reset_db_indices=False)\n",
        "HumanLLMMonitor.check_init_class_db(force=True)\n",
        "\n",
        "# 1) Définition des LLM\n",
        "llmORchains_list = {\n",
        "    \"default_llm\": ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.2),\n",
        "    \"premium_llm\": ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.0),\n",
        "}\n",
        "\n",
        "# 2) Instancier chaque classe\n",
        "analyst_agent = AnalystGeneratorAgent(llmORchains_list, agent_name=\"AnalystGen\")\n",
        "doc_search_agent = DocumentSearchAgent(llmORchains_list, agent_name=\"DocSearch\")\n",
        "interview_agent = InterviewAgent(llmORchains_list, agent_name=\"Interview\")\n",
        "writer_agent = SectionWriterAgent(llmORchains_list, agent_name=\"Writer\")\n",
        "\n",
        "# 3) Premier test: Générer 3 analystes\n",
        "topic = \"The benefits of adopting LangGraph as an agent framework\"\n",
        "feedback = \"Add an entrepreneurial perspective\"\n",
        "analysts_list = analyst_agent.generate_analysts(topic=topic, max_analysts=3, feedback=feedback)\n",
        "print(\"\\n--- Step 1: Analysts Generated ---\")\n",
        "for i, item in enumerate(analysts_list):\n",
        "    print(f\"Analyst {i+1} => {item['raw_text'][:250]}...\")\n",
        "\n",
        "# 4) Exécution d'une recherche \"web\"\n",
        "# On imagine un bout de conversation:\n",
        "conversation = [HumanMessage(content=\"We want more info on HPC distributed training best practices\")]\n",
        "search_result = doc_search_agent.search_web(conversation)\n",
        "print(\"\\n--- Step 2: Search Web result ---\")\n",
        "print(search_result)\n",
        "\n",
        "# 5) Interview : Générer question + générer réponse\n",
        "persona_analyst = \"Name: HPC Analyst\\nRole: HPC Researcher\\nDescription: Focus on HPC synergy.\"\n",
        "conv_before = []  # Pas de conversation initiale\n",
        "question_msg = interview_agent.generate_question(persona=persona_analyst, conversation=conv_before)\n",
        "print(\"\\n--- Step 3a: Interview => Generated Question ---\")\n",
        "print(question_msg.content)\n",
        "\n",
        "# On simule qu'on va inclure la question dans la conversation:\n",
        "conv = [question_msg]  # La question comme AIMessage\n",
        "context_docs = \"HPC doc content => HPC HPC HPC...\"  # un petit context\n",
        "persona_expert = \"Name: HPC Expert\\nDescription: Senior HPC scientist.\"\n",
        "answer_msg = interview_agent.generate_answer(persona=persona_expert, conversation=conv, context=context_docs)\n",
        "print(\"\\n--- Step 3b: Interview => Generated Answer ---\")\n",
        "print(answer_msg.content)\n",
        "\n",
        "# 6) Rédaction de la section\n",
        "interview_text = question_msg.content + \"\\n---\\n\" + answer_msg.content\n",
        "doc_context = \"Doc HPC HPC HPC + additional references\"\n",
        "focus = \"Focus HPC synergy in large-scale parallel systems\"\n",
        "section_text = writer_agent.write_section(\n",
        "    interview_text=interview_text,\n",
        "    context=doc_context,\n",
        "    focus=focus\n",
        ")\n",
        "print(\"\\n--- Step 4: Section Writer => Output ---\")\n",
        "print(section_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyUpIkf8Jl38",
        "outputId": "5d57e613-73a8-43cf-aaf6-0503af3bf019"
      },
      "id": "PyUpIkf8Jl38",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[37m****AnalystGen>generate_analysts calling HumanLLMMonitor****\u001b[0m\n",
            "****agent : AnalystGen, automation : None****\n",
            "Adding agent data: {'agent_name': 'AnalystGen', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** AnalystGen->generate_analysts  BEFORE *****\n",
            "SYSTEM PROMPT:\n",
            "You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
            "\n",
            "1. First, review the research topic:\n",
            "The benefits of adopting LangGraph as an agent framework\n",
            "\n",
            "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
            "\n",
            "Add an entrepreneurial perspective\n",
            "\n",
            "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
            "\n",
            "4. Pick the top 3 themes.\n",
            "\n",
            "5. Assign one analyst to each theme.\n",
            "\n",
            "USER MESSAGE:\n",
            "Generate the set of analysts.\n",
            "***** AnalystGen->generate_analysts BEFORE *****\u001b[0m\n",
            "[A] Modify agent's system prompt\n",
            "[B] Give instruction or information to agent\n",
            "[C] Skip & set agent output (from recent or manually)\n",
            "[D] Log comments (not used by the model, just for information)\n",
            "[E] See previous results\n",
            "[F] See MODIFIED/SCORED/COMMENTED results\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[H] Change default agent\n",
            "[I] Change premium agent\n",
            "[J] Set num of parallel inferences (1, Synthesis=OFF)\n",
            "[K] Exit\n",
            "[P] Generate with a PREMIUM agent (default:False)\n",
            "[R] Activate/Deactivate inferences checks\n",
            "[Z] Continue\n",
            "\n",
            "\u001b[32mBEFORE\u001b[0m inference @ AnalystGen-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 2.8902299404144287, 'SELECTION': 2.890218496322632, 'Z': 9.059906005859375e-06} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "Temperature set to 0\n",
            "\u001b[0m**** New inference result recieved and added to outputs as #1\u001b[0m:\n",
            "Here’s a set of AI analyst personas based on the research topic and feedback provided:\n",
            "\n",
            "### Analyst 1: Innovation Strategist\n",
            "**Theme:** Enhancing Business Agility with LangGraph  \n",
            "**Description:** This analyst focuses on how adopting LangGraph can streamline operations and improve responsiveness to market changes. They explore the framework's capabilities in enabling rapid prototyping, iterative development, and real-time data analysis, which are crucial for businesses looking to stay competitive in a fast-paced environment.  \n",
            "**Background:** With a background in business development and technology innovation, this analyst has experience in helping startups leverage new technologies to enhance their operational efficiency and market adaptability.\n",
            "\n",
            "### Analyst 2: Cost Efficiency Expert\n",
            "**Theme:** Reducing Operational Costs through LangGraph  \n",
            "**Description:** This analyst examines the cost-saving potential of LangGraph as an agent framework. They analyze how the framework can reduce overhead by automating processes, minimizing manual intervention, and optimizing resource allocation. The focus is on providing a clear ROI for businesses considering the transition to LangGraph.  \n",
            "**Background:** With a background in financial analysis and operational management, this analyst specializes in identifying cost-saving opportunities and improving financial performance through technology adoption.\n",
            "\n",
            "### Analyst 3: Market Growth Advocate\n",
            "**Theme:** Driving Market Expansion with LangGraph  \n",
            "**Description:** This analyst investigates how LangGraph can facilitate market expansion for businesses. They look into the framework's capabilities in enhancing customer engagement, personalizing user experiences, and enabling data-driven decision-making that can lead to new market opportunities.  \n",
            "**Background:** With a background in marketing and business strategy, this analyst has a strong understanding of how technology can be leveraged to create competitive advantages and drive growth in various market segments.\n",
            "\n",
            "These personas provide a comprehensive view of the benefits of adopting LangGraph from different entrepreneurial perspectives, focusing on agility, cost efficiency, and market growth.\n",
            "\u001b[9mEND OF #1****\u001b[0m\n",
            "Processing LLM output 1 out of 1\n",
            "***AnalystGen, AFTER INFERENCE***\n",
            "No function definitions found.\n",
            "Adding agent data: {'agent_name': 'AnalystGen', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** AnalystGen->CallHumanLLM AFTER *****\n",
            "LLM ANSWER:\n",
            "Here’s a set of AI analyst personas based on the research topic and feedback provided:\n",
            "\n",
            "### Analyst 1: Innovation Strategist\n",
            "**Theme:** Enhancing Business Agility with LangGraph  \n",
            "**Description:** This analyst focuses on how adopting LangGraph can streamline operations and improve responsiveness to market changes. They explore the framework's capabilities in enabling rapid prototyping, iterative development, and real-time data analysis, which are crucial for businesses looking to stay competitive in a fast-paced environment.  \n",
            "**Background:** With a background in business development and technology innovation, this analyst has experience in helping startups leverage new technologies to enhance their operational efficiency and market adaptability.\n",
            "\n",
            "### Analyst 2: Cost Efficiency Expert\n",
            "**Theme:** Reducing Operational Costs through LangGraph  \n",
            "**Description:** This analyst examines the cost-saving potential of LangGraph as an agent framework. They analyze how the framework can reduce overhead by automating processes, minimizing manual intervention, and optimizing resource allocation. The focus is on providing a clear ROI for businesses considering the transition to LangGraph.  \n",
            "**Background:** With a background in financial analysis and operational management, this analyst specializes in identifying cost-saving opportunities and improving financial performance through technology adoption.\n",
            "\n",
            "### Analyst 3: Market Growth Advocate\n",
            "**Theme:** Driving Market Expansion with LangGraph  \n",
            "**Description:** This analyst investigates how LangGraph can facilitate market expansion for businesses. They look into the framework's capabilities in enhancing customer engagement, personalizing user experiences, and enabling data-driven decision-making that can lead to new market opportunities.  \n",
            "**Background:** With a background in marketing and business strategy, this analyst has a strong understanding of how technology can be leveraged to create competitive advantages and drive growth in various market segments.\n",
            "\n",
            "These personas provide a comprehensive view of the benefits of adopting LangGraph from different entrepreneurial perspectives, focusing on agility, cost efficiency, and market growth.\n",
            "\n",
            "***** AnalystGen->CallHumanLLM AFTER *****\u001b[0m\n",
            "[A] Edit answer in VSCode\n",
            "[B] Critic answer to regenerate it\n",
            "[C] Critic to improve agent's behavior\n",
            "[D] Evaluate answer\n",
            "[E] Go back (to BEFORE menu)\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[Z] Continue\n",
            "[H] Exit\n",
            "***AnalystGen, AFTER INFERENCE, after smart_print menu***\n",
            "\n",
            "\u001b[32mAFTER\u001b[0m inference @ AnalystGen-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 2.6907362937927246, 'SELECTION': 2.690701484680176, 'Z': 3.218650817871094e-05} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "\n",
            "--- Step 1: Analysts Generated ---\n",
            "Analyst 1 => Here’s a set of AI analyst personas based on the research topic and feedback provided:\n",
            "\n",
            "### Analyst 1: Innovation Strategist\n",
            "**Theme:** Enhancing Business Agility with LangGraph  \n",
            "**Description:** This analyst focuses on how adopting LangGraph can st...\n",
            "\u001b[37m****DocSearch>search_web calling HumanLLMMonitor****\u001b[0m\n",
            "****agent : DocSearch, automation : None****\n",
            "Adding agent data: {'agent_name': 'DocSearch', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** DocSearch->search_web  BEFORE *****\n",
            "SYSTEM PROMPT:\n",
            "You will be given a conversation between an analyst and an expert.\n",
            "\n",
            "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
            "\n",
            "First, analyze the full conversation.\n",
            "\n",
            "Pay particular attention to the final question posed by the analyst.\n",
            "\n",
            "Convert this final question into a well-structured web search query\n",
            "\n",
            "USER MESSAGE:\n",
            "We want more info on HPC distributed training best practices\n",
            "***** DocSearch->search_web BEFORE *****\u001b[0m\n",
            "[A] Modify agent's system prompt\n",
            "[B] Give instruction or information to agent\n",
            "[C] Skip & set agent output (from recent or manually)\n",
            "[D] Log comments (not used by the model, just for information)\n",
            "[E] See previous results\n",
            "[F] See MODIFIED/SCORED/COMMENTED results\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[H] Change default agent\n",
            "[I] Change premium agent\n",
            "[J] Set num of parallel inferences (1, Synthesis=OFF)\n",
            "[K] Exit\n",
            "[P] Generate with a PREMIUM agent (default:False)\n",
            "[R] Activate/Deactivate inferences checks\n",
            "[Z] Continue\n",
            "\n",
            "\u001b[32mBEFORE\u001b[0m inference @ DocSearch-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 2.6104178428649902, 'SELECTION': 2.610405445098877, 'Z': 1.049041748046875e-05} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "Temperature set to 0\n",
            "\u001b[0m**** New inference result recieved and added to outputs as #1\u001b[0m:\n",
            "\"best practices for HPC distributed training\"\n",
            "\u001b[9mEND OF #1****\u001b[0m\n",
            "Processing LLM output 1 out of 1\n",
            "***DocSearch, AFTER INFERENCE***\n",
            "No function definitions found.\n",
            "Adding agent data: {'agent_name': 'DocSearch', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** DocSearch->CallHumanLLM AFTER *****\n",
            "LLM ANSWER:\n",
            "\"best practices for HPC distributed training\"\n",
            "\n",
            "***** DocSearch->CallHumanLLM AFTER *****\u001b[0m\n",
            "[A] Edit answer in VSCode\n",
            "[B] Critic answer to regenerate it\n",
            "[C] Critic to improve agent's behavior\n",
            "[D] Evaluate answer\n",
            "[E] Go back (to BEFORE menu)\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[Z] Continue\n",
            "[H] Exit\n",
            "***DocSearch, AFTER INFERENCE, after smart_print menu***\n",
            "\n",
            "\u001b[32mAFTER\u001b[0m inference @ DocSearch-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 4.555875539779663, 'SELECTION': 4.555866241455078, 'Z': 6.9141387939453125e-06} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "\n",
            "--- Step 2: Search Web result ---\n",
            "[Simulé] Search done with query: \"best practices for HPC distributed training\"\n",
            "\u001b[37m****Interview>generate_question calling HumanLLMMonitor****\u001b[0m\n",
            "****agent : Interview, automation : None****\n",
            "Adding agent data: {'agent_name': 'Interview', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** Interview->generate_question  BEFORE *****\n",
            "SYSTEM PROMPT:\n",
            "You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
            "\n",
            "Your goal is boil down to interesting and specific insights related to your topic.\n",
            "\n",
            "1. Interesting: Insights that people will find surprising or non-obvious.\n",
            "\n",
            "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
            "\n",
            "Here is your topic of focus and set of goals: Name: HPC Analyst\n",
            "Role: HPC Researcher\n",
            "Description: Focus on HPC synergy.\n",
            "\n",
            "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
            "\n",
            "Continue to ask questions to drill down and refine your understanding of the topic.\n",
            "\n",
            "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
            "\n",
            "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\n",
            "\n",
            "USER MESSAGE:\n",
            "\n",
            "***** Interview->generate_question BEFORE *****\u001b[0m\n",
            "[A] Modify agent's system prompt\n",
            "[B] Give instruction or information to agent\n",
            "[C] Skip & set agent output (from recent or manually)\n",
            "[D] Log comments (not used by the model, just for information)\n",
            "[E] See previous results\n",
            "[F] See MODIFIED/SCORED/COMMENTED results\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[H] Change default agent\n",
            "[I] Change premium agent\n",
            "[J] Set num of parallel inferences (1, Synthesis=OFF)\n",
            "[K] Exit\n",
            "[P] Generate with a PREMIUM agent (default:False)\n",
            "[R] Activate/Deactivate inferences checks\n",
            "[Z] Continue\n",
            "\n",
            "\u001b[32mBEFORE\u001b[0m inference @ Interview-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 6.143991947174072, 'SELECTION': 6.143983602523804, 'Z': 6.4373016357421875e-06} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "Temperature set to 0\n",
            "\u001b[0m**** New inference result recieved and added to outputs as #1\u001b[0m:\n",
            "Hello! My name is Alex Carter, and I’m an HPC analyst focused on exploring the synergies within high-performance computing. I’m excited to learn from your expertise today. \n",
            "\n",
            "To start off, could you explain what you mean by \"HPC synergy\" and why it’s important in the context of high-performance computing?\n",
            "\u001b[9mEND OF #1****\u001b[0m\n",
            "Processing LLM output 1 out of 1\n",
            "***Interview, AFTER INFERENCE***\n",
            "No function definitions found.\n",
            "Adding agent data: {'agent_name': 'Interview', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** Interview->CallHumanLLM AFTER *****\n",
            "LLM ANSWER:\n",
            "Hello! My name is Alex Carter, and I’m an HPC analyst focused on exploring the synergies within high-performance computing. I’m excited to learn from your expertise today. \n",
            "\n",
            "To start off, could you explain what you mean by \"HPC synergy\" and why it’s important in the context of high-performance computing?\n",
            "\n",
            "***** Interview->CallHumanLLM AFTER *****\u001b[0m\n",
            "[A] Edit answer in VSCode\n",
            "[B] Critic answer to regenerate it\n",
            "[C] Critic to improve agent's behavior\n",
            "[D] Evaluate answer\n",
            "[E] Go back (to BEFORE menu)\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[Z] Continue\n",
            "[H] Exit\n",
            "***Interview, AFTER INFERENCE, after smart_print menu***\n",
            "\n",
            "\u001b[32mAFTER\u001b[0m inference @ Interview-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 14.290668964385986, 'SELECTION': 14.290650844573975, 'Z': 1.5497207641601562e-05} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "\n",
            "--- Step 3a: Interview => Generated Question ---\n",
            "Hello! My name is Alex Carter, and I’m an HPC analyst focused on exploring the synergies within high-performance computing. I’m excited to learn from your expertise today. \n",
            "\n",
            "To start off, could you explain what you mean by \"HPC synergy\" and why it’s important in the context of high-performance computing?\n",
            "\u001b[37m****Interview>generate_answer calling HumanLLMMonitor****\u001b[0m\n",
            "****agent : Interview, automation : None****\n",
            "Adding agent data: {'agent_name': 'Interview', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** Interview->generate_answer  BEFORE *****\n",
            "SYSTEM PROMPT:\n",
            "You are an expert being interviewed by an analyst.\n",
            "\n",
            "Here is analyst area of focus: Name: HPC Expert\n",
            "Description: Senior HPC scientist..\n",
            "\n",
            "You goal is to answer a question posed by the interviewer.\n",
            "\n",
            "To answer question, use this context:\n",
            "\n",
            "HPC doc content => HPC HPC HPC...\n",
            "\n",
            "When answering questions, follow these guidelines:\n",
            "\n",
            "1. Use only the information provided in the context.\n",
            "\n",
            "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
            "\n",
            "3. The context contain sources at the topic of each individual document.\n",
            "\n",
            "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
            "\n",
            "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
            "\n",
            "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
            "\n",
            "[1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "And skip the addition of the brackets as well as the Document source preamble in your citation.\n",
            "\n",
            "USER MESSAGE:\n",
            "Hello! My name is Alex Carter, and I’m an HPC analyst focused on exploring the synergies within high-performance computing. I’m excited to learn from your expertise today. \n",
            "\n",
            "To start off, could you explain what you mean by \"HPC synergy\" and why it’s important in the context of high-performance computing?\n",
            "***** Interview->generate_answer BEFORE *****\u001b[0m\n",
            "[A] Modify agent's system prompt\n",
            "[B] Give instruction or information to agent\n",
            "[C] Skip & set agent output (from recent or manually)\n",
            "[D] Log comments (not used by the model, just for information)\n",
            "[E] See previous results\n",
            "[F] See MODIFIED/SCORED/COMMENTED results\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[H] Change default agent\n",
            "[I] Change premium agent\n",
            "[J] Set num of parallel inferences (1, Synthesis=OFF)\n",
            "[K] Exit\n",
            "[P] Generate with a PREMIUM agent (default:False)\n",
            "[R] Activate/Deactivate inferences checks\n",
            "[Z] Continue\n",
            "\n",
            "\u001b[32mBEFORE\u001b[0m inference @ Interview-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 5.668940305709839, 'SELECTION': 5.668931007385254, 'Z': 7.3909759521484375e-06} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "Temperature set to 0\n",
            "\u001b[0m**** New inference result recieved and added to outputs as #1\u001b[0m:\n",
            "HPC synergy refers to the collaborative and integrated use of various high-performance computing resources and techniques to achieve enhanced performance and efficiency in computational tasks. This synergy is important because it allows for the optimization of workflows, better resource utilization, and the ability to tackle complex problems that require significant computational power. By leveraging the strengths of different HPC components—such as hardware, software, and algorithms—researchers and organizations can achieve results that would be difficult or impossible to obtain using isolated systems or approaches. \n",
            "\n",
            "In summary, HPC synergy is crucial for maximizing the potential of high-performance computing environments and driving innovation across various fields. \n",
            "\n",
            "[1] assistant/docs/llama3_1.pdf, page 7\n",
            "\u001b[9mEND OF #1****\u001b[0m\n",
            "Processing LLM output 1 out of 1\n",
            "***Interview, AFTER INFERENCE***\n",
            "No function definitions found.\n",
            "Adding agent data: {'agent_name': 'Interview', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** Interview->CallHumanLLM AFTER *****\n",
            "LLM ANSWER:\n",
            "HPC synergy refers to the collaborative and integrated use of various high-performance computing resources and techniques to achieve enhanced performance and efficiency in computational tasks. This synergy is important because it allows for the optimization of workflows, better resource utilization, and the ability to tackle complex problems that require significant computational power. By leveraging the strengths of different HPC components—such as hardware, software, and algorithms—researchers and organizations can achieve results that would be difficult or impossible to obtain using isolated systems or approaches. \n",
            "\n",
            "In summary, HPC synergy is crucial for maximizing the potential of high-performance computing environments and driving innovation across various fields. \n",
            "\n",
            "[1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "***** Interview->CallHumanLLM AFTER *****\u001b[0m\n",
            "[A] Edit answer in VSCode\n",
            "[B] Critic answer to regenerate it\n",
            "[C] Critic to improve agent's behavior\n",
            "[D] Evaluate answer\n",
            "[E] Go back (to BEFORE menu)\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[Z] Continue\n",
            "[H] Exit\n",
            "***Interview, AFTER INFERENCE, after smart_print menu***\n",
            "\n",
            "\u001b[32mAFTER\u001b[0m inference @ Interview-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 12.76206111907959, 'SELECTION': 12.762053966522217, 'Z': 5.245208740234375e-06} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "\n",
            "--- Step 3b: Interview => Generated Answer ---\n",
            "HPC synergy refers to the collaborative and integrated use of various high-performance computing resources and techniques to achieve enhanced performance and efficiency in computational tasks. This synergy is important because it allows for the optimization of workflows, better resource utilization, and the ability to tackle complex problems that require significant computational power. By leveraging the strengths of different HPC components—such as hardware, software, and algorithms—researchers and organizations can achieve results that would be difficult or impossible to obtain using isolated systems or approaches. \n",
            "\n",
            "In summary, HPC synergy is crucial for maximizing the potential of high-performance computing environments and driving innovation across various fields. \n",
            "\n",
            "[1] assistant/docs/llama3_1.pdf, page 7\n",
            "\u001b[37m****Writer>write_section calling HumanLLMMonitor****\u001b[0m\n",
            "****agent : Writer, automation : None****\n",
            "Adding agent data: {'agent_name': 'Writer', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** Writer->write_section  BEFORE *****\n",
            "SYSTEM PROMPT:\n",
            "You are an expert technical writer.\n",
            "\n",
            "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
            "\n",
            "1. Analyze the content of the source documents:\n",
            "- The name of each source document is at the start of the document, with the <Document tag.\n",
            "\n",
            "2. Create a report structure using markdown formatting:\n",
            "- Use ## for the section title\n",
            "- Use ### for sub-section headers\n",
            "\n",
            "3. Write the report following this structure:\n",
            "a. Title (## header)\n",
            "b. Summary (### header)\n",
            "c. Sources (### header)\n",
            "\n",
            "4. Make your title engaging based upon the focus area of the analyst:\n",
            "Focus HPC synergy in large-scale parallel systems\n",
            "\n",
            "5. For the summary section:\n",
            "- Set up summary with general background / context related to the focus area of the analyst\n",
            "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
            "- Create a numbered list of source documents, as you use them\n",
            "- Do not mention the names of interviewers or experts\n",
            "- Aim for approximately 400 words maximum\n",
            "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
            "\n",
            "6. In the Sources section:\n",
            "- Include all sources used in your report\n",
            "- Provide full links to relevant websites or specific document paths\n",
            "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
            "- It will look like:\n",
            "\n",
            "### Sources\n",
            "[1] Link or Document name\n",
            "[2] Link or Document name\n",
            "\n",
            "7. Be sure to combine sources. For example this is not correct:\n",
            "\n",
            "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "There should be no redundant sources. It should simply be:\n",
            "\n",
            "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "8. Final review:\n",
            "- Ensure the report follows the required structure\n",
            "- Include no preamble before the title of the report\n",
            "- Check that all guidelines have been followed\n",
            "\n",
            "USER MESSAGE:\n",
            "Use these docs: Doc HPC HPC HPC + additional references to write your section.\n",
            "Interview content: Hello! My name is Alex Carter, and I’m an HPC analyst focused on exploring the synergies within high-performance computing. I’m excited to learn from your expertise today. \n",
            "\n",
            "To start off, could you explain what you mean by \"HPC synergy\" and why it’s important in the context of high-performance computing?\n",
            "---\n",
            "HPC synergy refers to the collaborative and integrated use of various high-performance computing resources and techniques to achieve enhanced performance and efficiency in computational tasks. This synergy is important because it allows for the optimization of workflows, better resource utilization, and the ability to tackle complex problems that require significant computational power. By leveraging the strengths of different HPC components—such as hardware, software, and algorithms—researchers and organizations can achieve results that would be difficult or impossible to obtain using isolated systems or approaches. \n",
            "\n",
            "In summary, HPC synergy is crucial for maximizing the potential of high-performance computing environments and driving innovation across various fields. \n",
            "\n",
            "[1] assistant/docs/llama3_1.pdf, page 7\n",
            "***** Writer->write_section BEFORE *****\u001b[0m\n",
            "[A] Modify agent's system prompt\n",
            "[B] Give instruction or information to agent\n",
            "[C] Skip & set agent output (from recent or manually)\n",
            "[D] Log comments (not used by the model, just for information)\n",
            "[E] See previous results\n",
            "[F] See MODIFIED/SCORED/COMMENTED results\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[H] Change default agent\n",
            "[I] Change premium agent\n",
            "[J] Set num of parallel inferences (1, Synthesis=OFF)\n",
            "[K] Exit\n",
            "[P] Generate with a PREMIUM agent (default:False)\n",
            "[R] Activate/Deactivate inferences checks\n",
            "[Z] Continue\n",
            "\n",
            "\u001b[32mBEFORE\u001b[0m inference @ Writer-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 5.909400701522827, 'SELECTION': 5.909390687942505, 'Z': 7.62939453125e-06} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "Temperature set to 0\n",
            "\u001b[0m**** New inference result recieved and added to outputs as #1\u001b[0m:\n",
            "## Unleashing the Power of HPC Synergy in Large-Scale Parallel Systems\n",
            "\n",
            "### Summary\n",
            "High-performance computing (HPC) has become a cornerstone of modern computational research, enabling scientists and engineers to solve complex problems across various domains. At the heart of this evolution lies the concept of HPC synergy, which refers to the collaborative and integrated use of diverse HPC resources and techniques. This synergy is essential for optimizing workflows, enhancing resource utilization, and addressing intricate challenges that demand substantial computational power.\n",
            "\n",
            "Recent insights reveal that HPC synergy is not merely a theoretical concept but a practical necessity in today's computational landscape. By effectively combining hardware, software, and algorithms, researchers can achieve remarkable outcomes that would be unattainable with isolated systems. For instance, the integration of advanced algorithms with cutting-edge hardware can lead to significant performance improvements, allowing for faster data processing and analysis. This collaborative approach fosters innovation, enabling breakthroughs in fields such as climate modeling, genomics, and artificial intelligence.\n",
            "\n",
            "One surprising aspect of HPC synergy is its potential to democratize access to high-performance resources. As organizations increasingly adopt cloud-based HPC solutions, smaller institutions and individual researchers can leverage powerful computing capabilities that were once reserved for well-funded laboratories. This shift not only accelerates research but also promotes a more inclusive scientific community.\n",
            "\n",
            "Moreover, the importance of HPC synergy extends beyond technical performance. It encourages interdisciplinary collaboration, as experts from different fields come together to tackle shared challenges. This collaborative spirit is vital for addressing global issues, such as climate change and public health crises, where multifaceted approaches are required.\n",
            "\n",
            "In summary, HPC synergy is a driving force behind the advancement of high-performance computing, enabling researchers to maximize the potential of their computational environments. By fostering collaboration and integration, HPC synergy paves the way for innovative solutions to some of the most pressing challenges of our time.\n",
            "\n",
            "1. [1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "### Sources\n",
            "[1] assistant/docs/llama3_1.pdf\n",
            "\u001b[9mEND OF #1****\u001b[0m\n",
            "Processing LLM output 1 out of 1\n",
            "***Writer, AFTER INFERENCE***\n",
            "No function definitions found.\n",
            "Adding agent data: {'agent_name': 'Writer', 'data_key': 'saved_task'}\n",
            "User ID: Thomas-tp\n",
            "\u001b[37m***** Writer->CallHumanLLM AFTER *****\n",
            "LLM ANSWER:\n",
            "## Unleashing the Power of HPC Synergy in Large-Scale Parallel Systems\n",
            "\n",
            "### Summary\n",
            "High-performance computing (HPC) has become a cornerstone of modern computational research, enabling scientists and engineers to solve complex problems across various domains. At the heart of this evolution lies the concept of HPC synergy, which refers to the collaborative and integrated use of diverse HPC resources and techniques. This synergy is essential for optimizing workflows, enhancing resource utilization, and addressing intricate challenges that demand substantial computational power.\n",
            "\n",
            "Recent insights reveal that HPC synergy is not merely a theoretical concept but a practical necessity in today's computational landscape. By effectively combining hardware, software, and algorithms, researchers can achieve remarkable outcomes that would be unattainable with isolated systems. For instance, the integration of advanced algorithms with cutting-edge hardware can lead to significant performance improvements, allowing for faster data processing and analysis. This collaborative approach fosters innovation, enabling breakthroughs in fields such as climate modeling, genomics, and artificial intelligence.\n",
            "\n",
            "One surprising aspect of HPC synergy is its potential to democratize access to high-performance resources. As organizations increasingly adopt cloud-based HPC solutions, smaller institutions and individual researchers can leverage powerful computing capabilities that were once reserved for well-funded laboratories. This shift not only accelerates research but also promotes a more inclusive scientific community.\n",
            "\n",
            "Moreover, the importance of HPC synergy extends beyond technical performance. It encourages interdisciplinary collaboration, as experts from different fields come together to tackle shared challenges. This collaborative spirit is vital for addressing global issues, such as climate change and public health crises, where multifaceted approaches are required.\n",
            "\n",
            "In summary, HPC synergy is a driving force behind the advancement of high-performance computing, enabling researchers to maximize the potential of their computational environments. By fostering collaboration and integration, HPC synergy paves the way for innovative solutions to some of the most pressing challenges of our time.\n",
            "\n",
            "1. [1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "### Sources\n",
            "[1] assistant/docs/llama3_1.pdf\n",
            "\n",
            "***** Writer->CallHumanLLM AFTER *****\u001b[0m\n",
            "[A] Edit answer in VSCode\n",
            "[B] Critic answer to regenerate it\n",
            "[C] Critic to improve agent's behavior\n",
            "[D] Evaluate answer\n",
            "[E] Go back (to BEFORE menu)\n",
            "[G] Skip for N rounds (auto mode)\n",
            "[Z] Continue\n",
            "[H] Exit\n",
            "***Writer, AFTER INFERENCE, after smart_print menu***\n",
            "\n",
            "\u001b[32mAFTER\u001b[0m inference @ Writer-> Choose an action (or hit Enter for inference) :z\n",
            "Time spent in each option and occurrences: {'TOTAL': 14.690805196762085, 'SELECTION': 14.690791606903076, 'Z': 1.1205673217773438e-05} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\n",
            "\n",
            "--- Step 4: Section Writer => Output ---\n",
            "## Unleashing the Power of HPC Synergy in Large-Scale Parallel Systems\n",
            "\n",
            "### Summary\n",
            "High-performance computing (HPC) has become a cornerstone of modern computational research, enabling scientists and engineers to solve complex problems across various domains. At the heart of this evolution lies the concept of HPC synergy, which refers to the collaborative and integrated use of diverse HPC resources and techniques. This synergy is essential for optimizing workflows, enhancing resource utilization, and addressing intricate challenges that demand substantial computational power.\n",
            "\n",
            "Recent insights reveal that HPC synergy is not merely a theoretical concept but a practical necessity in today's computational landscape. By effectively combining hardware, software, and algorithms, researchers can achieve remarkable outcomes that would be unattainable with isolated systems. For instance, the integration of advanced algorithms with cutting-edge hardware can lead to significant performance improvements, allowing for faster data processing and analysis. This collaborative approach fosters innovation, enabling breakthroughs in fields such as climate modeling, genomics, and artificial intelligence.\n",
            "\n",
            "One surprising aspect of HPC synergy is its potential to democratize access to high-performance resources. As organizations increasingly adopt cloud-based HPC solutions, smaller institutions and individual researchers can leverage powerful computing capabilities that were once reserved for well-funded laboratories. This shift not only accelerates research but also promotes a more inclusive scientific community.\n",
            "\n",
            "Moreover, the importance of HPC synergy extends beyond technical performance. It encourages interdisciplinary collaboration, as experts from different fields come together to tackle shared challenges. This collaborative spirit is vital for addressing global issues, such as climate change and public health crises, where multifaceted approaches are required.\n",
            "\n",
            "In summary, HPC synergy is a driving force behind the advancement of high-performance computing, enabling researchers to maximize the potential of their computational environments. By fostering collaboration and integration, HPC synergy paves the way for innovative solutions to some of the most pressing challenges of our time.\n",
            "\n",
            "1. [1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "### Sources\n",
            "[1] assistant/docs/llama3_1.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Pj0yhqK9w2xi",
      "metadata": {
        "id": "Pj0yhqK9w2xi"
      },
      "source": [
        "# Task6. EXPERIMENTATION learn.py\n",
        "\n",
        "OBJECTIF: En 30mn, améliorer le score de départ avec une(des) fonction(s) existante(s) OU développer une nouvelle fonction aidant au score global => maximiser le score (plan + contenu + références)\n",
        "\n",
        "# 1. PREPARATION: adapter le code du graph d'agents LLM de génération de synthèse pour fonctionner avec learn.py\n",
        "- bot est le paramètre de la fonction qui sera executé, il est de type SynthesisManager, pour être noté il devra manipuler les fonctions de manipulation de section\n",
        "- s'aider du prompt au coder: https://github.com/doxav/CollabFunctionsGPTCreator/blob/main/prompts/IR_CPS_TechSynthesis/code_task.txt\n",
        "- les articles qui seront testé sont à définir dans learn.py env = EnvironmentManager(env_type=\"techsynthesis\", ...\n",
        "\n",
        "#2. Réalisation expérience en comparant 5 modes (bien garder les états pour pouvoir poursuivre les XP en auto)\n",
        "# OBJECTIF: comparer modes de collaboration et identifier des patterns efficaces (boucles d'amélioration du code, choisir d'améliorer les spécifications avant d'améliorer à nouveau le code).\n",
        "1.    XP en solo (note individuelle)\n",
        "2.    XP en équipe par tâche: 1 personne développe 1 tâche/fonction et s'occupe de chaque agent - possibilité de faire du semi-auto (automatisation sélective d'agents)\n",
        "3.    XP en équipe par rôle/agent: 1 personne max pour 1 agent, plusieurs tâches/fonctions sont développées en même temps- possibilité de faire du semi-auto (automatisation sélective d'agents)\n",
        "4.    XP en équipe en cascade: chaque personne reprend et améliore le travail de l'autre - possibilité de faire du semi-auto (automatisation sélective d'agents)\n",
        "5.    XP full auto\n",
        "\n",
        "# RENDU tableau des XPs en markdown - pour chaque XP:\n",
        "1.    identifiant de l'XP (unique_id à définir dans config.py)\n",
        "2.    type XP (indiquer le nom pour solo)\n",
        "3.    meilleurs scores (global, plan, contenu, ressource) - indiquer à quel moment\n",
        "4.    nouvelles fonctions développées ou améliorées\n",
        "5.    code\n",
        "6.    logs websocketdata_*\n",
        "7.    backup Elastic pour l'XP\n",
        "8.    vidéo courte sous-titrée des différentes stratégies effficaces dans sa séquence ou sa collaboration ou ses choix\n",
        "\n",
        "| Identifiant de l'XP | Type XP            | Meilleurs scores (global/plan/contenu/ressource) | Stratégies les + efficaces                     | Nouvelles fonctions développées ou améliorées | Lien GitHub Code | Lien GitHub Logs | Lien Backup XP        | Lien Vidéo Courte Sous-titrée stratégie |\n",
        "|----------------------|--------------------|-----------------------------------------------|------------------------------------------------|----------------------------------------------|------------------|------------------|-----------------------|--------------------------------|\n",
        "| xp_solo_01          | solo               | 0.8 / 0.7 / 0.9 / 0.6                         | ex: focus sur X et choix/séquences Y                          | ex: fonction X optimisée                     | [Code](#)       | [Logs](#)       | [Backup](#)          | [Vidéo](#)                     |\n",
        "| xp_colab_task_01     | colab task         | 0.7 / 0.8 / 0.6 / 0.7                         | ex: répartition des tâches selon...                   | ex: nouvelle fonction Y ajoutée              | [Code](#)       | [Logs](#)       | [Backup](#)          | [Vidéo](#)                     |\n",
        "| xp_colab_role_01     | colab role         | 0.9 / 0.6 / 0.8 / 0.7                         | ex: définition claire des rôles selon ...               | Amélioration de la gestion des rôles         | [Code](#)       | [Logs](#)       | [Backup](#)          | [Vidéo](#)                     |\n",
        "| xp_colab_cascade_01  | colab cascade      | 0.8 / 0.9 / 0.7 / 0.8                         | ex: choix relais humain ou LLM après X selon conditions Z          | Cascade d'actions automatisée                | [Code](#)       | [Logs](#)       | [Backup](#)          | [Vidéo](#)                     |\n",
        "| xp_full_auto_01      | full-auto          | 0.9 / 0.8 / 0.9 / 0.9                         | ex: automatisation complète                   | Automatisation complète du processus         | [Code](#)       | [Logs](#)       | [Backup](#)          | [Vidéo](#)                     |\n",
        "                  |\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jFoP7v2fEe6p",
      "metadata": {
        "id": "jFoP7v2fEe6p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6869b6-2f56-475a-b6d0-169da5e97f60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain/__init__.py:30: UserWarning: Importing LLMChain from langchain root module is no longer supported. Please use langchain.chains.LLMChain instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/langchain/llms/__init__.py:549: LangChainDeprecationWarning: Importing LLMs from langchain is deprecated. Importing from langchain will no longer be supported as of langchain==0.2.0. Please import from langchain-community instead:\n",
            "\n",
            "`from langchain_community.llms import OpenAI`.\n",
            "\n",
            "To install langchain-community run `pip install -U langchain-community`.\n",
            "  warnings.warn(\n",
            "Downloading readme: 100% 753/753 [00:00<00:00, 3.87MB/s]\n",
            "Downloading data: 100% 1.26M/1.26M [00:00<00:00, 4.01MB/s]\n",
            "Generating train split: 100% 50/50 [00:00<00:00, 855.25 examples/s]\n",
            "2025-01-26 14:24:24.700034: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-01-26 14:24:24.725433: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-01-26 14:24:24.733013: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-01-26 14:24:24.751771: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-01-26 14:24:26.359104: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/content/CollabFunctionsGPTCreator/utils/llm_utils.py:1146: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  HumanLLMMonitor.common_vectordb_embedding_function = OpenAIEmbeddings(model=embedding_function,\n",
            "/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'a2d11e78b3ec41bc9b90fbc0f76b852d.us-central1.gcp.cloud.es.io'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n",
            "Elasticsearch response: {\n",
            "  \"name\" : \"instance-0000000000\",\n",
            "  \"cluster_name\" : \"a2d11e78b3ec41bc9b90fbc0f76b852d\",\n",
            "  \"cluster_uuid\" : \"MPjklVoQQf-CPYciAv_0UA\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"8.17.0\",\n",
            "    \"build_flavor\" : \"default\",\n",
            "    \"build_type\" : \"docker\",\n",
            "    \"build_hash\" : \"2b6a7fed44faa321997703718f07ee0420804b41\",\n",
            "    \"build_date\" : \"2024-12-11T12:08:05.663969764Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"9.12.0\",\n",
            "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n",
            "\n",
            "/content/CollabFunctionsGPTCreator/utils/llm_utils.py:481: LangChainPendingDeprecationWarning: The class `ElasticsearchStore` will be deprecated in a future version. Use :class:`~Use class in langchain-elasticsearch package` instead.\n",
            "  self.db = ElasticsearchStore(\n",
            "Access to HMI via : file:///content/CollabFunctionsGPTCreator/Jquery_front/IHMv5-Monaco..html\n",
            "WebSocket server started on port 6789\n",
            "Starting localtunnel...\n",
            "Proxy established via localtunnel: https://curvy-chicken-love.loca.lt\n",
            "WebSocket Local URL: ws://localhost:6789?secret=3bf881d5-96a9-492b-9d53-5db3\n",
            "WebSocket Remote URL via proxy: https://doxav.github.io/CollabFunctionsGPTCreator/IHMv5-Monaco.html?wsUrl=https://curvy-chicken-love.loca.lt?secret=3bf881d5-96a9-492b-9d53-5db3\n",
            "{'envs', 'default_llmORchain', 'temperature_max', 'temperature_min', 'agent_name', 'system_prompt', 'task_parameters', 'fixed_coach', 'auto_n_rounds', 'output_schema', 'recommend_critics', 'prompt_critic', 'automation', 'saved_task', 'model_max_context_size', 'CPS_env_type', 'synthesize_mode', 'premium_llmORchain', 'num_parallel_inferences', 'llmORchains_list', 'inference_checks', 'premium_llm_by_default'}\n",
            "{'envs': [<env.IR_CPS_TechSynthesis.env.VoyagerEnvIR_CPS_TechSynthesis object at 0x7b1a17346050>, <env.IR_CPS_TechSynthesis.env.VoyagerEnvIR_CPS_TechSynthesis object at 0x7b1a18aa9ed0>], 'temperature_max': 1, 'temperature_min': 0.0, 'fixed_coach': False, 'auto_n_rounds': None, 'recommend_critics': None, 'automation': None, 'saved_task': None, 'num_parallel_inferences': 1, 'llmORchains_list': {'default_llm': ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17282990>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17bdfdd0>, root_client=<openai.OpenAI object at 0x7b1a17a09050>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17282b10>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), 'premium_llm': ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17c41a90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17c20850>, root_client=<openai.OpenAI object at 0x7b1a17b70210>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17c418d0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), '3_majority_chain': {\n",
            "  response_1: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17a0a510>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17c30d10>, root_client=<openai.OpenAI object at 0x7b1a17c20790>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17a0a6d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_2: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a179fca50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a1723d050>, root_client=<openai.OpenAI object at 0x7b1a17a06750>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a179fc910>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_3: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17235090>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17228f50>, root_client=<openai.OpenAI object at 0x7b1a1723d310>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17235250>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  cleaned_input: <learn.ExtractMessage object at 0x7b1a17229110>\n",
            "}\n",
            "| ChatPromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_2', 'response_3'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_2', 'response_3'], input_types={}, partial_variables={}, template='Given the following responses below and the initial question below, provide an optimal response to the question mixing best elements of each and following the same answer output structure:\\n\\nInitial question:\\n{cleaned_input}\\n\\nResponse 1:\\n{response_1}\\n\\nResponse 2:\\n{response_2}\\n\\nResponse 3:\\n{response_3}\\n\\nOptimal Response:\\n'), additional_kwargs={})])\n",
            "| <learn.PrintPromptRunnable object at 0x7b1a17211010>\n",
            "| ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17220ed0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17210dd0>, root_client=<openai.OpenAI object at 0x7b1a1723dd50>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17221090>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), '10_majority_chain': {\n",
            "  response_1: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a1720e550>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17206490>, root_client=<openai.OpenAI object at 0x7b1a17212710>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1720e710>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_2: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171fa410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171f6450>, root_client=<openai.OpenAI object at 0x7b1a17206710>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171fa5d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_3: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171e6410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171e2350>, root_client=<openai.OpenAI object at 0x7b1a171f6750>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171e65d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_4: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171da3d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171ce290>, root_client=<openai.OpenAI object at 0x7b1a171e2650>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171da590>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_5: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171c6290>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171be190>, root_client=<openai.OpenAI object at 0x7b1a171ce550>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171c6450>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_6: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171b2110>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171a9f90>, root_client=<openai.OpenAI object at 0x7b1a171be490>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171b22d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_7: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a1719df50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17195e10>, root_client=<openai.OpenAI object at 0x7b1a171aa290>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1719e110>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_8: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17389e10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17381e50>, root_client=<openai.OpenAI object at 0x7b1a17196110>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17389fd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_9: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17382350>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17369c50>, root_client=<openai.OpenAI object at 0x7b1a17382150>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1737a010>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_10: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17365bd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17359b90>, root_client=<openai.OpenAI object at 0x7b1a17369f10>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17365d90>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  cleaned_input: <learn.ExtractMessage object at 0x7b1a17345e50>\n",
            "}\n",
            "| ChatPromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_10', 'response_2', 'response_3', 'response_4', 'response_5', 'response_6', 'response_7', 'response_8', 'response_9'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_10', 'response_2', 'response_3', 'response_4', 'response_5', 'response_6', 'response_7', 'response_8', 'response_9'], input_types={}, partial_variables={}, template='Given the following responses below and the initial question below, provide an optimal response to the question mixing best elements of each and following the same answer output structure:\\n\\nInitial question:\\n{cleaned_input}\\n\\nResponse 1:\\n{response_1}\\n\\nResponse 2:\\n{response_2}\\n\\nResponse 3:\\n{response_3}\\n\\nResponse 4:\\n{response_4}\\n\\nResponse 5:\\n{response_5}\\n\\nResponse 6:\\n{response_6}\\n\\nResponse 7:\\n{response_7}\\n\\nResponse 8:\\n{response_8}\\n\\nResponse 9:\\n{response_9}\\n\\nResponse 10:\\n{response_10}\\n\\nOptimal Response:\\n'), additional_kwargs={})])\n",
            "| <learn.PrintPromptRunnable object at 0x7b1a17345e90>\n",
            "| ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17351b90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17352350>, root_client=<openai.OpenAI object at 0x7b1a17359e50>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17351d50>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))}, 'premium_llm_by_default': False}\n",
            "\n",
            "File load: graph_assistant_synthesis_persist_at_the_end.py - Shared Utility\n",
            "File load: graph_assistant_synthesis_each_agent.py - Shared Utility\n",
            "Smart_print: Notebook mode = False\n",
            "2025-01-26 14:24:46 - {\"message\": \"[35m****TaskIdentificationAgent>identify_best_task calling HumanLLMMonitor****[0m\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"HumanLLMMonitor\", \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": true, \"step_id\": 0}\n",
            "****agent : TaskIdentificationAgent, automation : None****\n",
            "****user_message TaskIdentificationAgent : \n",
            "    \n",
            "    - Existing code:[[[\n",
            "# helpers primitives:\n",
            "def create_analysts(state):\n",
            "    \"\"\" Create analysts  \"\"\"\n",
            "    # create_analysts's body...\n",
            "\n",
            "\n",
            "def human_feedback(state):\n",
            "    \"\"\" No-op node that should be interrupted on  \"\"\"\n",
            "    # human_feedback's body...\n",
            "\n",
            "\n",
            "def should_continue(state):\n",
            "    \"\"\" Return the next node to execute  \"\"\"\n",
            "    # should_continue's body...\n",
            "\n",
            "\n",
            "def generate_question(state):\n",
            "    \"\"\" Node to generate a question  \"\"\"\n",
            "    # generate_question's body...\n",
            "\n",
            "\n",
            "def search_web(state):\n",
            "    \"\"\" Retrieve academic papers from OpenAlex  \"\"\"\n",
            "    # search_web's body...\n",
            "\n",
            "\n",
            "def search_wikipedia(state):\n",
            "    \"\"\" Retrieve docs from wikipedia  \"\"\"\n",
            "    # search_wikipedia's body...\n",
            "\n",
            "\n",
            "def generate_answer(state):\n",
            "    \"\"\" Node to answer a question  \"\"\"\n",
            "    # generate_answer's body...\n",
            "\n",
            "\n",
            "def save_interview(state):\n",
            "    \"\"\" Save interviews  \"\"\"\n",
            "    # save_interview's body...\n",
            "\n",
            "\n",
            "def route_messages(state, name):\n",
            "    \"\"\" Route between question and answer  \"\"\"\n",
            "    # route_messages's body...\n",
            "\n",
            "\n",
            "def write_section(state):\n",
            "    \"\"\" Node to answer a question  \"\"\"\n",
            "    # write_section's body...\n",
            "\n",
            "\n",
            "def initiate_all_interviews(state):\n",
            "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API  \"\"\"\n",
            "    # initiate_all_interviews's body...\n",
            "\n",
            "\n",
            "def write_report(state):\n",
            "    # write_report's body...\n",
            "\n",
            "\n",
            "def write_introduction(state):\n",
            "    # write_introduction's body...\n",
            "\n",
            "\n",
            "def write_conclusion(state):\n",
            "    # write_conclusion's body...\n",
            "\n",
            "\n",
            "def finalize_report(state):\n",
            "    \"\"\" This is the \"reduce\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion  \"\"\"\n",
            "    # finalize_report's body...\n",
            "\n",
            "\n",
            "def persist_final_report_in_bot(bot, final_report):\n",
            "    \"\"\" Converts the final Markdown report into document sections,\n",
            "and extracts sources to store in bot.add_or_update_results_in_resources. \"\"\"\n",
            "    # persist_final_report_in_bot's body...\n",
            "\n",
            "\n",
            "def improve_multi_agent_research_generation(bot, max_analysts):\n",
            "    \"\"\" Generate a full research report using a multi-agent LangGraph workflow:  \n",
            "Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \n",
            "Write report, Write introduction, Write conclusion, Finalize report.\n",
            "Persist the document in the bot object through agent action.\n",
            "\n",
            "Args:\n",
            "    bot: The bot object with the necessary methods.\n",
            "    max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\n",
            "Returns:\n",
            "    str: The final markdown research report. \"\"\"\n",
            "    # improve_multi_agent_research_generation's body...\n",
            "\n",
            "\n",
            "def create_analysts_bot(state):\n",
            "    \"\"\" Create analysts  \"\"\"\n",
            "    # create_analysts_bot's body...\n",
            "\n",
            "\n",
            "def human_feedback_bot(state):\n",
            "    \"\"\" No-op node that should be interrupted on  \"\"\"\n",
            "    # human_feedback_bot's body...\n",
            "\n",
            "\n",
            "def generate_question_bot(state):\n",
            "    \"\"\" Node to generate a question  \"\"\"\n",
            "    # generate_question_bot's body...\n",
            "\n",
            "\n",
            "def search_web_bot(state):\n",
            "    \"\"\" Enhanced web search with proper resource persistence \"\"\"\n",
            "    # search_web_bot's body...\n",
            "\n",
            "\n",
            "def search_wikipedia_bot(state):\n",
            "    \"\"\" Retrieve docs from wikipedia  \"\"\"\n",
            "    # search_wikipedia_bot's body...\n",
            "\n",
            "\n",
            "def generate_answer_bot(state):\n",
            "    \"\"\" Node to answer a question  \"\"\"\n",
            "    # generate_answer_bot's body...\n",
            "\n",
            "\n",
            "def save_interview_bot(state):\n",
            "    \"\"\" Save interviews  \"\"\"\n",
            "    # save_interview_bot's body...\n",
            "\n",
            "\n",
            "def write_section_bot(state):\n",
            "    \"\"\" Enhanced section writing with proper structure persistence \"\"\"\n",
            "    # write_section_bot's body...\n",
            "\n",
            "\n",
            "def write_report_bot(state):\n",
            "    # write_report_bot's body...\n",
            "\n",
            "\n",
            "def write_introduction_bot(state):\n",
            "    # write_introduction_bot's body...\n",
            "\n",
            "\n",
            "def write_conclusion_bot(state):\n",
            "    # write_conclusion_bot's body...\n",
            "\n",
            "\n",
            "def finalize_report_bot(state):\n",
            "    \"\"\" Enhanced report finalization with proper structure \"\"\"\n",
            "    # finalize_report_bot's body...\n",
            "\n",
            "\n",
            "def multi_agent_research_generation_persist_each_agent(bot, max_analysts):\n",
            "    \"\"\" Generate a full research report using a multi-agent LangGraph workflow:  \n",
            "Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \n",
            "Write report, Write introduction, Write conclusion, Finalize report.\n",
            "Persist the document in the bot object through agent action.\n",
            "\n",
            "Args:\n",
            "    bot: The bot object with the necessary methods.\n",
            "    max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\n",
            "Returns:\n",
            "    str: The final markdown research report. \"\"\"\n",
            "    # multi_agent_research_generation_persist_each_agent's body...\n",
            "\n",
            "\n",
            "def persona(self):\n",
            "    # persona's body...\n",
            "\n",
            "\n",
            "def test_mock_bot():\n",
            "    # test_mock_bot's body...\n",
            "\n",
            "\n",
            "def __init__(self, title, context):\n",
            "    # __init__'s body...\n",
            "\n",
            "\n",
            "def create_and_add_section_then_return_id(self, title, content, section_id, parent_id):\n",
            "    # create_and_add_section_then_return_id's body...\n",
            "\n",
            "\n",
            "def get_all_sections(self):\n",
            "    # get_all_sections's body...\n",
            "\n",
            "\n",
            "def get_sections(self, ids):\n",
            "    # get_sections's body...\n",
            "\n",
            "\n",
            "def edit_section(self, section_id, new_content, new_title, new_parent_id):\n",
            "    # edit_section's body...\n",
            "\n",
            "\n",
            "def add_or_update_results_in_resources(self, results, metadatas_to_add, store_linked_document_content):\n",
            "    # add_or_update_results_in_resources's body...\n",
            "\n",
            "\n",
            "def add_or_update_result_in_resources(self, metadatas, name, content, link, store_linked_document_content):\n",
            "    # add_or_update_result_in_resources's body...\n",
            "\n",
            "\n",
            "def get_all_resources(self):\n",
            "    # get_all_resources's body...\n",
            "\n",
            "\n",
            "def semantic_search_resources(self, query_texts, n_results):\n",
            "    # semantic_search_resources's body...\n",
            "\n",
            "\n",
            "def remove_resource(self, resource_id):\n",
            "    # remove_resource's body...\n",
            "\n",
            "# Successful tasks implemented:\n",
            "\n",
            "# failed tasks / not implemented:\n",
            "\n",
            "]]]\n",
            "    - Current status of examples on which the task will be tested on: <<< Document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e properties:\n",
            "> Current table of content:\n",
            "Empty\n",
            "> Current resources: Empty\n",
            ">>>\n",
            "<<< Document #42252c6c-12f3-4edf-9045-8acd69bc3356 properties:\n",
            "> Current table of content:\n",
            "Empty\n",
            "> Current resources: Empty\n",
            ">>>\n",
            "    ****\n",
            "Adding agent data: {'agent_name': 'TaskIdentificationAgent', 'data_key': 'saved_task'}\n",
            "User ID: None\n",
            "2025-01-26 14:24:46 - {\"message\": \"User ID ?\", \"agent_name\": \"Learning Loop\", \"message_type\": \"USER_ID\", \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  892df7aa-1047-47eb-b871-d71bdc4b05b3\n",
            "2025-01-26 14:24:50 - {\"message\": \"[35m***** TaskIdentificationAgent->identify_best_task  BEFORE *****\\nSYSTEM PROMPT:\\n\\n    CONTEXT:\\n    You are an AI coach.\\n\\n    TASK DESCRIPTION:\\n    You define best next task to generate state-of-the-art research survey paper given a [Title] and an [Abstract] (properties from the bot object provided). Each task you propose will be prompted to a language model which will try to convert it into Python functions. If the code is successful and gains in technical synthesis above a pre-defined threshold, this learnt task is made available to the next learning iteration..\\n\\n    USER INPUT & STATE OF THE ENVIRONMENT:\\n    I will provide you:\\n- Learnt tasks available (with information gain between 0 and 1 on plan's titles, and contents): ...\\n- Failed tasks to learn that are too hard to code: ...\\n- Current status of examples of technical synthesis the proposed next task will be tested on: ....\\n\\n    CRITERIA:\\n1) Task should challenge the LLM while remaining solvable with available resources.\\n2) Your function should include appropriate modification to resources and sections to measure task success/performance.\\n3) Reason in 4 steps to find out the best task to minimize distance to goal.\\n4) Task should be written in the form of \\\"Task should be written in the form of [verb] [quantity if applicable] [object] [tools] [detailed instructions and parameters]\\\"\\n5) Task will be converted into Python code given available commands, learnt tasks. The Python code could call LLM when required.\\n6) Task should be novel compared to learnt and failed tasks.\\n7) Detail specifications (acceptance criteria, strategies/alternative to compare, use of LLM agents/tools/...) to successfully prompt a coder agent to generate code implementing the task while minimizing distance to goal. Organize the requirements with clear indexing to a depth of 3.\\n8) You should propose the next best novel task to implement 'given' available learnt tasks performance and LLM knowledge, 'maximizing' document generation quality, length and format, and speed to produce it.\\n9) You should propose a plan to achieve this task by breaking it down as a tree-structure. The plan tree should be of depth 3.\\n\\n    RESPONSE FORMAT:\\n    You should only respond in the Markdown format as described below:\\n        1. Reasoning: Analysis in 4 steps of the provided information to determine the next best task to develop, minimizing the distance to the goal\\n        2. Next Best Task:\\n            - Function Name: YourFunctionNameOfNextBestTaskIdentified\\n            - Description: .....\\n        3. Performance Acceptance Criteria:\\n            ...\\n        4. Development Plan:\\n            - Plan Depth: ...\\n            - Steps: ...\\n        5. Tests:\\n        ```python\\n        # document #125dc4bc-54e0-4336-82bc-417e40ec9b8f usage test:\\n        task_function_name(bot)\\n        # document #2fa754cb-2e90-3376-3b2c-142f29c9ebf8 usage test:\\n        task_function_name(bot)\\n        ```\\n    \\n    {'sources': 'exemples', 'num': 1, 'sort_order': 'by_date_asc', 'format': 'json'}\\n    \\n\\nUSER MESSAGE:\\n\\n    \\n    - Existing code:[[[\\n# helpers primitives:\\ndef create_analysts(state):\\n    \\\"\\\"\\\" Create analysts  \\\"\\\"\\\"\\n    # create_analysts's body...\\n\\n\\ndef human_feedback(state):\\n    \\\"\\\"\\\" No-op node that should be interrupted on  \\\"\\\"\\\"\\n    # human_feedback's body...\\n\\n\\ndef should_continue(state):\\n    \\\"\\\"\\\" Return the next node to execute  \\\"\\\"\\\"\\n    # should_continue's body...\\n\\n\\ndef generate_question(state):\\n    \\\"\\\"\\\" Node to generate a question  \\\"\\\"\\\"\\n    # generate_question's body...\\n\\n\\ndef search_web(state):\\n    \\\"\\\"\\\" Retrieve academic papers from OpenAlex  \\\"\\\"\\\"\\n    # search_web's body...\\n\\n\\ndef search_wikipedia(state):\\n    \\\"\\\"\\\" Retrieve docs from wikipedia  \\\"\\\"\\\"\\n    # search_wikipedia's body...\\n\\n\\ndef generate_answer(state):\\n    \\\"\\\"\\\" Node to answer a question  \\\"\\\"\\\"\\n    # generate_answer's body...\\n\\n\\ndef save_interview(state):\\n    \\\"\\\"\\\" Save interviews  \\\"\\\"\\\"\\n    # save_interview's body...\\n\\n\\ndef route_messages(state, name):\\n    \\\"\\\"\\\" Route between question and answer  \\\"\\\"\\\"\\n    # route_messages's body...\\n\\n\\ndef write_section(state):\\n    \\\"\\\"\\\" Node to answer a question  \\\"\\\"\\\"\\n    # write_section's body...\\n\\n\\ndef initiate_all_interviews(state):\\n    \\\"\\\"\\\" This is the \\\"map\\\" step where we run each interview sub-graph using Send API  \\\"\\\"\\\"\\n    # initiate_all_interviews's body...\\n\\n\\ndef write_report(state):\\n    # write_report's body...\\n\\n\\ndef write_introduction(state):\\n    # write_introduction's body...\\n\\n\\ndef write_conclusion(state):\\n    # write_conclusion's body...\\n\\n\\ndef finalize_report(state):\\n    \\\"\\\"\\\" This is the \\\"reduce\\\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion  \\\"\\\"\\\"\\n    # finalize_report's body...\\n\\n\\ndef persist_final_report_in_bot(bot, final_report):\\n    \\\"\\\"\\\" Converts the final Markdown report into document sections,\\nand extracts sources to store in bot.add_or_update_results_in_resources. \\\"\\\"\\\"\\n    # persist_final_report_in_bot's body...\\n\\n\\ndef improve_multi_agent_research_generation(bot, max_analysts):\\n    \\\"\\\"\\\" Generate a full research report using a multi-agent LangGraph workflow:  \\nCreate a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\nWrite report, Write introduction, Write conclusion, Finalize report.\\nPersist the document in the bot object through agent action.\\n\\nArgs:\\n    bot: The bot object with the necessary methods.\\n    max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\nReturns:\\n    str: The final markdown research report. \\\"\\\"\\\"\\n    # improve_multi_agent_research_generation's body...\\n\\n\\ndef create_analysts_bot(state):\\n    \\\"\\\"\\\" Create analysts  \\\"\\\"\\\"\\n    # create_analysts_bot's body...\\n\\n\\ndef human_feedback_bot(state):\\n    \\\"\\\"\\\" No-op node that should be interrupted on  \\\"\\\"\\\"\\n    # human_feedback_bot's body...\\n\\n\\ndef generate_question_bot(state):\\n    \\\"\\\"\\\" Node to generate a question  \\\"\\\"\\\"\\n    # generate_question_bot's body...\\n\\n\\ndef search_web_bot(state):\\n    \\\"\\\"\\\" Enhanced web search with proper resource persistence \\\"\\\"\\\"\\n    # search_web_bot's body...\\n\\n\\ndef search_wikipedia_bot(state):\\n    \\\"\\\"\\\" Retrieve docs from wikipedia  \\\"\\\"\\\"\\n    # search_wikipedia_bot's body...\\n\\n\\ndef generate_answer_bot(state):\\n    \\\"\\\"\\\" Node to answer a question  \\\"\\\"\\\"\\n    # generate_answer_bot's body...\\n\\n\\ndef save_interview_bot(state):\\n    \\\"\\\"\\\" Save interviews  \\\"\\\"\\\"\\n    # save_interview_bot's body...\\n\\n\\ndef write_section_bot(state):\\n    \\\"\\\"\\\" Enhanced section writing with proper structure persistence \\\"\\\"\\\"\\n    # write_section_bot's body...\\n\\n\\ndef write_report_bot(state):\\n    # write_report_bot's body...\\n\\n\\ndef write_introduction_bot(state):\\n    # write_introduction_bot's body...\\n\\n\\ndef write_conclusion_bot(state):\\n    # write_conclusion_bot's body...\\n\\n\\ndef finalize_report_bot(state):\\n    \\\"\\\"\\\" Enhanced report finalization with proper structure \\\"\\\"\\\"\\n    # finalize_report_bot's body...\\n\\n\\ndef multi_agent_research_generation_persist_each_agent(bot, max_analysts):\\n    \\\"\\\"\\\" Generate a full research report using a multi-agent LangGraph workflow:  \\nCreate a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\nWrite report, Write introduction, Write conclusion, Finalize report.\\nPersist the document in the bot object through agent action.\\n\\nArgs:\\n    bot: The bot object with the necessary methods.\\n    max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\nReturns:\\n    str: The final markdown research report. \\\"\\\"\\\"\\n    # multi_agent_research_generation_persist_each_agent's body...\\n\\n\\ndef persona(self):\\n    # persona's body...\\n\\n\\ndef test_mock_bot():\\n    # test_mock_bot's body...\\n\\n\\ndef __init__(self, title, context):\\n    # __init__'s body...\\n\\n\\ndef create_and_add_section_then_return_id(self, title, content, section_id, parent_id):\\n    # create_and_add_section_then_return_id's body...\\n\\n\\ndef get_all_sections(self):\\n    # get_all_sections's body...\\n\\n\\ndef get_sections(self, ids):\\n    # get_sections's body...\\n\\n\\ndef edit_section(self, section_id, new_content, new_title, new_parent_id):\\n    # edit_section's body...\\n\\n\\ndef add_or_update_results_in_resources(self, results, metadatas_to_add, store_linked_document_content):\\n    # add_or_update_results_in_resources's body...\\n\\n\\ndef add_or_update_result_in_resources(self, metadatas, name, content, link, store_linked_document_content):\\n    # add_or_update_result_in_resources's body...\\n\\n\\ndef get_all_resources(self):\\n    # get_all_resources's body...\\n\\n\\ndef semantic_search_resources(self, query_texts, n_results):\\n    # semantic_search_resources's body...\\n\\n\\ndef remove_resource(self, resource_id):\\n    # remove_resource's body...\\n\\n# Successful tasks implemented:\\n\\n# failed tasks / not implemented:\\n\\n]]]\\n    - Current status of examples on which the task will be tested on: <<< Document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>\\n<<< Document #42252c6c-12f3-4edf-9045-8acd69bc3356 properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>\\n    \\n***** TaskIdentificationAgent->identify_best_task BEFORE *****[0m\\n[A] Modify agent's system prompt\\n[B] Give instruction or information to agent\\n[C] Skip & set agent output (from recent or manually)\\n[D] Log comments (not used by the model, just for information)\\n[E] See previous results\\n[F] See MODIFIED/SCORED/COMMENTED results\\n[G] Skip for N rounds (auto mode)\\n[H] Change default agent\\n[I] Change premium agent\\n[J] Set num of parallel inferences (1, Synthesis=OFF)\\n[K] Exit\\n[P] Generate with a PREMIUM agent (default:False)\\n[R] Activate/Deactivate inferences checks\\n[Z] Continue\\n\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"BEFORE inference action MENU\", \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:24:50 - {\"message\": \"\\u001b[32mBEFORE\\u001b[0m inference @ TaskIdentificationAgent-> Choose an action (or hit Enter for inference) :\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": null, \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "Executing function 'get_tasks' for monitor 'TaskIdentificationAgent' with params: {'id_last_task': 'None'}\n",
            "Executing function 'get_tasks' for monitor 'TaskIdentificationAgent' with params: {'id_last_task': 'None'}\n",
            "Executing function 'get_tasks' for monitor 'TaskIdentificationAgent' with params: {'id_last_task': 'None'}\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  B\n",
            "2025-01-26 14:25:31 - {\"message\": \"ENTER ADDITIONAL INSTRUCTIONS FOR THE AGENT: \", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"ADDITIONAL_INFO\", \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  improve the function improve_multi_agent_research_generation and keep its name. you have to improve it to make it have better score\n",
            "2025-01-26 14:25:58 - {\"message\": \"[35m***** TaskIdentificationAgent->identify_best_task  BEFORE *****\\nSYSTEM PROMPT:\\n\\n    CONTEXT:\\n    You are an AI coach.\\n\\n    TASK DESCRIPTION:\\n    You define best next task to generate state-of-the-art research survey paper given a [Title] and an [Abstract] (properties from the bot object provided). Each task you propose will be prompted to a language model which will try to convert it into Python functions. If the code is successful and gains in technical synthesis above a pre-defined threshold, this learnt task is made available to the next learning iteration..\\n\\n    USER INPUT & STATE OF THE ENVIRONMENT:\\n    I will provide you:\\n- Learnt tasks available (with information gain between 0 and 1 on plan's titles, and contents): ...\\n- Failed tasks to learn that are too hard to code: ...\\n- Current status of examples of technical synthesis the proposed next task will be tested on: ....\\n\\n    CRITERIA:\\n1) Task should challenge the LLM while remaining solvable with available resources.\\n2) Your function should include appropriate modification to resources and sections to measure task success/performance.\\n3) Reason in 4 steps to find out the best task to minimize distance to goal.\\n4) Task should be written in the form of \\\"Task should be written in the form of [verb] [quantity if applicable] [object] [tools] [detailed instructions and parameters]\\\"\\n5) Task will be converted into Python code given available commands, learnt tasks. The Python code could call LLM when required.\\n6) Task should be novel compared to learnt and failed tasks.\\n7) Detail specifications (acceptance criteria, strategies/alternative to compare, use of LLM agents/tools/...) to successfully prompt a coder agent to generate code implementing the task while minimizing distance to goal. Organize the requirements with clear indexing to a depth of 3.\\n8) You should propose the next best novel task to implement 'given' available learnt tasks performance and LLM knowledge, 'maximizing' document generation quality, length and format, and speed to produce it.\\n9) You should propose a plan to achieve this task by breaking it down as a tree-structure. The plan tree should be of depth 3.\\n\\n    RESPONSE FORMAT:\\n    You should only respond in the Markdown format as described below:\\n        1. Reasoning: Analysis in 4 steps of the provided information to determine the next best task to develop, minimizing the distance to the goal\\n        2. Next Best Task:\\n            - Function Name: YourFunctionNameOfNextBestTaskIdentified\\n            - Description: .....\\n        3. Performance Acceptance Criteria:\\n            ...\\n        4. Development Plan:\\n            - Plan Depth: ...\\n            - Steps: ...\\n        5. Tests:\\n        ```python\\n        # document #125dc4bc-54e0-4336-82bc-417e40ec9b8f usage test:\\n        task_function_name(bot)\\n        # document #2fa754cb-2e90-3376-3b2c-142f29c9ebf8 usage test:\\n        task_function_name(bot)\\n        ```\\n    \\n    {'sources': 'exemples', 'num': 1, 'sort_order': 'by_date_asc', 'format': 'json'}\\n    \\n\\nUSER MESSAGE:\\n\\n    \\n    - Existing code:[[[\\n# helpers primitives:\\ndef create_analysts(state):\\n    \\\"\\\"\\\" Create analysts  \\\"\\\"\\\"\\n    # create_analysts's body...\\n\\n\\ndef human_feedback(state):\\n    \\\"\\\"\\\" No-op node that should be interrupted on  \\\"\\\"\\\"\\n    # human_feedback's body...\\n\\n\\ndef should_continue(state):\\n    \\\"\\\"\\\" Return the next node to execute  \\\"\\\"\\\"\\n    # should_continue's body...\\n\\n\\ndef generate_question(state):\\n    \\\"\\\"\\\" Node to generate a question  \\\"\\\"\\\"\\n    # generate_question's body...\\n\\n\\ndef search_web(state):\\n    \\\"\\\"\\\" Retrieve academic papers from OpenAlex  \\\"\\\"\\\"\\n    # search_web's body...\\n\\n\\ndef search_wikipedia(state):\\n    \\\"\\\"\\\" Retrieve docs from wikipedia  \\\"\\\"\\\"\\n    # search_wikipedia's body...\\n\\n\\ndef generate_answer(state):\\n    \\\"\\\"\\\" Node to answer a question  \\\"\\\"\\\"\\n    # generate_answer's body...\\n\\n\\ndef save_interview(state):\\n    \\\"\\\"\\\" Save interviews  \\\"\\\"\\\"\\n    # save_interview's body...\\n\\n\\ndef route_messages(state, name):\\n    \\\"\\\"\\\" Route between question and answer  \\\"\\\"\\\"\\n    # route_messages's body...\\n\\n\\ndef write_section(state):\\n    \\\"\\\"\\\" Node to answer a question  \\\"\\\"\\\"\\n    # write_section's body...\\n\\n\\ndef initiate_all_interviews(state):\\n    \\\"\\\"\\\" This is the \\\"map\\\" step where we run each interview sub-graph using Send API  \\\"\\\"\\\"\\n    # initiate_all_interviews's body...\\n\\n\\ndef write_report(state):\\n    # write_report's body...\\n\\n\\ndef write_introduction(state):\\n    # write_introduction's body...\\n\\n\\ndef write_conclusion(state):\\n    # write_conclusion's body...\\n\\n\\ndef finalize_report(state):\\n    \\\"\\\"\\\" This is the \\\"reduce\\\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion  \\\"\\\"\\\"\\n    # finalize_report's body...\\n\\n\\ndef persist_final_report_in_bot(bot, final_report):\\n    \\\"\\\"\\\" Converts the final Markdown report into document sections,\\nand extracts sources to store in bot.add_or_update_results_in_resources. \\\"\\\"\\\"\\n    # persist_final_report_in_bot's body...\\n\\n\\ndef improve_multi_agent_research_generation(bot, max_analysts):\\n    \\\"\\\"\\\" Generate a full research report using a multi-agent LangGraph workflow:  \\nCreate a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\nWrite report, Write introduction, Write conclusion, Finalize report.\\nPersist the document in the bot object through agent action.\\n\\nArgs:\\n    bot: The bot object with the necessary methods.\\n    max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\nReturns:\\n    str: The final markdown research report. \\\"\\\"\\\"\\n    # improve_multi_agent_research_generation's body...\\n\\n\\ndef create_analysts_bot(state):\\n    \\\"\\\"\\\" Create analysts  \\\"\\\"\\\"\\n    # create_analysts_bot's body...\\n\\n\\ndef human_feedback_bot(state):\\n    \\\"\\\"\\\" No-op node that should be interrupted on  \\\"\\\"\\\"\\n    # human_feedback_bot's body...\\n\\n\\ndef generate_question_bot(state):\\n    \\\"\\\"\\\" Node to generate a question  \\\"\\\"\\\"\\n    # generate_question_bot's body...\\n\\n\\ndef search_web_bot(state):\\n    \\\"\\\"\\\" Enhanced web search with proper resource persistence \\\"\\\"\\\"\\n    # search_web_bot's body...\\n\\n\\ndef search_wikipedia_bot(state):\\n    \\\"\\\"\\\" Retrieve docs from wikipedia  \\\"\\\"\\\"\\n    # search_wikipedia_bot's body...\\n\\n\\ndef generate_answer_bot(state):\\n    \\\"\\\"\\\" Node to answer a question  \\\"\\\"\\\"\\n    # generate_answer_bot's body...\\n\\n\\ndef save_interview_bot(state):\\n    \\\"\\\"\\\" Save interviews  \\\"\\\"\\\"\\n    # save_interview_bot's body...\\n\\n\\ndef write_section_bot(state):\\n    \\\"\\\"\\\" Enhanced section writing with proper structure persistence \\\"\\\"\\\"\\n    # write_section_bot's body...\\n\\n\\ndef write_report_bot(state):\\n    # write_report_bot's body...\\n\\n\\ndef write_introduction_bot(state):\\n    # write_introduction_bot's body...\\n\\n\\ndef write_conclusion_bot(state):\\n    # write_conclusion_bot's body...\\n\\n\\ndef finalize_report_bot(state):\\n    \\\"\\\"\\\" Enhanced report finalization with proper structure \\\"\\\"\\\"\\n    # finalize_report_bot's body...\\n\\n\\ndef multi_agent_research_generation_persist_each_agent(bot, max_analysts):\\n    \\\"\\\"\\\" Generate a full research report using a multi-agent LangGraph workflow:  \\nCreate a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\nWrite report, Write introduction, Write conclusion, Finalize report.\\nPersist the document in the bot object through agent action.\\n\\nArgs:\\n    bot: The bot object with the necessary methods.\\n    max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\nReturns:\\n    str: The final markdown research report. \\\"\\\"\\\"\\n    # multi_agent_research_generation_persist_each_agent's body...\\n\\n\\ndef persona(self):\\n    # persona's body...\\n\\n\\ndef test_mock_bot():\\n    # test_mock_bot's body...\\n\\n\\ndef __init__(self, title, context):\\n    # __init__'s body...\\n\\n\\ndef create_and_add_section_then_return_id(self, title, content, section_id, parent_id):\\n    # create_and_add_section_then_return_id's body...\\n\\n\\ndef get_all_sections(self):\\n    # get_all_sections's body...\\n\\n\\ndef get_sections(self, ids):\\n    # get_sections's body...\\n\\n\\ndef edit_section(self, section_id, new_content, new_title, new_parent_id):\\n    # edit_section's body...\\n\\n\\ndef add_or_update_results_in_resources(self, results, metadatas_to_add, store_linked_document_content):\\n    # add_or_update_results_in_resources's body...\\n\\n\\ndef add_or_update_result_in_resources(self, metadatas, name, content, link, store_linked_document_content):\\n    # add_or_update_result_in_resources's body...\\n\\n\\ndef get_all_resources(self):\\n    # get_all_resources's body...\\n\\n\\ndef semantic_search_resources(self, query_texts, n_results):\\n    # semantic_search_resources's body...\\n\\n\\ndef remove_resource(self, resource_id):\\n    # remove_resource's body...\\n\\n# Successful tasks implemented:\\n\\n# failed tasks / not implemented:\\n\\n]]]\\n    - Current status of examples on which the task will be tested on: <<< Document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>\\n<<< Document #42252c6c-12f3-4edf-9045-8acd69bc3356 properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>\\n    \\n***** TaskIdentificationAgent->identify_best_task BEFORE *****[0m\\n[A] Modify agent's system prompt\\n[B] Give instruction or information to agent\\n[C] Skip & set agent output (from recent or manually)\\n[D] Log comments (not used by the model, just for information)\\n[E] See previous results\\n[F] See MODIFIED/SCORED/COMMENTED results\\n[G] Skip for N rounds (auto mode)\\n[H] Change default agent\\n[I] Change premium agent\\n[J] Set num of parallel inferences (1, Synthesis=OFF)\\n[K] Exit\\n[P] Generate with a PREMIUM agent (default:False)\\n[R] Activate/Deactivate inferences checks\\n[Z] Continue\\n\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"BEFORE inference action MENU\", \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:25:58 - {\"message\": \"\\u001b[32mBEFORE\\u001b[0m inference @ TaskIdentificationAgent-> Choose an action (or hit Enter for inference) :\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": null, \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  Z\n",
            "2025-01-26 14:26:01 - {\"message\": \"Time spent in each option and occurrences: {'TOTAL': 70.55270671844482, 'SELECTION': 43.830461502075195, 'B': 26.72223448753357, 'Z': 7.3909759521484375e-06} - {'TOTAL': 2, 'SELECTION': 2, 'B': 1, 'Z': 1}\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": null, \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": true, \"step_id\": 0}\n",
            "Temperature set to 0\n",
            "2025-01-26 14:26:01 - {\"message\": \"\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"Inference streaming output\", \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:26:06 - {\"message\": \"1. **Reasoning**: \\n   - **Step 1**: The existing function `improve_multi_agent_research_generation` is designed to generate a full research report using a multi-agent workflow. However, it lacks a structured approach to writing sections and does not persist each section effectively.\\n   - **Step 2**: The current implementation merges sections except for the introduction and conclusion, which may lead to a lack of clarity and organization in the final report. Improving the section writing process and ensuring proper persistence can enhance the overall quality of the report.\\n   - **Step 3**: The goal is to enhance the function to ensure that each section is written and stored correctly, allowing for better organization and retrieval of information. This will also help in generating a more comprehensive and coherent report.\\n   - **Step 4**: By focusing on improving the writing and persistence of sections, we can challenge the LLM to create a more sophisticated workflow that includes detailed instructions for each step, ensuring that the report is well-structured and informative.\\n\\n\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"Inference streaming output 0\", \"append\": true, \"column_id\": 0, \"column_max\": 1, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:26:07 - {\"message\": \"2. **Next Best Task**:\\n   - **Function Name**: improve_multi_agent_research_generation\\n   - **Description**: Enhance the existing `improve_multi_agent_research_generation` function to include structured writing of sections, proper persistence of each section, and improved organization of the final report. This will involve creating distinct sections for each part of the research, ensuring that they are stored and retrieved effectively.\\n\\n\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"Inference streaming output 0\", \"append\": true, \"column_id\": 0, \"column_max\": 1, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:26:11 - {\"message\": \"3. **Performance Acceptance Criteria**:\\n   - The function should generate a report with clearly defined sections (e.g., introduction, methodology, results, discussion, conclusion).\\n   - Each section should be stored in the bot's resources for easy access and modification.\\n   - The final report should be coherent, well-organized, and formatted correctly in Markdown.\\n   - The function should handle errors gracefully and provide feedback if any step fails.\\n\\n\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"Inference streaming output 0\", \"append\": true, \"column_id\": 0, \"column_max\": 1, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:26:13 - {\"message\": \"4. **Development Plan**:\\n   - **Plan Depth**: 3\\n   - **Steps**:\\n     1. **Section Writing**:\\n        - 1.1. Create a function to write each section of the report.\\n        - 1.2. Ensure that each section is stored in the bot's resources.\\n        - 1.3. Implement a mechanism to retrieve and edit sections as needed.\\n     2. **Report Finalization**:\\n        - 2.1. Create a function to compile all sections into a final report.\\n        - 2.2. Ensure that the introduction and conclusion are written last, summarizing the content of the report.\\n        - 2.3. Format the final report in Markdown.\\n     3. **Error Handling and Feedback**:\\n        - 3.1. Implement error handling for each step of the process.\\n        - 3.2. Provide feedback to the user on the status of the report generation.\\n        - 3.3. Log any issues encountered during the process for future reference.\\n\\n\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"Inference streaming output 0\", \"append\": true, \"column_id\": 0, \"column_max\": 1, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:26:14 - {\"message\": \"5. **Tests**:\\n```python\\n# document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n# document #42252c6c-12f3-4edf-9045-8acd69bc3356 usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n```\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"Inference streaming output 0\", \"append\": true, \"column_id\": 0, \"column_max\": 1, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:26:14 - {\"message\": \"1. **Reasoning**: \\n   - **Step 1**: The existing function `improve_multi_agent_research_generation` is designed to generate a full research report using a multi-agent workflow. However, it lacks a structured approach to writing sections and does not persist each section effectively.\\n   - **Step 2**: The current implementation merges sections except for the introduction and conclusion, which may lead to a lack of clarity and organization in the final report. Improving the section writing process and ensuring proper persistence can enhance the overall quality of the report.\\n   - **Step 3**: The goal is to enhance the function to ensure that each section is written and stored correctly, allowing for better organization and retrieval of information. This will also help in generating a more comprehensive and coherent report.\\n   - **Step 4**: By focusing on improving the writing and persistence of sections, we can challenge the LLM to create a more sophisticated workflow that includes detailed instructions for each step, ensuring that the report is well-structured and informative.\\n\\n2. **Next Best Task**:\\n   - **Function Name**: improve_multi_agent_research_generation\\n   - **Description**: Enhance the existing `improve_multi_agent_research_generation` function to include structured writing of sections, proper persistence of each section, and improved organization of the final report. This will involve creating distinct sections for each part of the research, ensuring that they are stored and retrieved effectively.\\n\\n3. **Performance Acceptance Criteria**:\\n   - The function should generate a report with clearly defined sections (e.g., introduction, methodology, results, discussion, conclusion).\\n   - Each section should be stored in the bot's resources for easy access and modification.\\n   - The final report should be coherent, well-organized, and formatted correctly in Markdown.\\n   - The function should handle errors gracefully and provide feedback if any step fails.\\n\\n4. **Development Plan**:\\n   - **Plan Depth**: 3\\n   - **Steps**:\\n     1. **Section Writing**:\\n        - 1.1. Create a function to write each section of the report.\\n        - 1.2. Ensure that each section is stored in the bot's resources.\\n        - 1.3. Implement a mechanism to retrieve and edit sections as needed.\\n     2. **Report Finalization**:\\n        - 2.1. Create a function to compile all sections into a final report.\\n        - 2.2. Ensure that the introduction and conclusion are written last, summarizing the content of the report.\\n        - 2.3. Format the final report in Markdown.\\n     3. **Error Handling and Feedback**:\\n        - 3.1. Implement error handling for each step of the process.\\n        - 3.2. Provide feedback to the user on the status of the report generation.\\n        - 3.3. Log any issues encountered during the process for future reference.\\n\\n5. **Tests**:\\n```python\\n# document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n# document #42252c6c-12f3-4edf-9045-8acd69bc3356 usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n```\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"NEW inference result recieved\", \"append\": false, \"column_id\": 0, \"column_max\": 1, \"optional\": false, \"step_id\": 0}\n",
            "Processing LLM output 1 out of 1\n",
            "***TaskIdentificationAgent, AFTER INFERENCE***\n",
            "No function definitions found.\n",
            "Adding agent data: {'agent_name': 'TaskIdentificationAgent', 'data_key': 'saved_task'}\n",
            "User ID: 892DF7AA-1047-47EB-B871-D71BDC4B05B3\n",
            "2025-01-26 14:26:15 - {\"message\": \"[35m***** TaskIdentificationAgent->CallHumanLLM AFTER *****\\nLLM ANSWER:\\n1. **Reasoning**: \\n   - **Step 1**: The existing function `improve_multi_agent_research_generation` is designed to generate a full research report using a multi-agent workflow. However, it lacks a structured approach to writing sections and does not persist each section effectively.\\n   - **Step 2**: The current implementation merges sections except for the introduction and conclusion, which may lead to a lack of clarity and organization in the final report. Improving the section writing process and ensuring proper persistence can enhance the overall quality of the report.\\n   - **Step 3**: The goal is to enhance the function to ensure that each section is written and stored correctly, allowing for better organization and retrieval of information. This will also help in generating a more comprehensive and coherent report.\\n   - **Step 4**: By focusing on improving the writing and persistence of sections, we can challenge the LLM to create a more sophisticated workflow that includes detailed instructions for each step, ensuring that the report is well-structured and informative.\\n\\n2. **Next Best Task**:\\n   - **Function Name**: improve_multi_agent_research_generation\\n   - **Description**: Enhance the existing `improve_multi_agent_research_generation` function to include structured writing of sections, proper persistence of each section, and improved organization of the final report. This will involve creating distinct sections for each part of the research, ensuring that they are stored and retrieved effectively.\\n\\n3. **Performance Acceptance Criteria**:\\n   - The function should generate a report with clearly defined sections (e.g., introduction, methodology, results, discussion, conclusion).\\n   - Each section should be stored in the bot's resources for easy access and modification.\\n   - The final report should be coherent, well-organized, and formatted correctly in Markdown.\\n   - The function should handle errors gracefully and provide feedback if any step fails.\\n\\n4. **Development Plan**:\\n   - **Plan Depth**: 3\\n   - **Steps**:\\n     1. **Section Writing**:\\n        - 1.1. Create a function to write each section of the report.\\n        - 1.2. Ensure that each section is stored in the bot's resources.\\n        - 1.3. Implement a mechanism to retrieve and edit sections as needed.\\n     2. **Report Finalization**:\\n        - 2.1. Create a function to compile all sections into a final report.\\n        - 2.2. Ensure that the introduction and conclusion are written last, summarizing the content of the report.\\n        - 2.3. Format the final report in Markdown.\\n     3. **Error Handling and Feedback**:\\n        - 3.1. Implement error handling for each step of the process.\\n        - 3.2. Provide feedback to the user on the status of the report generation.\\n        - 3.3. Log any issues encountered during the process for future reference.\\n\\n5. **Tests**:\\n```python\\n# document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n# document #42252c6c-12f3-4edf-9045-8acd69bc3356 usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n```\\n\\n***** TaskIdentificationAgent->CallHumanLLM AFTER *****[0m\\n[A] Edit answer in VSCode\\n[B] Critic answer to regenerate it\\n[C] Critic to improve agent's behavior\\n[D] Evaluate answer\\n[E] Go back (to BEFORE menu)\\n[G] Skip for N rounds (auto mode)\\n[Z] Continue\\n[H] Exit\\n\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": \"AFTER inference action MENU\", \"append\": \"TaskIdentificationAgent\", \"column_id\": 0, \"column_max\": 1, \"optional\": false, \"step_id\": 0}\n",
            "***TaskIdentificationAgent, AFTER INFERENCE, after smart_print menu***\n",
            "2025-01-26 14:26:15 - {\"message\": \"\\n\\u001b[32mAFTER\\u001b[0m inference @ TaskIdentificationAgent-> Choose an action (or hit Enter for inference) :\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": null, \"column_id\": 0, \"column_max\": 1, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  Z\n",
            "2025-01-26 14:26:40 - {\"message\": \"Time spent in each option and occurrences: {'TOTAL': 24.610772609710693, 'SELECTION': 24.610759735107422, 'Z': 1.049041748046875e-05} - {'TOTAL': 1, 'SELECTION': 1, 'Z': 1}\", \"agent_name\": \"TaskIdentificationAgent\", \"message_type\": null, \"append\": false, \"column_id\": null, \"column_max\": 1, \"optional\": true, \"step_id\": 0}\n",
            "{'envs', 'default_llmORchain', 'temperature_max', 'temperature_min', 'agent_name', 'system_prompt', 'task_parameters', 'fixed_coach', 'auto_n_rounds', 'output_schema', 'recommend_critics', 'prompt_critic', 'automation', 'saved_task', 'model_max_context_size', 'CPS_env_type', 'synthesize_mode', 'premium_llmORchain', 'num_parallel_inferences', 'llmORchains_list', 'inference_checks', 'premium_llm_by_default'}\n",
            "{'envs': [<env.IR_CPS_TechSynthesis.env.VoyagerEnvIR_CPS_TechSynthesis object at 0x7b1a17346050>, <env.IR_CPS_TechSynthesis.env.VoyagerEnvIR_CPS_TechSynthesis object at 0x7b1a18aa9ed0>], 'temperature_max': 1.0, 'temperature_min': 0.0, 'auto_n_rounds': None, 'recommend_critics': None, 'automation': None, 'saved_task': None, 'num_parallel_inferences': 1, 'llmORchains_list': {'default_llm': ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17282990>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17bdfdd0>, root_client=<openai.OpenAI object at 0x7b1a17a09050>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17282b10>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), 'premium_llm': ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17c41a90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17c20850>, root_client=<openai.OpenAI object at 0x7b1a17b70210>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17c418d0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), '3_majority_chain': {\n",
            "  response_1: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17a0a510>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17c30d10>, root_client=<openai.OpenAI object at 0x7b1a17c20790>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17a0a6d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_2: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a179fca50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a1723d050>, root_client=<openai.OpenAI object at 0x7b1a17a06750>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a179fc910>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_3: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17235090>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17228f50>, root_client=<openai.OpenAI object at 0x7b1a1723d310>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17235250>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  cleaned_input: <learn.ExtractMessage object at 0x7b1a17229110>\n",
            "}\n",
            "| ChatPromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_2', 'response_3'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_2', 'response_3'], input_types={}, partial_variables={}, template='Given the following responses below and the initial question below, provide an optimal response to the question mixing best elements of each and following the same answer output structure:\\n\\nInitial question:\\n{cleaned_input}\\n\\nResponse 1:\\n{response_1}\\n\\nResponse 2:\\n{response_2}\\n\\nResponse 3:\\n{response_3}\\n\\nOptimal Response:\\n'), additional_kwargs={})])\n",
            "| <learn.PrintPromptRunnable object at 0x7b1a17211010>\n",
            "| ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17220ed0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17210dd0>, root_client=<openai.OpenAI object at 0x7b1a1723dd50>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17221090>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), '10_majority_chain': {\n",
            "  response_1: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a1720e550>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17206490>, root_client=<openai.OpenAI object at 0x7b1a17212710>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1720e710>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_2: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171fa410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171f6450>, root_client=<openai.OpenAI object at 0x7b1a17206710>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171fa5d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_3: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171e6410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171e2350>, root_client=<openai.OpenAI object at 0x7b1a171f6750>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171e65d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_4: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171da3d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171ce290>, root_client=<openai.OpenAI object at 0x7b1a171e2650>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171da590>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_5: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171c6290>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171be190>, root_client=<openai.OpenAI object at 0x7b1a171ce550>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171c6450>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_6: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171b2110>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171a9f90>, root_client=<openai.OpenAI object at 0x7b1a171be490>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171b22d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_7: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a1719df50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17195e10>, root_client=<openai.OpenAI object at 0x7b1a171aa290>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1719e110>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_8: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17389e10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17381e50>, root_client=<openai.OpenAI object at 0x7b1a17196110>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17389fd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_9: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17382350>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17369c50>, root_client=<openai.OpenAI object at 0x7b1a17382150>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1737a010>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_10: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17365bd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17359b90>, root_client=<openai.OpenAI object at 0x7b1a17369f10>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17365d90>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  cleaned_input: <learn.ExtractMessage object at 0x7b1a17345e50>\n",
            "}\n",
            "| ChatPromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_10', 'response_2', 'response_3', 'response_4', 'response_5', 'response_6', 'response_7', 'response_8', 'response_9'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_10', 'response_2', 'response_3', 'response_4', 'response_5', 'response_6', 'response_7', 'response_8', 'response_9'], input_types={}, partial_variables={}, template='Given the following responses below and the initial question below, provide an optimal response to the question mixing best elements of each and following the same answer output structure:\\n\\nInitial question:\\n{cleaned_input}\\n\\nResponse 1:\\n{response_1}\\n\\nResponse 2:\\n{response_2}\\n\\nResponse 3:\\n{response_3}\\n\\nResponse 4:\\n{response_4}\\n\\nResponse 5:\\n{response_5}\\n\\nResponse 6:\\n{response_6}\\n\\nResponse 7:\\n{response_7}\\n\\nResponse 8:\\n{response_8}\\n\\nResponse 9:\\n{response_9}\\n\\nResponse 10:\\n{response_10}\\n\\nOptimal Response:\\n'), additional_kwargs={})])\n",
            "| <learn.PrintPromptRunnable object at 0x7b1a17345e90>\n",
            "| ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17351b90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17352350>, root_client=<openai.OpenAI object at 0x7b1a17359e50>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17351d50>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))}}\n",
            "{'envs', 'default_llmORchain', 'temperature_max', 'temperature_min', 'agent_name', 'system_prompt', 'task_parameters', 'fixed_coach', 'auto_n_rounds', 'output_schema', 'recommend_critics', 'prompt_critic', 'automation', 'saved_task', 'model_max_context_size', 'CPS_env_type', 'synthesize_mode', 'premium_llmORchain', 'num_parallel_inferences', 'llmORchains_list', 'inference_checks', 'premium_llm_by_default'}\n",
            "{'envs': [<env.IR_CPS_TechSynthesis.env.VoyagerEnvIR_CPS_TechSynthesis object at 0x7b1a17346050>, <env.IR_CPS_TechSynthesis.env.VoyagerEnvIR_CPS_TechSynthesis object at 0x7b1a18aa9ed0>], 'temperature_max': None, 'auto_n_rounds': None, 'automation': None, 'saved_task': None, 'num_parallel_inferences': 1, 'llmORchains_list': {'default_llm': ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17282990>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17bdfdd0>, root_client=<openai.OpenAI object at 0x7b1a17a09050>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17282b10>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), 'premium_llm': ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17c41a90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17c20850>, root_client=<openai.OpenAI object at 0x7b1a17b70210>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17c418d0>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), '3_majority_chain': {\n",
            "  response_1: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17a0a510>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17c30d10>, root_client=<openai.OpenAI object at 0x7b1a17c20790>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17a0a6d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_2: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a179fca50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a1723d050>, root_client=<openai.OpenAI object at 0x7b1a17a06750>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a179fc910>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_3: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17235090>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17228f50>, root_client=<openai.OpenAI object at 0x7b1a1723d310>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17235250>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  cleaned_input: <learn.ExtractMessage object at 0x7b1a17229110>\n",
            "}\n",
            "| ChatPromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_2', 'response_3'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_2', 'response_3'], input_types={}, partial_variables={}, template='Given the following responses below and the initial question below, provide an optimal response to the question mixing best elements of each and following the same answer output structure:\\n\\nInitial question:\\n{cleaned_input}\\n\\nResponse 1:\\n{response_1}\\n\\nResponse 2:\\n{response_2}\\n\\nResponse 3:\\n{response_3}\\n\\nOptimal Response:\\n'), additional_kwargs={})])\n",
            "| <learn.PrintPromptRunnable object at 0x7b1a17211010>\n",
            "| ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17220ed0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17210dd0>, root_client=<openai.OpenAI object at 0x7b1a1723dd50>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17221090>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********')), '10_majority_chain': {\n",
            "  response_1: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a1720e550>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17206490>, root_client=<openai.OpenAI object at 0x7b1a17212710>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1720e710>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_2: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171fa410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171f6450>, root_client=<openai.OpenAI object at 0x7b1a17206710>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171fa5d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_3: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171e6410>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171e2350>, root_client=<openai.OpenAI object at 0x7b1a171f6750>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171e65d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_4: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171da3d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171ce290>, root_client=<openai.OpenAI object at 0x7b1a171e2650>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171da590>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_5: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171c6290>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171be190>, root_client=<openai.OpenAI object at 0x7b1a171ce550>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171c6450>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_6: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a171b2110>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a171a9f90>, root_client=<openai.OpenAI object at 0x7b1a171be490>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a171b22d0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_7: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a1719df50>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17195e10>, root_client=<openai.OpenAI object at 0x7b1a171aa290>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1719e110>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_8: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17389e10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17381e50>, root_client=<openai.OpenAI object at 0x7b1a17196110>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17389fd0>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_9: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17382350>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17369c50>, root_client=<openai.OpenAI object at 0x7b1a17382150>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a1737a010>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  response_10: ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17365bd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17359b90>, root_client=<openai.OpenAI object at 0x7b1a17369f10>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17365d90>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')),\n",
            "  cleaned_input: <learn.ExtractMessage object at 0x7b1a17345e50>\n",
            "}\n",
            "| ChatPromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_10', 'response_2', 'response_3', 'response_4', 'response_5', 'response_6', 'response_7', 'response_8', 'response_9'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['cleaned_input', 'response_1', 'response_10', 'response_2', 'response_3', 'response_4', 'response_5', 'response_6', 'response_7', 'response_8', 'response_9'], input_types={}, partial_variables={}, template='Given the following responses below and the initial question below, provide an optimal response to the question mixing best elements of each and following the same answer output structure:\\n\\nInitial question:\\n{cleaned_input}\\n\\nResponse 1:\\n{response_1}\\n\\nResponse 2:\\n{response_2}\\n\\nResponse 3:\\n{response_3}\\n\\nResponse 4:\\n{response_4}\\n\\nResponse 5:\\n{response_5}\\n\\nResponse 6:\\n{response_6}\\n\\nResponse 7:\\n{response_7}\\n\\nResponse 8:\\n{response_8}\\n\\nResponse 9:\\n{response_9}\\n\\nResponse 10:\\n{response_10}\\n\\nOptimal Response:\\n'), additional_kwargs={})])\n",
            "| <learn.PrintPromptRunnable object at 0x7b1a17345e90>\n",
            "| ChatOpenAI(cache=False, client=<openai.resources.chat.completions.Completions object at 0x7b1a17351b90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7b1a17352350>, root_client=<openai.OpenAI object at 0x7b1a17359e50>, root_async_client=<openai.AsyncOpenAI object at 0x7b1a17351d50>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))}}\n",
            "Adding agent data: {'step_id': 0, 'agent_name': 'CodingAgent', 'data_key': 'previous_errors'}\n",
            "User ID: None\n",
            "2025-01-26 14:26:42 - {\"message\": \"User ID ?\", \"agent_name\": \"Learning Loop\", \"message_type\": \"USER_ID\", \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  892df7aa-1047-47eb-b871-d71bdc4b05b3\n",
            "Adding agent data: {'step_id': 0, 'agent_name': 'CodingAgent', 'data_key': 'previous_codes', 'date': '2025-01-26 14:26:44.100960'}\n",
            "User ID: None\n",
            "2025-01-26 14:26:44 - {\"message\": \"User ID ?\", \"agent_name\": \"Learning Loop\", \"message_type\": \"USER_ID\", \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  892df7aa-1047-47eb-b871-d71bdc4b05b3\n",
            "Adding agent data: {'step_id': 0, 'agent_name': 'CodingAgent', 'data_key': 'previous_scores', 'date': '2025-01-26 14:26:48.033753'}\n",
            "User ID: None\n",
            "2025-01-26 14:26:48 - {\"message\": \"User ID ?\", \"agent_name\": \"Learning Loop\", \"message_type\": \"USER_ID\", \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  892df7aa-1047-47eb-b871-d71bdc4b05b3\n",
            "Adding agent data: {'step_id': 0, 'agent_name': 'CodingAgent', 'data_key': 'unique_codes', 'date': '2025-01-26 14:26:51.422575'}\n",
            "User ID: None\n",
            "2025-01-26 14:26:51 - {\"message\": \"User ID ?\", \"agent_name\": \"Learning Loop\", \"message_type\": \"USER_ID\", \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "SMART INPUT Received response from WebSocket\n",
            "SMART INPUT Answer:  892df7aa-1047-47eb-b871-d71bdc4b05b3\n",
            "Starting code_task_and_run_test\n",
            "File load: graph_assistant_synthesis_persist_at_the_end.py - Shared Utility\n",
            "File load: graph_assistant_synthesis_each_agent.py - Shared Utility\n",
            "Primitives: <<<\n",
            "from IPython.display import Image, display\n",
            "from langgraph.graph import START, END, StateGraph\n",
            "from langgraph.checkpoint.memory import MemorySaver\n",
            "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
            "from pydantic import BaseModel, Field\n",
            "from langgraph.graph import MessagesState\n",
            "import operator\n",
            "from typing import List, Annotated\n",
            "from typing_extensions import TypedDict\n",
            "from langchain_community.document_loaders import WikipediaLoader\n",
            "from langchain_core.messages import get_buffer_string\n",
            "from langgraph.constants import Send\n",
            "\n",
            "from langchain_openai import ChatOpenAI\n",
            "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
            "\n",
            "class Analyst(BaseModel):\n",
            "    affiliation: str = Field(\n",
            "        description=\"Primary affiliation of the analyst.\",\n",
            "    )\n",
            "    name: str = Field(\n",
            "        description=\"Name of the analyst.\"\n",
            "    )\n",
            "    role: str = Field(\n",
            "        description=\"Role of the analyst in the context of the topic.\",\n",
            "    )\n",
            "    description: str = Field(\n",
            "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
            "    )\n",
            "    @property\n",
            "    def persona(self) -> str:\n",
            "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
            "\n",
            "class Perspectives(BaseModel):\n",
            "    analysts: List[Analyst] = Field(\n",
            "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
            "    )\n",
            "\n",
            "class GenerateAnalystsState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "\n",
            "def create_analysts(state: GenerateAnalystsState):\n",
            "    \"\"\" Create analysts \"\"\"\n",
            "    if \"analyst_instructions\" not in state:\n",
            "        state['analyst_instructions'] = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
            "\n",
            "        1. First, review the research topic:\n",
            "        {topic}\n",
            "\n",
            "        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
            "        {human_analyst_feedback}\n",
            "\n",
            "        3. Determine the most interesting themes based upon documents and / or feedback above.\n",
            "\n",
            "        4. Pick the top {max_analysts} themes.\n",
            "\n",
            "        5. Assign one analyst to each theme.\n",
            "\n",
            "        Respond with a JSON object containing a list of analysts, where each analyst has:\n",
            "        - name: string\n",
            "        - role: string\n",
            "        - affiliation: string\n",
            "        - description: string\"\"\"\n",
            "    \n",
            "    analyst_instructions = state[\"analyst_instructions\"]\n",
            "\n",
            "    topic=state['topic']\n",
            "    max_analysts=state['max_analysts']\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', '')\n",
            "\n",
            "    # Enforce structured output\n",
            "    structured_llm = llm.with_structured_output(Perspectives)\n",
            "\n",
            "    # System message\n",
            "    system_message = analyst_instructions.format(topic=topic,\n",
            "                                                            human_analyst_feedback=human_analyst_feedback,\n",
            "                                                            max_analysts=max_analysts)\n",
            "\n",
            "    print(system_message)\n",
            "    # Generate question\n",
            "    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate the set of analysts.\")])\n",
            "    print(f\"Type of analysts: {type(analysts)}\")\n",
            "\n",
            "    # Write the list of analysis to state\n",
            "    return {\"analysts\": analysts.analysts}\n",
            "\n",
            "def create_analysts(state: GenerateAnalystsState):\n",
            "    \"\"\" Create analysts \"\"\"\n",
            "    if \"analyst_instructions\" not in state:\n",
            "        state['analyst_instructions'] = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
            "\n",
            "        1. First, review the research topic:\n",
            "        {topic}\n",
            "\n",
            "        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
            "        {human_analyst_feedback}\n",
            "\n",
            "        3. Determine the most interesting themes based upon documents and / or feedback above.\n",
            "\n",
            "        4. Pick the top {max_analysts} themes.\n",
            "\n",
            "        5. Assign one analyst to each theme.\n",
            "\n",
            "        Respond with a JSON object containing a list of analysts, where each analyst has:\n",
            "        - name: string\n",
            "        - role: string\n",
            "        - affiliation: string\n",
            "        - description: string\"\"\"\n",
            "    \n",
            "    analyst_instructions = state[\"analyst_instructions\"]\n",
            "    topic = state['topic']\n",
            "    max_analysts = state['max_analysts']\n",
            "    human_analyst_feedback = state.get('human_analyst_feedback', '')\n",
            "\n",
            "    # Enforce structured output\n",
            "    structured_llm = llm.with_structured_output(Perspectives)\n",
            "\n",
            "    # System message\n",
            "    system_message = analyst_instructions.format(\n",
            "        topic=topic,\n",
            "        human_analyst_feedback=human_analyst_feedback,\n",
            "        max_analysts=max_analysts\n",
            "    )\n",
            "\n",
            "    try:\n",
            "        # Generate analysts\n",
            "        analysts_response = structured_llm.invoke([\n",
            "            SystemMessage(content=system_message),\n",
            "            HumanMessage(content=\"Generate the set of analysts.\")\n",
            "        ])\n",
            "\n",
            "        # Handle different possible return types\n",
            "        if isinstance(analysts_response, Perspectives):\n",
            "            # If it's already a Perspectives object\n",
            "            generated_analysts = analysts_response.analysts\n",
            "        elif isinstance(analysts_response, dict):\n",
            "            # If it's a dict, try to extract analysts\n",
            "            generated_analysts = analysts_response.get('analysts', [])\n",
            "        elif hasattr(analysts_response, 'analysts'):\n",
            "            # If it has an analysts attribute\n",
            "            generated_analysts = analysts_response.analysts\n",
            "        else:\n",
            "            # Fallback to default analysts\n",
            "            generated_analysts = [\n",
            "                Analyst(\n",
            "                    name=f\"Analyst {i+1}\", \n",
            "                    role=f\"Research Specialist {i+1}\", \n",
            "                    affiliation=\"Research Institute\", \n",
            "                    description=f\"Analyzing aspects of {topic}\"\n",
            "                ) for i in range(max_analysts)\n",
            "            ]\n",
            "\n",
            "        # Ensure all are Analyst objects\n",
            "        generated_analysts = [\n",
            "            Analyst(**a.dict() if hasattr(a, 'dict') else a) \n",
            "            for a in generated_analysts\n",
            "        ]\n",
            "\n",
            "        return {\"analysts\": generated_analysts}\n",
            "\n",
            "    except Exception as e:\n",
            "        print(f\"Error generating analysts: {e}\")\n",
            "        # Fallback to default analysts\n",
            "        default_analysts = [\n",
            "            Analyst(\n",
            "                name=f\"Analyst {i+1}\", \n",
            "                role=f\"Research Specialist {i+1}\", \n",
            "                affiliation=\"Research Institute\", \n",
            "                description=f\"Analyzing aspects of {topic}\"\n",
            "            ) for i in range(max_analysts)\n",
            "        ]\n",
            "        return {\"analysts\": default_analysts}\n",
            "\n",
            "def human_feedback(state: GenerateAnalystsState):\n",
            "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
            "    pass\n",
            "\n",
            "def should_continue(state: GenerateAnalystsState):\n",
            "    \"\"\" Return the next node to execute \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', None)\n",
            "    if human_analyst_feedback:\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise end\n",
            "    return END\n",
            "\n",
            "class InterviewState(MessagesState):\n",
            "    max_num_turns: int # Number turns of conversation\n",
            "    context: Annotated[list, operator.add] # Source docs\n",
            "    analyst: Analyst # Analyst asking questions\n",
            "    interview: str # Interview transcript\n",
            "    sections: list # Final key we duplicate in outer state for Send() API\n",
            "\n",
            "class SearchQuery(BaseModel):\n",
            "    search_query: str = Field(None, description=\"Search query for retrieval.\")\n",
            "\n",
            "def generate_question(state: InterviewState):\n",
            "    \"\"\" Node to generate a question \"\"\"\n",
            "\n",
            "    # Check if question_instructions is provided by state\n",
            "    if \"question_instructions\" not in state:\n",
            "        state[\"question_instructions\"] = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
            "\n",
            "        Your goal is boil down to interesting and specific insights related to your topic.\n",
            "\n",
            "        1. Interesting: Insights that people will find surprising or non-obvious.\n",
            "\n",
            "        2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
            "\n",
            "        Here is your topic of focus and set of goals: {goals}\n",
            "\n",
            "        Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
            "\n",
            "        Continue to ask questions to drill down and refine your understanding of the topic.\n",
            "\n",
            "        When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
            "\n",
            "        Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
            "\n",
            "    question_instructions = state[\"question_instructions\"]\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Generate question\n",
            "    system_message = question_instructions.format(goals=analyst.persona)\n",
            "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Write messages to state\n",
            "    return {\"messages\": [question]}\n",
            "\n",
            "def search_web(state: InterviewState):\n",
            "    \"\"\" Retrieve academic papers from OpenAlex \"\"\"\n",
            "    import requests\n",
            "    OPENALEX_API_URL = \"https://api.openalex.org/works\"\n",
            "\n",
            "    # Search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    if \"search_instructions\" not in state:\n",
            "        state[\"search_instructions\"] = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
            "\n",
            "        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
            "\n",
            "        First, analyze the full conversation.\n",
            "\n",
            "        Pay particular attention to the final question posed by the analyst.\n",
            "\n",
            "        Convert this final question into a well-structured web search query\"\"\")\n",
            "    search_instructions = state[\"search_instructions\"]\n",
            "\n",
            "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
            "\n",
            "    # Construct the OpenAlex API query parameters\n",
            "    params = {\n",
            "        \"search\": search_query.search_query,\n",
            "        \"filter\": \"is_paratext:false\",  # Exclude non-research content\n",
            "        \"sort\": \"relevance_score:desc\",\n",
            "        \"per_page\": 5  # Limit to top 5 relevant results\n",
            "    }\n",
            "\n",
            "    # Perform the request to OpenAlex\n",
            "    response = requests.get(OPENALEX_API_URL, params=params)\n",
            "    search_docs = []\n",
            "    \n",
            "    if response.status_code == 200:\n",
            "        data = response.json()\n",
            "        for result in data.get(\"results\", []):\n",
            "            search_docs.append({\n",
            "                \"title\": result.get(\"title\", \"Unknown Title\"),\n",
            "                \"authors\": \", \".join([auth[\"author\"][\"display_name\"] for auth in result.get(\"authorships\", [])]),\n",
            "                \"abstract\": result.get(\"abstract\", \"No abstract available\"),\n",
            "                \"url\": result.get(\"id\", \"Unknown URL\")\n",
            "            })\n",
            "    else:\n",
            "        print(f\"Error retrieving data from OpenAlex: {response.status_code}\")\n",
            "\n",
            "    # Format results\n",
            "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
            "        [\n",
            "            f'<Document title=\"{doc[\"title\"]}\" href=\"{doc[\"url\"]}\">\\nAuthors: {doc[\"authors\"]}\\n\\nAbstract: {doc[\"abstract\"]}\\n</Document>'\n",
            "            for doc in search_docs\n",
            "        ]\n",
            "    )\n",
            "\n",
            "    return {\"context\": [formatted_search_docs]}\n",
            "\n",
            "def search_wikipedia(state: InterviewState):\n",
            "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
            "    # Check if search_instructions is provided by state\n",
            "    if \"search_instructions\" not in state:\n",
            "        state[\"search_instructions\"] = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
            "        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
            "        First, analyze the full conversation.\n",
            "        Pay particular attention to the final question posed by the analyst.\n",
            "        Convert this final question into a well-structured web search query\"\"\")\n",
            "\n",
            "    search_instructions = state[\"search_instructions\"]\n",
            "\n",
            "    # Search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
            "\n",
            "    # Search\n",
            "    search_docs = WikipediaLoader(query=search_query.search_query,\n",
            "                                  load_max_docs=2).load()\n",
            "\n",
            "     # Format\n",
            "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
            "        [\n",
            "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
            "            for doc in search_docs\n",
            "        ]\n",
            "    )\n",
            "\n",
            "    return {\"context\": [formatted_search_docs]}\n",
            "\n",
            "def generate_answer(state: InterviewState):\n",
            "    \"\"\" Node to answer a question \"\"\"\n",
            "    # Check if answer_instructions is provided by state\n",
            "    if \"answer_instructions\" not in state:\n",
            "        state[\"answer_instructions\"] = \"\"\"You are an expert being interviewed by an analyst.\n",
            "\n",
            "        Here is analyst area of focus: {goals}.\n",
            "\n",
            "        You goal is to answer a question posed by the interviewer.\n",
            "\n",
            "        To answer question, use this context:\n",
            "\n",
            "        {context}\n",
            "\n",
            "        When answering questions, follow these guidelines:\n",
            "\n",
            "        1. Use only the information provided in the context.\n",
            "\n",
            "        2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
            "\n",
            "        3. The context contain sources at the topic of each individual document.\n",
            "\n",
            "        4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
            "\n",
            "        5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
            "\n",
            "        6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
            "\n",
            "        [1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "        And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
            "\n",
            "    answer_instructions = state[\"answer_instructions\"]\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "    context = state[\"context\"]\n",
            "\n",
            "    # Answer question\n",
            "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
            "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Name the message as coming from the expert\n",
            "    answer.name = \"expert\"\n",
            "\n",
            "    # Append it to state\n",
            "    return {\"messages\": [answer]}\n",
            "\n",
            "def save_interview(state: InterviewState):\n",
            "\n",
            "    \"\"\" Save interviews \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Convert interview to a string\n",
            "    interview = get_buffer_string(messages)\n",
            "\n",
            "    # Save to interviews key\n",
            "    return {\"interview\": interview}\n",
            "\n",
            "def route_messages(state: InterviewState,\n",
            "                   name: str = \"expert\"):\n",
            "\n",
            "    \"\"\" Route between question and answer \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "    max_num_turns = state.get('max_num_turns',2)\n",
            "\n",
            "    # Check the number of expert answers\n",
            "    num_responses = len(\n",
            "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
            "    )\n",
            "\n",
            "    # End if expert has answered more than the max turns\n",
            "    if num_responses >= max_num_turns:\n",
            "        return 'save_interview'\n",
            "\n",
            "    # This router is run after each question - answer pair\n",
            "    # Get the last question asked to check if it signals the end of discussion\n",
            "    last_question = messages[-2]\n",
            "\n",
            "    if \"Thank you so much for your help\" in last_question.content:\n",
            "        return 'save_interview'\n",
            "    return \"ask_question\"\n",
            "\n",
            "def write_section(state: InterviewState):\n",
            "    \"\"\" Node to answer a question \"\"\"\n",
            "    # Check if section_writer_instructions is provided by state\n",
            "    if \"section_writer_instructions\" not in state:\n",
            "        state[\"section_writer_instructions\"] = \"\"\"You are an expert technical writer.\n",
            "\n",
            "        Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
            "\n",
            "        1. Analyze the content of the source documents:\n",
            "        - The name of each source document is at the start of the document, with the <Document tag.\n",
            "\n",
            "        2. Create a report structure using markdown formatting:\n",
            "        - Use ## for the section title\n",
            "        - Use ### for sub-section headers\n",
            "\n",
            "        3. Write the report following this structure:\n",
            "        a. Title (## header)\n",
            "        b. Summary (### header)\n",
            "        c. Sources (### header)\n",
            "\n",
            "        4. Make your title engaging based upon the focus area of the analyst:\n",
            "        {focus}\n",
            "\n",
            "        5. For the summary section:\n",
            "        - Set up summary with general background / context related to the focus area of the analyst\n",
            "        - Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
            "        - Create a numbered list of source documents, as you use them\n",
            "        - Do not mention the names of interviewers or experts\n",
            "        - Aim for approximately 400 words maximum\n",
            "        - Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
            "\n",
            "        6. In the Sources section:\n",
            "        - Include all sources used in your report\n",
            "        - Provide full links to relevant websites or specific document paths\n",
            "        - Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
            "        - It will look like:\n",
            "\n",
            "        ### Sources\n",
            "        [1] Link or Document name\n",
            "        [2] Link or Document name\n",
            "\n",
            "        7. Be sure to combine sources. For example this is not correct:\n",
            "\n",
            "        [3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "        [4] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "        There should be no redundant sources. It should simply be:\n",
            "\n",
            "        [3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "        8. Final review:\n",
            "        - Ensure the report follows the required structure\n",
            "        - Include no preamble before the title of the report\n",
            "        - Check that all guidelines have been followed\"\"\"\n",
            "\n",
            "    section_writer_instructions = state[\"section_writer_instructions\"]\n",
            "\n",
            "    # Get state\n",
            "    interview = state[\"interview\"]\n",
            "    context = state[\"context\"]\n",
            "    analyst = state[\"analyst\"]\n",
            "\n",
            "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
            "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
            "    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write your section: {context}\")])\n",
            "\n",
            "    # Append it to state\n",
            "    return {\"sections\": [section.content]}\n",
            "\n",
            "class ResearchGraphState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "    sections: Annotated[list, operator.add] # Send() API key\n",
            "    introduction: str # Introduction for the final report\n",
            "    content: str # Content for the final report\n",
            "    conclusion: str # Conclusion for the final report\n",
            "    final_report: str # Final report\n",
            "\n",
            "def initiate_all_interviews(state: ResearchGraphState):\n",
            "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
            "    if human_analyst_feedback:\n",
            "        # Return to create_analysts\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise kick off interviews in parallel via Send() API\n",
            "    else:\n",
            "        topic = state[\"topic\"]\n",
            "        return [Send(\"conduct_interview\", {\"analyst\": analyst,\n",
            "                                           \"messages\": [HumanMessage(\n",
            "                                               content=f\"So you said you were writing an article on {topic}?\"\n",
            "                                           )\n",
            "                                                       ]}) for analyst in state[\"analysts\"]]\n",
            "\n",
            "def write_report(state: ResearchGraphState):\n",
            "    # Check if report_writer_instructions is provided by state\n",
            "    if \"report_writer_instructions\" not in state:\n",
            "        state['report_writer_instructions'] = \"\"\"You are a technical writer creating a report on this overall topic:\n",
            "\n",
            "{topic}\n",
            "\n",
            "You have a team of analysts. Each analyst has done two things:\n",
            "\n",
            "1. They conducted an interview with an expert on a specific sub-topic.\n",
            "2. They write up their finding into a memo.\n",
            "\n",
            "Your task:\n",
            "\n",
            "1. You will be given a collection of memos from your analysts.\n",
            "2. Think carefully about the insights from each memo.\n",
            "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\n",
            "4. Summarize the central points in each memo into a cohesive single narrative.\n",
            "\n",
            "To format your report:\n",
            "\n",
            "1. Use markdown formatting.\n",
            "2. Include no pre-amble for the report.\n",
            "3. Use no sub-heading.\n",
            "4. Start your report with a single title header: ## Insights\n",
            "5. Do not mention any analyst names in your report.\n",
            "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
            "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
            "8. List your sources in order and do not repeat.\n",
            "\n",
            "[1] Source 1\n",
            "[2] Source 2\n",
            "\n",
            "Here are the memos from your analysts to build your report from:\n",
            "\n",
            "{context}\"\"\"\n",
            "\n",
            "    report_writer_instructions = state[\"report_writer_instructions\"]\n",
            "\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\n",
            "    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Write a report based upon these memos.\")])\n",
            "    return {\"content\": report.content}\n",
            "\n",
            "def write_introduction(state: ResearchGraphState):\n",
            "    # Check if intro_conclusion_instructions is provided by state\n",
            "    if \"intro_conclusion_instructions\" not in state:\n",
            "        state['intro_conclusion_instructions'] = \"\"\"You are a technical writer finishing a report on {topic}\n",
            "\n",
            "You will be given all of the sections of the report.\n",
            "\n",
            "You job is to write a crisp and compelling introduction or conclusion section.\n",
            "\n",
            "The user will instruct you whether to write the introduction or conclusion.\n",
            "\n",
            "Include no pre-amble for either section.\n",
            "\n",
            "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
            "\n",
            "Use markdown formatting.\n",
            "\n",
            "For your introduction, create a compelling title and use the # header for the title.\n",
            "\n",
            "For your introduction, use ## Introduction as the section header.\n",
            "\n",
            "For your conclusion, use ## Conclusion as the section header.\n",
            "\n",
            "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
            "\n",
            "    intro_conclusion_instructions = state[\"intro_conclusion_instructions\"]\n",
            "\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    intro = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report introduction\")])\n",
            "    return {\"introduction\": intro.content}\n",
            "\n",
            "def write_conclusion(state: ResearchGraphState):\n",
            "    # Check if intro_conclusion_instructions is provided by state\n",
            "    if \"intro_conclusion_instructions\" not in state:\n",
            "        state['intro_conclusion_instructions'] = \"\"\"You are a technical writer finishing a report on {topic}\n",
            "\n",
            "You will be given all of the sections of the report.\n",
            "\n",
            "You job is to write a crisp and compelling introduction or conclusion section.\n",
            "\n",
            "The user will instruct you whether to write the introduction or conclusion.\n",
            "\n",
            "Include no pre-amble for either section.\n",
            "\n",
            "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
            "\n",
            "Use markdown formatting.\n",
            "\n",
            "For your introduction, create a compelling title and use the # header for the title.\n",
            "\n",
            "For your introduction, use ## Introduction as the section header.\n",
            "\n",
            "For your conclusion, use ## Conclusion as the section header.\n",
            "\n",
            "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
            "\n",
            "    intro_conclusion_instructions = state[\"intro_conclusion_instructions\"]        \n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report conclusion\")])\n",
            "    return {\"conclusion\": conclusion.content}\n",
            "\n",
            "def finalize_report(state: ResearchGraphState):\n",
            "    \"\"\" This is the \"reduce\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion \"\"\"\n",
            "    if not state:\n",
            "        return {\"final_report\": \"\"}\n",
            "        \n",
            "    # Save full final report\n",
            "    content = state.get(\"content\", \"\")\n",
            "    introduction = state.get(\"introduction\", \"\")\n",
            "    conclusion = state.get(\"conclusion\", \"\")\n",
            "    \n",
            "    if content.startswith(\"## Insights\"):\n",
            "        content = content.strip(\"## Insights\")\n",
            "    \n",
            "    sources = None\n",
            "    if \"## Sources\" in content:\n",
            "        try:\n",
            "            content, sources = content.split(\"\\n## Sources\\n\")\n",
            "        except:\n",
            "            sources = None\n",
            "\n",
            "    final_report = \"\"\n",
            "    if introduction:\n",
            "        final_report += introduction + \"\\n\\n---\\n\\n\"\n",
            "    if content:\n",
            "        final_report += content\n",
            "    if conclusion:\n",
            "        final_report += \"\\n\\n---\\n\\n\" + conclusion\n",
            "    if sources:\n",
            "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
            "\n",
            "    return {\"final_report\": final_report}\n",
            "\n",
            "def persist_final_report_in_bot(bot, final_report):\n",
            "    \"\"\"\n",
            "    Converts the final Markdown report into document sections,\n",
            "    and extracts sources to store in bot.add_or_update_results_in_resources.\n",
            "    \"\"\"\n",
            "    # Handle None or empty input\n",
            "    if final_report is None:\n",
            "        final_report = {\"final_report\": \"\"}  # Create empty report instead of raising error\n",
            "        \n",
            "    # Handle dictionary input\n",
            "    if isinstance(final_report, dict):\n",
            "        final_report = final_report.get(\"final_report\", \"\")\n",
            "    \n",
            "    # Ensure we have a string\n",
            "    final_report = str(final_report)\n",
            "    \n",
            "    # If empty report, create minimal section\n",
            "    if not final_report.strip():\n",
            "        bot.create_and_add_section_then_return_id(\n",
            "            title=\"Empty Report\",\n",
            "            content=\"No content was generated.\"\n",
            "        )\n",
            "        return\n",
            "\n",
            "    import re\n",
            "    \n",
            "    # The rest of the function remains the same...\n",
            "    section_pattern = re.compile(r\"(##\\s+.+?)(?=##\\s|$)\", re.DOTALL)\n",
            "    \n",
            "    grand_titre_match = re.search(r\"^#\\s+(.*)\", final_report)\n",
            "    if grand_titre_match:\n",
            "        grand_titre = grand_titre_match.group(1).strip()\n",
            "        bot.create_and_add_section_then_return_id(\n",
            "            title=grand_titre,\n",
            "            content=f\"(Main Title)\\n\\n{grand_titre}\"\n",
            "        )\n",
            "    \n",
            "    sections = section_pattern.findall(final_report)\n",
            "\n",
            "    for section_md in sections:\n",
            "        lines = section_md.split('\\n', 1)\n",
            "        if len(lines) == 2:\n",
            "            section_title_line, section_body = lines\n",
            "        else:\n",
            "            section_title_line = lines[0]\n",
            "            section_body = \"\"\n",
            "\n",
            "        section_title = section_title_line.replace(\"##\", \"\").strip()\n",
            "        bot.create_and_add_section_then_return_id(title=section_title, content=section_body)\n",
            "\n",
            "    sources_block_match = re.search(r\"(##\\s+Sources.*)\", final_report, re.IGNORECASE | re.DOTALL)\n",
            "    if sources_block_match:\n",
            "        sources_block = sources_block_match.group(1)\n",
            "        \n",
            "        lines = sources_block.split('\\n')\n",
            "        resources_to_add = []\n",
            "        for line in lines:\n",
            "            m = re.match(r\"\\[(\\d+)\\]\\s+(.*)\", line.strip())\n",
            "            if m:\n",
            "                index = m.group(1)\n",
            "                url_or_name = m.group(2)\n",
            "                resource_item = {\n",
            "                    \"name\": f\"Source_{index}\",\n",
            "                    \"content\": {\"url\": url_or_name},\n",
            "                    \"metadatas\": {\"index\": index}\n",
            "                }\n",
            "                resources_to_add.append(resource_item)\n",
            "        \n",
            "        if resources_to_add:\n",
            "            bot.add_or_update_results_in_resources(\n",
            "                results=resources_to_add, \n",
            "                metadatas_to_add={\"type\": \"reference\"},\n",
            "                store_linked_document_content=False\n",
            "            )\n",
            "\n",
            "def improve_multi_agent_research_generation(bot, max_analysts: int = 3):\n",
            "    \"\"\"\n",
            "    Generate a full research report using a multi-agent LangGraph workflow:  \n",
            "    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \n",
            "    Write report, Write introduction, Write conclusion, Finalize report.\n",
            "    Persist the document in the bot object through agent action.\n",
            "    \n",
            "    Args:\n",
            "        bot: The bot object with the necessary methods.\n",
            "        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\n",
            "    Returns:\n",
            "        str: The final markdown research report.\n",
            "    \"\"\"\n",
            "    title, topic = bot.document.title, bot.document.context\n",
            "    # Create initial state with topic and max_analysts\n",
            "    initial_state: GenerateAnalystsState = { \"topic\": topic, \"max_analysts\": max_analysts, \"human_analyst_feedback\": None, \"analysts\": []}\n",
            "\n",
            "    # Recreate the interview graph within the function\n",
            "    interview_builder = StateGraph(InterviewState)\n",
            "    interview_builder.add_node(\"ask_question\", generate_question)\n",
            "    interview_builder.add_node(\"search_web\", search_web)\n",
            "    interview_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
            "    interview_builder.add_node(\"answer_question\", generate_answer)\n",
            "    interview_builder.add_node(\"save_interview\", save_interview)\n",
            "    interview_builder.add_node(\"write_section\", write_section)\n",
            "\n",
            "    # Flow\n",
            "    interview_builder.add_edge(START, \"ask_question\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
            "    interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
            "    interview_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
            "    interview_builder.add_conditional_edges(\"answer_question\", route_messages,['ask_question','save_interview'])\n",
            "    interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
            "    interview_builder.add_edge(\"write_section\", END)\n",
            "\n",
            "    # Compile interview graph\n",
            "    memory = MemorySaver()\n",
            "    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")\n",
            "\n",
            "    # Set up the thread configuration\n",
            "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
            "\n",
            "    # Compile the research graph\n",
            "    builder = StateGraph(ResearchGraphState)\n",
            "    builder.add_node(\"create_analysts\", create_analysts)\n",
            "    builder.add_node(\"human_feedback\", human_feedback)\n",
            "    \n",
            "    # Use the interview_graph directly, without .compile()\n",
            "    builder.add_node(\"conduct_interview\", interview_graph)\n",
            "    builder.add_node(\"write_report\", write_report)\n",
            "    builder.add_node(\"write_introduction\", write_introduction)\n",
            "    builder.add_node(\"write_conclusion\", write_conclusion)\n",
            "    builder.add_node(\"finalize_report\", finalize_report)\n",
            "\n",
            "    # Logic\n",
            "    builder.add_edge(START, \"create_analysts\")\n",
            "    builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
            "    builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
            "    builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_report\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
            "    builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
            "    builder.add_edge(\"finalize_report\", END)\n",
            "\n",
            "    # Compile the graph\n",
            "    memory2 = MemorySaver()\n",
            "    graph = builder.compile(checkpointer=memory2)\n",
            "    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
            "\n",
            "    # Invoke the graph\n",
            "    graph.invoke(initial_state, thread)\n",
            "\n",
            "    # Retrieve the final report\n",
            "    final_state = graph.get_state(thread)\n",
            "    report = final_state.values.get('final_report')\n",
            "\n",
            "    persist_final_report_in_bot(bot, report)\n",
            "    return report\n",
            "\n",
            "from IPython.display import Image, display\n",
            "from langgraph.graph import START, END, StateGraph\n",
            "from langgraph.checkpoint.memory import MemorySaver\n",
            "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
            "from pydantic import BaseModel, Field\n",
            "from langgraph.graph import MessagesState\n",
            "import operator\n",
            "from typing import List, Annotated\n",
            "from typing_extensions import TypedDict\n",
            "from langchain_community.document_loaders import WikipediaLoader\n",
            "from langchain_core.messages import get_buffer_string\n",
            "from langgraph.constants import Send\n",
            "from typing import List\n",
            "from typing_extensions import TypedDict\n",
            "from pydantic import BaseModel, Field\n",
            "from IPython.display import Image, display\n",
            "from langgraph.graph import START, END, StateGraph\n",
            "from langgraph.checkpoint.memory import MemorySaver\n",
            "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
            "import operator\n",
            "from typing import  Annotated\n",
            "from langgraph.graph import MessagesState\n",
            "import datetime\n",
            "import os\n",
            "from langchain_openai import ChatOpenAI\n",
            "# Wikipedia search tool\n",
            "from langchain_community.document_loaders import WikipediaLoader\n",
            "from langchain_core.messages import get_buffer_string\n",
            "\n",
            "# os.environ['OPENAI_BASE_URL'] = 'https://api.openai.com/v1'\n",
            "# os.environ['OPENROUTER_API_KEY'] = '\n",
            "# os.environ['OPENAI_API_KEY'] = os.environ['OPENROUTER_API_KEY']\n",
            "\n",
            "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
            "\n",
            "class Analyst(BaseModel):\n",
            "    affiliation: str = Field(\n",
            "        description=\"Primary affiliation of the analyst.\",\n",
            "    )\n",
            "    name: str = Field(\n",
            "        description=\"Name of the analyst.\"\n",
            "    )\n",
            "    role: str = Field(\n",
            "        description=\"Role of the analyst in the context of the topic.\",\n",
            "    )\n",
            "    description: str = Field(\n",
            "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
            "    )\n",
            "    @property\n",
            "    def persona(self) -> str:\n",
            "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
            "\n",
            "class Perspectives(BaseModel):\n",
            "    analysts: List[Analyst] = Field(\n",
            "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
            "    )\n",
            "\n",
            "class GenerateAnalystsState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "\n",
            "analyst_instructions=\"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
            "\n",
            "1. First, review the research topic:\n",
            "{topic}\n",
            "\n",
            "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
            "\n",
            "{human_analyst_feedback}\n",
            "\n",
            "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
            "\n",
            "4. Pick the top {max_analysts} themes.\n",
            "\n",
            "5. Assign one analyst to each theme.\"\"\"\n",
            "\n",
            "def create_analysts_bot(state: GenerateAnalystsState):\n",
            "\n",
            "    \"\"\" Create analysts \"\"\"\n",
            "\n",
            "    topic=state['topic']\n",
            "    max_analysts=state['max_analysts']\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', '')\n",
            "    print(f\"Topic: {topic}\")\n",
            "    print(f\"Max analysts: {max_analysts}\")\n",
            "    print(f\"Human analyst feedback: {human_analyst_feedback}\")\n",
            "\n",
            "    # Enforce structured output\n",
            "    structured_llm = llm.with_structured_output(Perspectives)\n",
            "\n",
            "    # System message\n",
            "    system_message = analyst_instructions.format(topic=topic,\n",
            "                                                            human_analyst_feedback=human_analyst_feedback,\n",
            "                                                            max_analysts=max_analysts)\n",
            "\n",
            "    # Generate question\n",
            "    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate the set of analysts.\")])\n",
            "    print(f\"Generated analysts: {analysts}\")\n",
            "    # print type of analysts\n",
            "    print(f\"Type of analysts: {type(analysts)}\")\n",
            "    # Write the list of analysis to state\n",
            "    #return { \"analysts\": analysts.analysts, \"sections\": state.get(\"sections\", []), \"context\": state.get(\"context\", []) }\n",
            "    #return {\"analysts\": analysts.analysts, \"sections\": state.get(\"sections\", []), \"messages\": state.get(\"messages\", []), \"context\": state.get(\"context\", []), \"human_analyst_feedback\": state.get(\"human_analyst_feedback\", None)}\n",
            "    return {\"analysts\": analysts.analysts}\n",
            "\n",
            "def human_feedback_bot(state: GenerateAnalystsState):\n",
            "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
            "    pass\n",
            "\n",
            "def should_continue(state: GenerateAnalystsState):\n",
            "    \"\"\" Return the next node to execute \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', None)\n",
            "    if human_analyst_feedback:\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise end\n",
            "    return END\n",
            "\n",
            "#further_feedack = None\n",
            "#graph.update_state(thread, {\"human_analyst_feedback\":further_feedack}, as_node=\"human_feedback\")\n",
            "class InterviewState(MessagesState):\n",
            "    max_num_turns: int = 2  # Add default value\n",
            "    context: Annotated[list, operator.add] = []  # Add default value\n",
            "    analyst: Analyst\n",
            "    interview: str = \"\"  # Add default value\n",
            "    sections: Annotated[list, operator.add] = []  # Add default value\n",
            "    messages: list = []  # Add default value\n",
            "\n",
            "class SearchQuery(BaseModel):\n",
            "    search_query: str = Field(None, description=\"Search query for retrieval.\")\n",
            "\n",
            "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
            "\n",
            "Your goal is boil down to interesting and specific insights related to your topic.\n",
            "\n",
            "1. Interesting: Insights that people will find surprising or non-obvious.\n",
            "\n",
            "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
            "\n",
            "Here is your topic of focus and set of goals: {goals}\n",
            "\n",
            "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
            "\n",
            "Continue to ask questions to drill down and refine your understanding of the topic.\n",
            "\n",
            "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
            "\n",
            "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
            "\n",
            "def generate_question_bot(state: InterviewState):\n",
            "    \"\"\" Node to generate a question \"\"\"\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Generate question\n",
            "    system_message = question_instructions.format(goals=analyst.persona)\n",
            "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Write messages to state\n",
            "    #return { \"messages\": [question], \"context\": state.get(\"context\", []), \"sections\": state.get(\"sections\", [])}\n",
            "    return {\"messages\": [question]}\n",
            "\n",
            "# Search query writing\n",
            "search_instructions = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
            "\n",
            "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
            "\n",
            "First, analyze the full conversation.\n",
            "\n",
            "Pay particular attention to the final question posed by the analyst.\n",
            "\n",
            "Convert this final question into a well-structured web search query\"\"\")\n",
            "\n",
            "def search_web_bot(state: InterviewState):\n",
            "    \"\"\"Enhanced web search with proper resource persistence\"\"\"\n",
            "    import requests\n",
            "    OPENALEX_API_URL = \"https://api.openalex.org/works\"\n",
            "    \n",
            "    # Get search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
            "    \n",
            "    # Search OpenAlex\n",
            "    params = {\n",
            "        \"search\": search_query.search_query,\n",
            "        \"filter\": \"is_paratext:false\",\n",
            "        \"sort\": \"relevance_score:desc\",\n",
            "        \"per_page\": 5\n",
            "    }\n",
            "    \n",
            "    response = requests.get(OPENALEX_API_URL, params=params)\n",
            "    search_docs = []\n",
            "    \n",
            "    if response.status_code == 200:\n",
            "        data = response.json()\n",
            "        \n",
            "        # Prepare resources for bot persistence\n",
            "        resources_to_add = []\n",
            "        for result in data.get(\"results\", []):\n",
            "            doc_info = {\n",
            "                \"title\": result.get(\"title\", \"Unknown Title\"),\n",
            "                \"link\": result.get(\"id\", \"Unknown URL\"),\n",
            "                \"description\": {\n",
            "                    \"abstract\": result.get(\"abstract\", \"No abstract available\"),\n",
            "                    \"authors\": \", \".join([auth[\"author\"][\"display_name\"] for auth in result.get(\"authorships\", [])])\n",
            "                }\n",
            "            }\n",
            "            search_docs.append(doc_info)\n",
            "            resources_to_add.append({\n",
            "                \"name\": doc_info[\"title\"],\n",
            "                \"link\": doc_info[\"link\"],\n",
            "                \"content\": doc_info[\"description\"]\n",
            "            })\n",
            "\n",
            "        # Persist to bot resources with metadata\n",
            "        bot = get_bot()\n",
            "        if bot:\n",
            "            bot.add_or_update_results_in_resources(\n",
            "                results=resources_to_add,\n",
            "                metadatas_to_add={\n",
            "                    \"source\": \"OpenAlex\",\n",
            "                    \"query\": search_query.search_query,\n",
            "                    \"search_timestamp\": str(datetime.now())\n",
            "                }\n",
            "            )\n",
            "\n",
            "    # Format for LLM consumption\n",
            "    formatted_docs = \"\\n\\n---\\n\\n\".join([\n",
            "        f'<Document title=\"{doc[\"title\"]}\" href=\"{doc[\"link\"]}\">\\nAuthors: {doc[\"description\"][\"authors\"]}\\nAbstract: {doc[\"description\"][\"abstract\"]}\\n</Document>'\n",
            "        for doc in search_docs\n",
            "    ])\n",
            "    \n",
            "    return {\"context\": [formatted_docs]}\n",
            "\n",
            "\n",
            "def search_wikipedia_bot(state: InterviewState):\n",
            "\n",
            "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
            "\n",
            "    # Search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
            "\n",
            "    # Search\n",
            "    search_docs = WikipediaLoader(query=search_query.search_query,\n",
            "                                  load_max_docs=2).load()\n",
            "\n",
            "     # Format\n",
            "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
            "        [\n",
            "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
            "            for doc in search_docs\n",
            "        ]\n",
            "    )\n",
            "\n",
            "    return {\"context\": [formatted_search_docs]}\n",
            "\n",
            "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
            "\n",
            "Here is analyst area of focus: {goals}.\n",
            "\n",
            "You goal is to answer a question posed by the interviewer.\n",
            "\n",
            "To answer question, use this context:\n",
            "\n",
            "{context}\n",
            "\n",
            "When answering questions, follow these guidelines:\n",
            "\n",
            "1. Use only the information provided in the context.\n",
            "\n",
            "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
            "\n",
            "3. The context contain sources at the topic of each individual document.\n",
            "\n",
            "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
            "\n",
            "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
            "\n",
            "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
            "\n",
            "[1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
            "\n",
            "def generate_answer_bot(state: InterviewState):\n",
            "\n",
            "    \"\"\" Node to answer a question \"\"\"\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "    context = state[\"context\"]\n",
            "\n",
            "    # Answer question\n",
            "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
            "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Name the message as coming from the expert\n",
            "    answer.name = \"expert\"\n",
            "\n",
            "    # Append it to state\n",
            "    return {\"messages\": [answer]}\n",
            "\n",
            "def save_interview_bot(state: InterviewState):\n",
            "\n",
            "    \"\"\" Save interviews \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Convert interview to a string\n",
            "    interview = get_buffer_string(messages)\n",
            "\n",
            "    # Save to interviews key\n",
            "    return {\"interview\": interview}\n",
            "\n",
            "def route_messages(state: InterviewState,\n",
            "                   name: str = \"expert\"):\n",
            "\n",
            "    \"\"\" Route between question and answer \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "    max_num_turns = state.get('max_num_turns',2)\n",
            "\n",
            "    # Check the number of expert answers\n",
            "    num_responses = len(\n",
            "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
            "    )\n",
            "\n",
            "    # End if expert has answered more than the max turns\n",
            "    if num_responses >= max_num_turns:\n",
            "        return 'save_interview'\n",
            "\n",
            "    # This router is run after each question - answer pair\n",
            "    # Get the last question asked to check if it signals the end of discussion\n",
            "    last_question = messages[-2]\n",
            "\n",
            "    if \"Thank you so much for your help\" in last_question.content:\n",
            "        return 'save_interview'\n",
            "    return \"ask_question\"\n",
            "\n",
            "section_writer_instructions = \"\"\"You are an expert technical writer.\n",
            "\n",
            "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
            "\n",
            "1. Analyze the content of the source documents:\n",
            "- The name of each source document is at the start of the document, with the <Document tag.\n",
            "\n",
            "2. Create a report structure using markdown formatting:\n",
            "- Use ## for the section title\n",
            "- Use ### for sub-section headers\n",
            "\n",
            "3. Write the report following this structure:\n",
            "a. Title (## header)\n",
            "b. Summary (### header)\n",
            "c. Sources (### header)\n",
            "\n",
            "4. Make your title engaging based upon the focus area of the analyst:\n",
            "{focus}\n",
            "\n",
            "5. For the summary section:\n",
            "- Set up summary with general background / context related to the focus area of the analyst\n",
            "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
            "- Create a numbered list of source documents, as you use them\n",
            "- Do not mention the names of interviewers or experts\n",
            "- Aim for approximately 400 words maximum\n",
            "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
            "\n",
            "6. In the Sources section:\n",
            "- Include all sources used in your report\n",
            "- Provide full links to relevant websites or specific document paths\n",
            "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
            "- It will look like:\n",
            "\n",
            "### Sources\n",
            "[1] Link or Document name\n",
            "[2] Link or Document name\n",
            "\n",
            "7. Be sure to combine sources. For example this is not correct:\n",
            "\n",
            "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "There should be no redundant sources. It should simply be:\n",
            "\n",
            "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "8. Final review:\n",
            "- Ensure the report follows the required structure\n",
            "- Include no preamble before the title of the report\n",
            "- Check that all guidelines have been followed\"\"\"\n",
            "\n",
            "def write_section_bot(state: InterviewState):\n",
            "    \"\"\"Enhanced section writing with proper structure persistence\"\"\"\n",
            "    interview = state[\"interview\"]\n",
            "    context = state[\"context\"]\n",
            "    analyst = state[\"analyst\"]\n",
            "    \n",
            "    section = llm.invoke([\n",
            "        SystemMessage(content=section_writer_instructions),\n",
            "        HumanMessage(content=f\"Write a section based on: {context}\")\n",
            "    ])\n",
            "    \n",
            "    bot = get_bot()\n",
            "    if bot:\n",
            "        try:\n",
            "            # Create main content section if doesn't exist\n",
            "            main_sections = bot.get_all_sections()\n",
            "            main_content_id = next(\n",
            "                (s.section_id for s in main_sections if s.title == \"Main Content\"), \n",
            "                None\n",
            "            )\n",
            "            \n",
            "            if not main_content_id:\n",
            "                main_content_id = bot.create_and_add_section_then_return_id(\n",
            "                    title=\"Main Content\",\n",
            "                    content=\"\",\n",
            "                    section_id=1  # Ensure it's first\n",
            "                )\n",
            "\n",
            "            # Add analyst's section as child\n",
            "            section_id = bot.create_and_add_section_then_return_id(\n",
            "                title=f\"Analysis by {analyst.name}\",\n",
            "                content=section.content,\n",
            "                parent_id=main_content_id\n",
            "            )\n",
            "            \n",
            "            # Store metadata about the section\n",
            "            bot.add_or_update_result_in_resources(\n",
            "                metadatas={\n",
            "                    \"section_id\": section_id,\n",
            "                    \"analyst\": analyst.name,\n",
            "                    \"analyst_role\": analyst.role,\n",
            "                    \"timestamp\": str(datetime.now())\n",
            "                },\n",
            "                name=f\"Section_{section_id}_Metadata\",\n",
            "                content={\"section_type\": \"analysis\", \"parent_section\": main_content_id}\n",
            "            )\n",
            "            \n",
            "        except Exception as e:\n",
            "            print(f\"Error persisting section: {e}\")\n",
            "            \n",
            "    return {\"sections\": [section.content]}\n",
            "\n",
            "\n",
            "class ResearchGraphState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "    sections: Annotated[list, operator.add] # Send() API key\n",
            "    introduction: str # Introduction for the final report\n",
            "    content: str # Content for the final report\n",
            "    conclusion: str # Conclusion for the final report\n",
            "    final_report: str # Final report\n",
            "\n",
            "def initiate_all_interviews(state: ResearchGraphState):\n",
            "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
            "    if human_analyst_feedback:\n",
            "        # Return to create_analysts\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise kick off interviews in parallel via Send() API\n",
            "    else:\n",
            "        topic = state[\"topic\"]\n",
            "        # return [Send(\"conduct_interview\", {\"analyst\": analyst,\n",
            "        #                                    \"messages\": [HumanMessage(\n",
            "        #                                        content=f\"So you said you were writing an article on {topic}?\"\n",
            "        #                                    )\n",
            "        #                                                ]}) for analyst in state[\"analysts\"]]\n",
            "        return [Send(\"conduct_interview\", {\n",
            "                    \"analyst\": analyst, \"messages\": [ HumanMessage( content=f\"So you said you were writing an article on {topic}?\")],\n",
            "                    \"max_num_turns\": 2,  # Add explicit max_num_turns\n",
            "                    \"context\": [],  # Add empty context\n",
            "                    \"sections\": [],  # Add empty sections\n",
            "                    \"interview\": \"\"  # Add empty interview\n",
            "                }\n",
            "            ) for analyst in state[\"analysts\"]\n",
            "        ]\n",
            "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic:\n",
            "\n",
            "{topic}\n",
            "\n",
            "You have a team of analysts. Each analyst has done two things:\n",
            "\n",
            "1. They conducted an interview with an expert on a specific sub-topic.\n",
            "2. They write up their finding into a memo.\n",
            "\n",
            "Your task:\n",
            "\n",
            "1. You will be given a collection of memos from your analysts.\n",
            "2. Think carefully about the insights from each memo.\n",
            "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\n",
            "4. Summarize the central points in each memo into a cohesive single narrative.\n",
            "\n",
            "To format your report:\n",
            "\n",
            "1. Use markdown formatting.\n",
            "2. Include no pre-amble for the report.\n",
            "3. Use no sub-heading.\n",
            "4. Start your report with a single title header: ## Insights\n",
            "5. Do not mention any analyst names in your report.\n",
            "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
            "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
            "8. List your sources in order and do not repeat.\n",
            "\n",
            "[1] Source 1\n",
            "[2] Source 2\n",
            "\n",
            "Here are the memos from your analysts to build your report from:\n",
            "\n",
            "{context}\"\"\"\n",
            "\n",
            "def write_report_bot(state: ResearchGraphState):\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\n",
            "    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Write a report based upon these memos.\")])\n",
            "    return {\"content\": report.content}\n",
            "\n",
            "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
            "\n",
            "You will be given all of the sections of the report.\n",
            "\n",
            "You job is to write a crisp and compelling introduction or conclusion section.\n",
            "\n",
            "The user will instruct you whether to write the introduction or conclusion.\n",
            "\n",
            "Include no pre-amble for either section.\n",
            "\n",
            "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
            "\n",
            "Use markdown formatting.\n",
            "\n",
            "For your introduction, create a compelling title and use the # header for the title.\n",
            "\n",
            "For your introduction, use ## Introduction as the section header.\n",
            "\n",
            "For your conclusion, use ## Conclusion as the section header.\n",
            "\n",
            "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
            "\n",
            "def write_introduction_bot(state: ResearchGraphState):\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    intro = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report introduction\")])\n",
            "    return {\"introduction\": intro.content}\n",
            "\n",
            "def write_conclusion_bot(state: ResearchGraphState):\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report conclusion\")])\n",
            "    return {\"conclusion\": conclusion.content}\n",
            "\n",
            "def finalize_report_bot(state: ResearchGraphState):\n",
            "    \"\"\"Enhanced report finalization with proper structure\"\"\"\n",
            "    content = state[\"content\"]\n",
            "    introduction = state[\"introduction\"]\n",
            "    conclusion = state[\"conclusion\"]\n",
            "    \n",
            "    bot = get_bot()\n",
            "    if bot:\n",
            "        try:\n",
            "            # Organize sections in proper order\n",
            "            intro_id = bot.create_and_add_section_then_return_id(\n",
            "                title=\"Introduction\",\n",
            "                content=introduction,\n",
            "                section_id=1\n",
            "            )\n",
            "            \n",
            "            content_id = bot.create_and_add_section_then_return_id(\n",
            "                title=\"Main Findings\",\n",
            "                content=content,\n",
            "                section_id=2\n",
            "            )\n",
            "            \n",
            "            conclusion_id = bot.create_and_add_section_then_return_id(\n",
            "                title=\"Conclusion\",\n",
            "                content=conclusion,\n",
            "                section_id=3\n",
            "            )\n",
            "            \n",
            "            # Add metadata about report structure\n",
            "            bot.add_or_update_result_in_resources(\n",
            "                metadatas={\n",
            "                    \"report_structure\": {\n",
            "                        \"introduction_id\": intro_id,\n",
            "                        \"content_id\": content_id,\n",
            "                        \"conclusion_id\": conclusion_id\n",
            "                    },\n",
            "                    \"generation_timestamp\": str(datetime.now())\n",
            "                },\n",
            "                name=\"Final_Report_Structure\"\n",
            "            )\n",
            "            \n",
            "            # Combine for final report\n",
            "            final_report = f\"{introduction}\\n\\n---\\n\\n{content}\\n\\n---\\n\\n{conclusion}\"\n",
            "            \n",
            "            # Store final assembled version\n",
            "            bot.create_and_add_section_then_return_id(\n",
            "                title=\"Complete Report\",\n",
            "                content=final_report,\n",
            "                section_id=4\n",
            "            )\n",
            "            \n",
            "        except Exception as e:\n",
            "            print(f\"Error finalizing report: {e}\")\n",
            "            final_report = f\"{introduction}\\n\\n---\\n\\n{content}\\n\\n---\\n\\n{conclusion}\"\n",
            "            \n",
            "    return {\"final_report\": final_report}\n",
            "\n",
            "def multi_agent_research_generation_persist_each_agent(bot, max_analysts: int = 3):\n",
            "    \"\"\"\n",
            "    Generate a full research report using a multi-agent LangGraph workflow:  \n",
            "    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \n",
            "    Write report, Write introduction, Write conclusion, Finalize report.\n",
            "    Persist the document in the bot object through agent action.\n",
            "    \n",
            "    Args:\n",
            "        bot: The bot object with the necessary methods.\n",
            "        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\n",
            "    Returns:\n",
            "        str: The final markdown research report.\n",
            "    \"\"\"\n",
            "    title, topic = bot.document.title, bot.document.context\n",
            "\n",
            "    global get_bot\n",
            "    get_bot = lambda: bot\n",
            "\n",
            "    # Create initial state with topic and max_analysts\n",
            "    #initial_state: GenerateAnalystsState = { \"topic\": topic, \"max_analysts\": max_analysts, \"human_analyst_feedback\": None, \"analysts\": [], \"sections\": [],  \"messages\": [], \"context\": [] }\n",
            "    initial_state: GenerateAnalystsState = { \"topic\": topic, \"max_analysts\": max_analysts, \"human_analyst_feedback\": None, \"analysts\": []}\n",
            "    # Recreate the interview graph within the function\n",
            "    interview_builder = StateGraph(InterviewState)\n",
            "    interview_builder.add_node(\"ask_question\", generate_question_bot)\n",
            "    interview_builder.add_node(\"search_web\", search_web_bot)\n",
            "    interview_builder.add_node(\"search_wikipedia\", search_wikipedia_bot)\n",
            "    interview_builder.add_node(\"answer_question\", generate_answer_bot)\n",
            "    interview_builder.add_node(\"save_interview\", save_interview_bot)\n",
            "    interview_builder.add_node(\"write_section\", write_section_bot)\n",
            "\n",
            "    # Flow\n",
            "    interview_builder.add_edge(START, \"ask_question\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
            "    interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
            "    interview_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
            "    interview_builder.add_conditional_edges(\"answer_question\", route_messages,['ask_question','save_interview'])\n",
            "    interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
            "    interview_builder.add_edge(\"write_section\", END)\n",
            "\n",
            "    # Compile interview graph\n",
            "    memory = MemorySaver()\n",
            "    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")\n",
            "\n",
            "    # Set up the thread configuration\n",
            "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
            "\n",
            "    # Compile the research graph\n",
            "    builder = StateGraph(ResearchGraphState)\n",
            "    builder.add_node(\"create_analysts\", create_analysts_bot)\n",
            "    builder.add_node(\"human_feedback\", human_feedback_bot)\n",
            "    \n",
            "    # Use the interview_graph directly, without .compile()\n",
            "    builder.add_node(\"conduct_interview\", interview_graph)\n",
            "    builder.add_node(\"write_report\", write_report_bot)\n",
            "    builder.add_node(\"write_introduction\", write_introduction_bot)\n",
            "    builder.add_node(\"write_conclusion\", write_conclusion_bot)\n",
            "    builder.add_node(\"finalize_report\", finalize_report_bot)\n",
            "\n",
            "    # Logic\n",
            "    builder.add_edge(START, \"create_analysts\")\n",
            "    builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
            "    builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
            "    builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_report\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
            "    builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
            "    builder.add_edge(\"finalize_report\", END)\n",
            "\n",
            "    # Compile the graph\n",
            "    memory2 = MemorySaver()\n",
            "    graph = builder.compile(checkpointer=memory2)\n",
            "    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
            "\n",
            "    # Invoke the graph\n",
            "    try:\n",
            "        result = graph.invoke(initial_state, thread)\n",
            "        final_state = graph.get_state(thread)\n",
            "        report = final_state.values.get('final_report', '')\n",
            "    except Exception as e:\n",
            "        print(f\"Error in graph execution: {e}\")\n",
            "        print(f\"Current state: {graph.get_state(thread)}\")\n",
            "        raise\n",
            "\n",
            "    return report\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    from dataclasses import dataclass\n",
            "    from typing import List, Dict, Any, Optional\n",
            "    from datetime import datetime\n",
            "\n",
            "    @dataclass\n",
            "    class Section:\n",
            "        section_id: int\n",
            "        title: str\n",
            "        content: str\n",
            "        parent_id: Optional[int] = None\n",
            "\n",
            "    @dataclass\n",
            "    class Document:\n",
            "        title: str\n",
            "        context: str\n",
            "\n",
            "    class MockBot:\n",
            "        def __init__(self, title: str, context: str):\n",
            "            self.document = Document(title=title, context=context)\n",
            "            self.sections: List[Section] = []\n",
            "            self.resources: List[Dict] = []\n",
            "            self.next_section_id = 1\n",
            "            self.next_resource_id = 1\n",
            "            print(f\"MockBot initialized with title: {title} and context: {context}\")\n",
            "\n",
            "        def create_and_add_section_then_return_id(self, title: str, content: str, section_id: int = None, parent_id: int = None) -> int:\n",
            "            if section_id is None:\n",
            "                section_id = self.next_section_id\n",
            "                self.next_section_id += 1\n",
            "            \n",
            "            section = Section(section_id=section_id, title=title, content=content, parent_id=parent_id)\n",
            "            self.sections.append(section)\n",
            "            print(f\"Created section {section_id}: {title} (parent: {parent_id})\")\n",
            "            return section_id\n",
            "\n",
            "        def get_all_sections(self) -> List[Section]:\n",
            "            return self.sections\n",
            "\n",
            "        def get_sections(self, ids: List[int]) -> List[Section]:\n",
            "            return [s for s in self.sections if s.section_id in ids]\n",
            "\n",
            "        def edit_section(self, section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool:\n",
            "            for section in self.sections:\n",
            "                if section.section_id == section_id:\n",
            "                    if new_content is not None:\n",
            "                        section.content = new_content\n",
            "                    if new_title is not None:\n",
            "                        section.title = new_title\n",
            "                    if new_parent_id is not None:\n",
            "                        section.parent_id = new_parent_id\n",
            "                    print(f\"Edited section {section_id}\")\n",
            "                    return True\n",
            "            return False\n",
            "\n",
            "        def add_or_update_results_in_resources(self, results: List[Dict], metadatas_to_add: dict = None, store_linked_document_content: bool = False):\n",
            "            for result in results:\n",
            "                resource_id = self.next_resource_id\n",
            "                self.next_resource_id += 1\n",
            "                \n",
            "                resource = {\n",
            "                    'id': resource_id,\n",
            "                    'document': {\n",
            "                        'name': result.get('name', ''),\n",
            "                        'link': result.get('link', ''),\n",
            "                        'content': result.get('content', {})\n",
            "                    },\n",
            "                    'metadatas': metadatas_to_add or {}\n",
            "                }\n",
            "                \n",
            "                self.resources.append(resource)\n",
            "                print(f\"Added resource {resource_id}: {result.get('name', '')}\")\n",
            "            return self\n",
            "\n",
            "        def add_or_update_result_in_resources(self, metadatas: dict, name: str = None, content: dict = None, link: str = None, store_linked_document_content: bool = False):\n",
            "            resource_id = self.next_resource_id\n",
            "            self.next_resource_id += 1\n",
            "            \n",
            "            resource = {\n",
            "                'id': resource_id,\n",
            "                'document': {\n",
            "                    'name': name,\n",
            "                    'link': link,\n",
            "                    'content': content or {}\n",
            "                },\n",
            "                'metadatas': metadatas\n",
            "            }\n",
            "            \n",
            "            self.resources.append(resource)\n",
            "            print(f\"Added single resource {resource_id}: {name}\")\n",
            "            return self\n",
            "\n",
            "        def get_all_resources(self) -> List[Dict[str, Any]]:\n",
            "            return self.resources\n",
            "\n",
            "        def semantic_search_resources(self, query_texts, n_results=10):\n",
            "            print(f\"Mock semantic search for: {query_texts}\")\n",
            "            return []  # Mock empty results\n",
            "\n",
            "        def remove_resource(self, resource_id):\n",
            "            self.resources = [r for r in self.resources if r['id'] != resource_id]\n",
            "            print(f\"Removed resource {resource_id}\")\n",
            "            return self\n",
            "\n",
            "    # Test usage example:\n",
            "    def test_mock_bot():\n",
            "        # Initialize mock bot\n",
            "        mock_bot = MockBot(\n",
            "            title=\"Test Research\",\n",
            "            context=\"Testing the research assistant framework\"\n",
            "        )\n",
            "        \n",
            "        # Test section creation\n",
            "        section_id = mock_bot.create_and_add_section_then_return_id(\n",
            "            title=\"Introduction\",\n",
            "            content=\"This is a test introduction\"\n",
            "        )\n",
            "        \n",
            "        # Test resource addition\n",
            "        mock_bot.add_or_update_results_in_resources([\n",
            "            {\n",
            "                \"name\": \"Test Resource\",\n",
            "                \"link\": \"https://test.com\",\n",
            "                \"content\": {\"description\": \"Test content\"}\n",
            "            }\n",
            "        ], metadatas_to_add={\"source\": \"test\"})\n",
            "        \n",
            "        # Print current state\n",
            "        print(\"\\nCurrent sections:\")\n",
            "        for section in mock_bot.get_all_sections():\n",
            "            print(f\"Section {section.section_id}: {section.title}\")\n",
            "        \n",
            "        print(\"\\nCurrent resources:\")\n",
            "        for resource in mock_bot.get_all_resources():\n",
            "            print(f\"Resource {resource['id']}: {resource['document']['name']}\")\n",
            "\n",
            "        return mock_bot\n",
            "\n",
            "    mock_bot = MockBot(\n",
            "        title=\"Test Research @ Toulon M2 Master\",\n",
            "        context=\"Testing the research assistant framework in Toulon M2 Master\"\n",
            "    )\n",
            "\n",
            "    # Run with explicit error handling\n",
            "    if True: # try:\n",
            "        result = multi_agent_research_generation_persist_each_agent(mock_bot, max_analysts=2)\n",
            "        \n",
            "        print(\"\\nFinal Results:\")\n",
            "        print(\"Sections:\", len(mock_bot.get_all_sections()))\n",
            "        print(\"Resources:\", len(mock_bot.get_all_resources()))\n",
            "        \n",
            "        if result:\n",
            "            print(\"\\nReport preview:\", result[:200] + \"...\" if result else \"No report\")\n",
            "            \n",
            "    # except Exception as e:\n",
            "    #     print(f\"Error running research generation: {e}\")\n",
            "    #     print(\"\\nFinal bot state:\")\n",
            "    #     print(\"Sections:\", mock_bot.get_all_sections())\n",
            "    #     print(\"Resources:\", mock_bot.get_all_resources())\n",
            ">>>\n",
            "2025-01-26 14:26:57 - {\"message\": \"[32m****CodingAgent>code_task_and_run_test calling HumanLLMMonitor****[0m\", \"agent_name\": \"CodingAgent\", \"message_type\": \"HumanLLMMonitor\", \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": true, \"step_id\": 0}\n",
            "****agent : CodingAgent, automation : None****\n",
            "****user_message CodingAgent : TASK DEFINITION: [[[1. **Reasoning**: \n",
            "   - **Step 1**: The existing function `improve_multi_agent_research_generation` is designed to generate a full research report using a multi-agent workflow. However, it lacks a structured approach to writing sections and does not persist each section effectively.\n",
            "   - **Step 2**: The current implementation merges sections except for the introduction and conclusion, which may lead to a lack of clarity and organization in the final report. Improving the section writing process and ensuring proper persistence can enhance the overall quality of the report.\n",
            "   - **Step 3**: The goal is to enhance the function to ensure that each section is written and stored correctly, allowing for better organization and retrieval of information. This will also help in generating a more comprehensive and coherent report.\n",
            "   - **Step 4**: By focusing on improving the writing and persistence of sections, we can challenge the LLM to create a more sophisticated workflow that includes detailed instructions for each step, ensuring that the report is well-structured and informative.\n",
            "\n",
            "2. **Next Best Task**:\n",
            "   - **Function Name**: improve_multi_agent_research_generation\n",
            "   - **Description**: Enhance the existing `improve_multi_agent_research_generation` function to include structured writing of sections, proper persistence of each section, and improved organization of the final report. This will involve creating distinct sections for each part of the research, ensuring that they are stored and retrieved effectively.\n",
            "\n",
            "3. **Performance Acceptance Criteria**:\n",
            "   - The function should generate a report with clearly defined sections (e.g., introduction, methodology, results, discussion, conclusion).\n",
            "   - Each section should be stored in the bot's resources for easy access and modification.\n",
            "   - The final report should be coherent, well-organized, and formatted correctly in Markdown.\n",
            "   - The function should handle errors gracefully and provide feedback if any step fails.\n",
            "\n",
            "4. **Development Plan**:\n",
            "   - **Plan Depth**: 3\n",
            "   - **Steps**:\n",
            "     1. **Section Writing**:\n",
            "        - 1.1. Create a function to write each section of the report.\n",
            "        - 1.2. Ensure that each section is stored in the bot's resources.\n",
            "        - 1.3. Implement a mechanism to retrieve and edit sections as needed.\n",
            "     2. **Report Finalization**:\n",
            "        - 2.1. Create a function to compile all sections into a final report.\n",
            "        - 2.2. Ensure that the introduction and conclusion are written last, summarizing the content of the report.\n",
            "        - 2.3. Format the final report in Markdown.\n",
            "     3. **Error Handling and Feedback**:\n",
            "        - 3.1. Implement error handling for each step of the process.\n",
            "        - 3.2. Provide feedback to the user on the status of the report generation.\n",
            "        - 3.3. Log any issues encountered during the process for future reference.\n",
            "\n",
            "5. **Tests**:\n",
            "```python\n",
            "# document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e usage test:\n",
            "improve_multi_agent_research_generation(bot, max_analysts=3)\n",
            "# document #42252c6c-12f3-4edf-9045-8acd69bc3356 usage test:\n",
            "improve_multi_agent_research_generation(bot, max_analysts=3)\n",
            "```]]]\n",
            "CURRENT STATE OF PROBLEM TO PERFORM/TEST TASK: [[[<<< Document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e properties:\n",
            "> Current table of content:\n",
            "Empty\n",
            "> Current resources: Empty\n",
            ">>>\n",
            "<<< Document #42252c6c-12f3-4edf-9045-8acd69bc3356 properties:\n",
            "> Current table of content:\n",
            "Empty\n",
            "> Current resources: Empty\n",
            ">>>]]]\n",
            "RE-USABLE CODE PRIMITIVES: [[[from IPython.display import Image, display\n",
            "from langgraph.graph import START, END, StateGraph\n",
            "from langgraph.checkpoint.memory import MemorySaver\n",
            "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
            "from pydantic import BaseModel, Field\n",
            "from langgraph.graph import MessagesState\n",
            "import operator\n",
            "from typing import List, Annotated\n",
            "from typing_extensions import TypedDict\n",
            "from langchain_community.document_loaders import WikipediaLoader\n",
            "from langchain_core.messages import get_buffer_string\n",
            "from langgraph.constants import Send\n",
            "\n",
            "from langchain_openai import ChatOpenAI\n",
            "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
            "\n",
            "class Analyst(BaseModel):\n",
            "    affiliation: str = Field(\n",
            "        description=\"Primary affiliation of the analyst.\",\n",
            "    )\n",
            "    name: str = Field(\n",
            "        description=\"Name of the analyst.\"\n",
            "    )\n",
            "    role: str = Field(\n",
            "        description=\"Role of the analyst in the context of the topic.\",\n",
            "    )\n",
            "    description: str = Field(\n",
            "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
            "    )\n",
            "    @property\n",
            "    def persona(self) -> str:\n",
            "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
            "\n",
            "class Perspectives(BaseModel):\n",
            "    analysts: List[Analyst] = Field(\n",
            "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
            "    )\n",
            "\n",
            "class GenerateAnalystsState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "\n",
            "def create_analysts(state: GenerateAnalystsState):\n",
            "    \"\"\" Create analysts \"\"\"\n",
            "    if \"analyst_instructions\" not in state:\n",
            "        state['analyst_instructions'] = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
            "\n",
            "        1. First, review the research topic:\n",
            "        {topic}\n",
            "\n",
            "        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
            "        {human_analyst_feedback}\n",
            "\n",
            "        3. Determine the most interesting themes based upon documents and / or feedback above.\n",
            "\n",
            "        4. Pick the top {max_analysts} themes.\n",
            "\n",
            "        5. Assign one analyst to each theme.\n",
            "\n",
            "        Respond with a JSON object containing a list of analysts, where each analyst has:\n",
            "        - name: string\n",
            "        - role: string\n",
            "        - affiliation: string\n",
            "        - description: string\"\"\"\n",
            "    \n",
            "    analyst_instructions = state[\"analyst_instructions\"]\n",
            "\n",
            "    topic=state['topic']\n",
            "    max_analysts=state['max_analysts']\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', '')\n",
            "\n",
            "    # Enforce structured output\n",
            "    structured_llm = llm.with_structured_output(Perspectives)\n",
            "\n",
            "    # System message\n",
            "    system_message = analyst_instructions.format(topic=topic,\n",
            "                                                            human_analyst_feedback=human_analyst_feedback,\n",
            "                                                            max_analysts=max_analysts)\n",
            "\n",
            "    print(system_message)\n",
            "    # Generate question\n",
            "    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate the set of analysts.\")])\n",
            "    print(f\"Type of analysts: {type(analysts)}\")\n",
            "\n",
            "    # Write the list of analysis to state\n",
            "    return {\"analysts\": analysts.analysts}\n",
            "\n",
            "def create_analysts(state: GenerateAnalystsState):\n",
            "    \"\"\" Create analysts \"\"\"\n",
            "    if \"analyst_instructions\" not in state:\n",
            "        state['analyst_instructions'] = \"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
            "\n",
            "        1. First, review the research topic:\n",
            "        {topic}\n",
            "\n",
            "        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
            "        {human_analyst_feedback}\n",
            "\n",
            "        3. Determine the most interesting themes based upon documents and / or feedback above.\n",
            "\n",
            "        4. Pick the top {max_analysts} themes.\n",
            "\n",
            "        5. Assign one analyst to each theme.\n",
            "\n",
            "        Respond with a JSON object containing a list of analysts, where each analyst has:\n",
            "        - name: string\n",
            "        - role: string\n",
            "        - affiliation: string\n",
            "        - description: string\"\"\"\n",
            "    \n",
            "    analyst_instructions = state[\"analyst_instructions\"]\n",
            "    topic = state['topic']\n",
            "    max_analysts = state['max_analysts']\n",
            "    human_analyst_feedback = state.get('human_analyst_feedback', '')\n",
            "\n",
            "    # Enforce structured output\n",
            "    structured_llm = llm.with_structured_output(Perspectives)\n",
            "\n",
            "    # System message\n",
            "    system_message = analyst_instructions.format(\n",
            "        topic=topic,\n",
            "        human_analyst_feedback=human_analyst_feedback,\n",
            "        max_analysts=max_analysts\n",
            "    )\n",
            "\n",
            "    try:\n",
            "        # Generate analysts\n",
            "        analysts_response = structured_llm.invoke([\n",
            "            SystemMessage(content=system_message),\n",
            "            HumanMessage(content=\"Generate the set of analysts.\")\n",
            "        ])\n",
            "\n",
            "        # Handle different possible return types\n",
            "        if isinstance(analysts_response, Perspectives):\n",
            "            # If it's already a Perspectives object\n",
            "            generated_analysts = analysts_response.analysts\n",
            "        elif isinstance(analysts_response, dict):\n",
            "            # If it's a dict, try to extract analysts\n",
            "            generated_analysts = analysts_response.get('analysts', [])\n",
            "        elif hasattr(analysts_response, 'analysts'):\n",
            "            # If it has an analysts attribute\n",
            "            generated_analysts = analysts_response.analysts\n",
            "        else:\n",
            "            # Fallback to default analysts\n",
            "            generated_analysts = [\n",
            "                Analyst(\n",
            "                    name=f\"Analyst {i+1}\", \n",
            "                    role=f\"Research Specialist {i+1}\", \n",
            "                    affiliation=\"Research Institute\", \n",
            "                    description=f\"Analyzing aspects of {topic}\"\n",
            "                ) for i in range(max_analysts)\n",
            "            ]\n",
            "\n",
            "        # Ensure all are Analyst objects\n",
            "        generated_analysts = [\n",
            "            Analyst(**a.dict() if hasattr(a, 'dict') else a) \n",
            "            for a in generated_analysts\n",
            "        ]\n",
            "\n",
            "        return {\"analysts\": generated_analysts}\n",
            "\n",
            "    except Exception as e:\n",
            "        print(f\"Error generating analysts: {e}\")\n",
            "        # Fallback to default analysts\n",
            "        default_analysts = [\n",
            "            Analyst(\n",
            "                name=f\"Analyst {i+1}\", \n",
            "                role=f\"Research Specialist {i+1}\", \n",
            "                affiliation=\"Research Institute\", \n",
            "                description=f\"Analyzing aspects of {topic}\"\n",
            "            ) for i in range(max_analysts)\n",
            "        ]\n",
            "        return {\"analysts\": default_analysts}\n",
            "\n",
            "def human_feedback(state: GenerateAnalystsState):\n",
            "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
            "    pass\n",
            "\n",
            "def should_continue(state: GenerateAnalystsState):\n",
            "    \"\"\" Return the next node to execute \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', None)\n",
            "    if human_analyst_feedback:\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise end\n",
            "    return END\n",
            "\n",
            "class InterviewState(MessagesState):\n",
            "    max_num_turns: int # Number turns of conversation\n",
            "    context: Annotated[list, operator.add] # Source docs\n",
            "    analyst: Analyst # Analyst asking questions\n",
            "    interview: str # Interview transcript\n",
            "    sections: list # Final key we duplicate in outer state for Send() API\n",
            "\n",
            "class SearchQuery(BaseModel):\n",
            "    search_query: str = Field(None, description=\"Search query for retrieval.\")\n",
            "\n",
            "def generate_question(state: InterviewState):\n",
            "    \"\"\" Node to generate a question \"\"\"\n",
            "\n",
            "    # Check if question_instructions is provided by state\n",
            "    if \"question_instructions\" not in state:\n",
            "        state[\"question_instructions\"] = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
            "\n",
            "        Your goal is boil down to interesting and specific insights related to your topic.\n",
            "\n",
            "        1. Interesting: Insights that people will find surprising or non-obvious.\n",
            "\n",
            "        2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
            "\n",
            "        Here is your topic of focus and set of goals: {goals}\n",
            "\n",
            "        Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
            "\n",
            "        Continue to ask questions to drill down and refine your understanding of the topic.\n",
            "\n",
            "        When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
            "\n",
            "        Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
            "\n",
            "    question_instructions = state[\"question_instructions\"]\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Generate question\n",
            "    system_message = question_instructions.format(goals=analyst.persona)\n",
            "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Write messages to state\n",
            "    return {\"messages\": [question]}\n",
            "\n",
            "def search_web(state: InterviewState):\n",
            "    \"\"\" Retrieve academic papers from OpenAlex \"\"\"\n",
            "    import requests\n",
            "    OPENALEX_API_URL = \"https://api.openalex.org/works\"\n",
            "\n",
            "    # Search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    if \"search_instructions\" not in state:\n",
            "        state[\"search_instructions\"] = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
            "\n",
            "        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
            "\n",
            "        First, analyze the full conversation.\n",
            "\n",
            "        Pay particular attention to the final question posed by the analyst.\n",
            "\n",
            "        Convert this final question into a well-structured web search query\"\"\")\n",
            "    search_instructions = state[\"search_instructions\"]\n",
            "\n",
            "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
            "\n",
            "    # Construct the OpenAlex API query parameters\n",
            "    params = {\n",
            "        \"search\": search_query.search_query,\n",
            "        \"filter\": \"is_paratext:false\",  # Exclude non-research content\n",
            "        \"sort\": \"relevance_score:desc\",\n",
            "        \"per_page\": 5  # Limit to top 5 relevant results\n",
            "    }\n",
            "\n",
            "    # Perform the request to OpenAlex\n",
            "    response = requests.get(OPENALEX_API_URL, params=params)\n",
            "    search_docs = []\n",
            "    \n",
            "    if response.status_code == 200:\n",
            "        data = response.json()\n",
            "        for result in data.get(\"results\", []):\n",
            "            search_docs.append({\n",
            "                \"title\": result.get(\"title\", \"Unknown Title\"),\n",
            "                \"authors\": \", \".join([auth[\"author\"][\"display_name\"] for auth in result.get(\"authorships\", [])]),\n",
            "                \"abstract\": result.get(\"abstract\", \"No abstract available\"),\n",
            "                \"url\": result.get(\"id\", \"Unknown URL\")\n",
            "            })\n",
            "    else:\n",
            "        print(f\"Error retrieving data from OpenAlex: {response.status_code}\")\n",
            "\n",
            "    # Format results\n",
            "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
            "        [\n",
            "            f'<Document title=\"{doc[\"title\"]}\" href=\"{doc[\"url\"]}\">\\nAuthors: {doc[\"authors\"]}\\n\\nAbstract: {doc[\"abstract\"]}\\n</Document>'\n",
            "            for doc in search_docs\n",
            "        ]\n",
            "    )\n",
            "\n",
            "    return {\"context\": [formatted_search_docs]}\n",
            "\n",
            "def search_wikipedia(state: InterviewState):\n",
            "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
            "    # Check if search_instructions is provided by state\n",
            "    if \"search_instructions\" not in state:\n",
            "        state[\"search_instructions\"] = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
            "        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
            "        First, analyze the full conversation.\n",
            "        Pay particular attention to the final question posed by the analyst.\n",
            "        Convert this final question into a well-structured web search query\"\"\")\n",
            "\n",
            "    search_instructions = state[\"search_instructions\"]\n",
            "\n",
            "    # Search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
            "\n",
            "    # Search\n",
            "    search_docs = WikipediaLoader(query=search_query.search_query,\n",
            "                                  load_max_docs=2).load()\n",
            "\n",
            "     # Format\n",
            "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
            "        [\n",
            "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
            "            for doc in search_docs\n",
            "        ]\n",
            "    )\n",
            "\n",
            "    return {\"context\": [formatted_search_docs]}\n",
            "\n",
            "def generate_answer(state: InterviewState):\n",
            "    \"\"\" Node to answer a question \"\"\"\n",
            "    # Check if answer_instructions is provided by state\n",
            "    if \"answer_instructions\" not in state:\n",
            "        state[\"answer_instructions\"] = \"\"\"You are an expert being interviewed by an analyst.\n",
            "\n",
            "        Here is analyst area of focus: {goals}.\n",
            "\n",
            "        You goal is to answer a question posed by the interviewer.\n",
            "\n",
            "        To answer question, use this context:\n",
            "\n",
            "        {context}\n",
            "\n",
            "        When answering questions, follow these guidelines:\n",
            "\n",
            "        1. Use only the information provided in the context.\n",
            "\n",
            "        2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
            "\n",
            "        3. The context contain sources at the topic of each individual document.\n",
            "\n",
            "        4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
            "\n",
            "        5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
            "\n",
            "        6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
            "\n",
            "        [1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "        And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
            "\n",
            "    answer_instructions = state[\"answer_instructions\"]\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "    context = state[\"context\"]\n",
            "\n",
            "    # Answer question\n",
            "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
            "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Name the message as coming from the expert\n",
            "    answer.name = \"expert\"\n",
            "\n",
            "    # Append it to state\n",
            "    return {\"messages\": [answer]}\n",
            "\n",
            "def save_interview(state: InterviewState):\n",
            "\n",
            "    \"\"\" Save interviews \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Convert interview to a string\n",
            "    interview = get_buffer_string(messages)\n",
            "\n",
            "    # Save to interviews key\n",
            "    return {\"interview\": interview}\n",
            "\n",
            "def route_messages(state: InterviewState,\n",
            "                   name: str = \"expert\"):\n",
            "\n",
            "    \"\"\" Route between question and answer \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "    max_num_turns = state.get('max_num_turns',2)\n",
            "\n",
            "    # Check the number of expert answers\n",
            "    num_responses = len(\n",
            "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
            "    )\n",
            "\n",
            "    # End if expert has answered more than the max turns\n",
            "    if num_responses >= max_num_turns:\n",
            "        return 'save_interview'\n",
            "\n",
            "    # This router is run after each question - answer pair\n",
            "    # Get the last question asked to check if it signals the end of discussion\n",
            "    last_question = messages[-2]\n",
            "\n",
            "    if \"Thank you so much for your help\" in last_question.content:\n",
            "        return 'save_interview'\n",
            "    return \"ask_question\"\n",
            "\n",
            "def write_section(state: InterviewState):\n",
            "    \"\"\" Node to answer a question \"\"\"\n",
            "    # Check if section_writer_instructions is provided by state\n",
            "    if \"section_writer_instructions\" not in state:\n",
            "        state[\"section_writer_instructions\"] = \"\"\"You are an expert technical writer.\n",
            "\n",
            "        Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
            "\n",
            "        1. Analyze the content of the source documents:\n",
            "        - The name of each source document is at the start of the document, with the <Document tag.\n",
            "\n",
            "        2. Create a report structure using markdown formatting:\n",
            "        - Use ## for the section title\n",
            "        - Use ### for sub-section headers\n",
            "\n",
            "        3. Write the report following this structure:\n",
            "        a. Title (## header)\n",
            "        b. Summary (### header)\n",
            "        c. Sources (### header)\n",
            "\n",
            "        4. Make your title engaging based upon the focus area of the analyst:\n",
            "        {focus}\n",
            "\n",
            "        5. For the summary section:\n",
            "        - Set up summary with general background / context related to the focus area of the analyst\n",
            "        - Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
            "        - Create a numbered list of source documents, as you use them\n",
            "        - Do not mention the names of interviewers or experts\n",
            "        - Aim for approximately 400 words maximum\n",
            "        - Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
            "\n",
            "        6. In the Sources section:\n",
            "        - Include all sources used in your report\n",
            "        - Provide full links to relevant websites or specific document paths\n",
            "        - Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
            "        - It will look like:\n",
            "\n",
            "        ### Sources\n",
            "        [1] Link or Document name\n",
            "        [2] Link or Document name\n",
            "\n",
            "        7. Be sure to combine sources. For example this is not correct:\n",
            "\n",
            "        [3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "        [4] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "        There should be no redundant sources. It should simply be:\n",
            "\n",
            "        [3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "        8. Final review:\n",
            "        - Ensure the report follows the required structure\n",
            "        - Include no preamble before the title of the report\n",
            "        - Check that all guidelines have been followed\"\"\"\n",
            "\n",
            "    section_writer_instructions = state[\"section_writer_instructions\"]\n",
            "\n",
            "    # Get state\n",
            "    interview = state[\"interview\"]\n",
            "    context = state[\"context\"]\n",
            "    analyst = state[\"analyst\"]\n",
            "\n",
            "    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\n",
            "    system_message = section_writer_instructions.format(focus=analyst.description)\n",
            "    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Use this source to write your section: {context}\")])\n",
            "\n",
            "    # Append it to state\n",
            "    return {\"sections\": [section.content]}\n",
            "\n",
            "class ResearchGraphState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "    sections: Annotated[list, operator.add] # Send() API key\n",
            "    introduction: str # Introduction for the final report\n",
            "    content: str # Content for the final report\n",
            "    conclusion: str # Conclusion for the final report\n",
            "    final_report: str # Final report\n",
            "\n",
            "def initiate_all_interviews(state: ResearchGraphState):\n",
            "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
            "    if human_analyst_feedback:\n",
            "        # Return to create_analysts\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise kick off interviews in parallel via Send() API\n",
            "    else:\n",
            "        topic = state[\"topic\"]\n",
            "        return [Send(\"conduct_interview\", {\"analyst\": analyst,\n",
            "                                           \"messages\": [HumanMessage(\n",
            "                                               content=f\"So you said you were writing an article on {topic}?\"\n",
            "                                           )\n",
            "                                                       ]}) for analyst in state[\"analysts\"]]\n",
            "\n",
            "def write_report(state: ResearchGraphState):\n",
            "    # Check if report_writer_instructions is provided by state\n",
            "    if \"report_writer_instructions\" not in state:\n",
            "        state['report_writer_instructions'] = \"\"\"You are a technical writer creating a report on this overall topic:\n",
            "\n",
            "{topic}\n",
            "\n",
            "You have a team of analysts. Each analyst has done two things:\n",
            "\n",
            "1. They conducted an interview with an expert on a specific sub-topic.\n",
            "2. They write up their finding into a memo.\n",
            "\n",
            "Your task:\n",
            "\n",
            "1. You will be given a collection of memos from your analysts.\n",
            "2. Think carefully about the insights from each memo.\n",
            "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\n",
            "4. Summarize the central points in each memo into a cohesive single narrative.\n",
            "\n",
            "To format your report:\n",
            "\n",
            "1. Use markdown formatting.\n",
            "2. Include no pre-amble for the report.\n",
            "3. Use no sub-heading.\n",
            "4. Start your report with a single title header: ## Insights\n",
            "5. Do not mention any analyst names in your report.\n",
            "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
            "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
            "8. List your sources in order and do not repeat.\n",
            "\n",
            "[1] Source 1\n",
            "[2] Source 2\n",
            "\n",
            "Here are the memos from your analysts to build your report from:\n",
            "\n",
            "{context}\"\"\"\n",
            "\n",
            "    report_writer_instructions = state[\"report_writer_instructions\"]\n",
            "\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\n",
            "    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Write a report based upon these memos.\")])\n",
            "    return {\"content\": report.content}\n",
            "\n",
            "def write_introduction(state: ResearchGraphState):\n",
            "    # Check if intro_conclusion_instructions is provided by state\n",
            "    if \"intro_conclusion_instructions\" not in state:\n",
            "        state['intro_conclusion_instructions'] = \"\"\"You are a technical writer finishing a report on {topic}\n",
            "\n",
            "You will be given all of the sections of the report.\n",
            "\n",
            "You job is to write a crisp and compelling introduction or conclusion section.\n",
            "\n",
            "The user will instruct you whether to write the introduction or conclusion.\n",
            "\n",
            "Include no pre-amble for either section.\n",
            "\n",
            "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
            "\n",
            "Use markdown formatting.\n",
            "\n",
            "For your introduction, create a compelling title and use the # header for the title.\n",
            "\n",
            "For your introduction, use ## Introduction as the section header.\n",
            "\n",
            "For your conclusion, use ## Conclusion as the section header.\n",
            "\n",
            "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
            "\n",
            "    intro_conclusion_instructions = state[\"intro_conclusion_instructions\"]\n",
            "\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    intro = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report introduction\")])\n",
            "    return {\"introduction\": intro.content}\n",
            "\n",
            "def write_conclusion(state: ResearchGraphState):\n",
            "    # Check if intro_conclusion_instructions is provided by state\n",
            "    if \"intro_conclusion_instructions\" not in state:\n",
            "        state['intro_conclusion_instructions'] = \"\"\"You are a technical writer finishing a report on {topic}\n",
            "\n",
            "You will be given all of the sections of the report.\n",
            "\n",
            "You job is to write a crisp and compelling introduction or conclusion section.\n",
            "\n",
            "The user will instruct you whether to write the introduction or conclusion.\n",
            "\n",
            "Include no pre-amble for either section.\n",
            "\n",
            "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
            "\n",
            "Use markdown formatting.\n",
            "\n",
            "For your introduction, create a compelling title and use the # header for the title.\n",
            "\n",
            "For your introduction, use ## Introduction as the section header.\n",
            "\n",
            "For your conclusion, use ## Conclusion as the section header.\n",
            "\n",
            "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
            "\n",
            "    intro_conclusion_instructions = state[\"intro_conclusion_instructions\"]        \n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report conclusion\")])\n",
            "    return {\"conclusion\": conclusion.content}\n",
            "\n",
            "def finalize_report(state: ResearchGraphState):\n",
            "    \"\"\" This is the \"reduce\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion \"\"\"\n",
            "    if not state:\n",
            "        return {\"final_report\": \"\"}\n",
            "        \n",
            "    # Save full final report\n",
            "    content = state.get(\"content\", \"\")\n",
            "    introduction = state.get(\"introduction\", \"\")\n",
            "    conclusion = state.get(\"conclusion\", \"\")\n",
            "    \n",
            "    if content.startswith(\"## Insights\"):\n",
            "        content = content.strip(\"## Insights\")\n",
            "    \n",
            "    sources = None\n",
            "    if \"## Sources\" in content:\n",
            "        try:\n",
            "            content, sources = content.split(\"\\n## Sources\\n\")\n",
            "        except:\n",
            "            sources = None\n",
            "\n",
            "    final_report = \"\"\n",
            "    if introduction:\n",
            "        final_report += introduction + \"\\n\\n---\\n\\n\"\n",
            "    if content:\n",
            "        final_report += content\n",
            "    if conclusion:\n",
            "        final_report += \"\\n\\n---\\n\\n\" + conclusion\n",
            "    if sources:\n",
            "        final_report += \"\\n\\n## Sources\\n\" + sources\n",
            "\n",
            "    return {\"final_report\": final_report}\n",
            "\n",
            "def persist_final_report_in_bot(bot, final_report):\n",
            "    \"\"\"\n",
            "    Converts the final Markdown report into document sections,\n",
            "    and extracts sources to store in bot.add_or_update_results_in_resources.\n",
            "    \"\"\"\n",
            "    # Handle None or empty input\n",
            "    if final_report is None:\n",
            "        final_report = {\"final_report\": \"\"}  # Create empty report instead of raising error\n",
            "        \n",
            "    # Handle dictionary input\n",
            "    if isinstance(final_report, dict):\n",
            "        final_report = final_report.get(\"final_report\", \"\")\n",
            "    \n",
            "    # Ensure we have a string\n",
            "    final_report = str(final_report)\n",
            "    \n",
            "    # If empty report, create minimal section\n",
            "    if not final_report.strip():\n",
            "        bot.create_and_add_section_then_return_id(\n",
            "            title=\"Empty Report\",\n",
            "            content=\"No content was generated.\"\n",
            "        )\n",
            "        return\n",
            "\n",
            "    import re\n",
            "    \n",
            "    # The rest of the function remains the same...\n",
            "    section_pattern = re.compile(r\"(##\\s+.+?)(?=##\\s|$)\", re.DOTALL)\n",
            "    \n",
            "    grand_titre_match = re.search(r\"^#\\s+(.*)\", final_report)\n",
            "    if grand_titre_match:\n",
            "        grand_titre = grand_titre_match.group(1).strip()\n",
            "        bot.create_and_add_section_then_return_id(\n",
            "            title=grand_titre,\n",
            "            content=f\"(Main Title)\\n\\n{grand_titre}\"\n",
            "        )\n",
            "    \n",
            "    sections = section_pattern.findall(final_report)\n",
            "\n",
            "    for section_md in sections:\n",
            "        lines = section_md.split('\\n', 1)\n",
            "        if len(lines) == 2:\n",
            "            section_title_line, section_body = lines\n",
            "        else:\n",
            "            section_title_line = lines[0]\n",
            "            section_body = \"\"\n",
            "\n",
            "        section_title = section_title_line.replace(\"##\", \"\").strip()\n",
            "        bot.create_and_add_section_then_return_id(title=section_title, content=section_body)\n",
            "\n",
            "    sources_block_match = re.search(r\"(##\\s+Sources.*)\", final_report, re.IGNORECASE | re.DOTALL)\n",
            "    if sources_block_match:\n",
            "        sources_block = sources_block_match.group(1)\n",
            "        \n",
            "        lines = sources_block.split('\\n')\n",
            "        resources_to_add = []\n",
            "        for line in lines:\n",
            "            m = re.match(r\"\\[(\\d+)\\]\\s+(.*)\", line.strip())\n",
            "            if m:\n",
            "                index = m.group(1)\n",
            "                url_or_name = m.group(2)\n",
            "                resource_item = {\n",
            "                    \"name\": f\"Source_{index}\",\n",
            "                    \"content\": {\"url\": url_or_name},\n",
            "                    \"metadatas\": {\"index\": index}\n",
            "                }\n",
            "                resources_to_add.append(resource_item)\n",
            "        \n",
            "        if resources_to_add:\n",
            "            bot.add_or_update_results_in_resources(\n",
            "                results=resources_to_add, \n",
            "                metadatas_to_add={\"type\": \"reference\"},\n",
            "                store_linked_document_content=False\n",
            "            )\n",
            "\n",
            "def improve_multi_agent_research_generation(bot, max_analysts: int = 3):\n",
            "    \"\"\"\n",
            "    Generate a full research report using a multi-agent LangGraph workflow:  \n",
            "    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \n",
            "    Write report, Write introduction, Write conclusion, Finalize report.\n",
            "    Persist the document in the bot object through agent action.\n",
            "    \n",
            "    Args:\n",
            "        bot: The bot object with the necessary methods.\n",
            "        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\n",
            "    Returns:\n",
            "        str: The final markdown research report.\n",
            "    \"\"\"\n",
            "    title, topic = bot.document.title, bot.document.context\n",
            "    # Create initial state with topic and max_analysts\n",
            "    initial_state: GenerateAnalystsState = { \"topic\": topic, \"max_analysts\": max_analysts, \"human_analyst_feedback\": None, \"analysts\": []}\n",
            "\n",
            "    # Recreate the interview graph within the function\n",
            "    interview_builder = StateGraph(InterviewState)\n",
            "    interview_builder.add_node(\"ask_question\", generate_question)\n",
            "    interview_builder.add_node(\"search_web\", search_web)\n",
            "    interview_builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
            "    interview_builder.add_node(\"answer_question\", generate_answer)\n",
            "    interview_builder.add_node(\"save_interview\", save_interview)\n",
            "    interview_builder.add_node(\"write_section\", write_section)\n",
            "\n",
            "    # Flow\n",
            "    interview_builder.add_edge(START, \"ask_question\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
            "    interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
            "    interview_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
            "    interview_builder.add_conditional_edges(\"answer_question\", route_messages,['ask_question','save_interview'])\n",
            "    interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
            "    interview_builder.add_edge(\"write_section\", END)\n",
            "\n",
            "    # Compile interview graph\n",
            "    memory = MemorySaver()\n",
            "    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")\n",
            "\n",
            "    # Set up the thread configuration\n",
            "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
            "\n",
            "    # Compile the research graph\n",
            "    builder = StateGraph(ResearchGraphState)\n",
            "    builder.add_node(\"create_analysts\", create_analysts)\n",
            "    builder.add_node(\"human_feedback\", human_feedback)\n",
            "    \n",
            "    # Use the interview_graph directly, without .compile()\n",
            "    builder.add_node(\"conduct_interview\", interview_graph)\n",
            "    builder.add_node(\"write_report\", write_report)\n",
            "    builder.add_node(\"write_introduction\", write_introduction)\n",
            "    builder.add_node(\"write_conclusion\", write_conclusion)\n",
            "    builder.add_node(\"finalize_report\", finalize_report)\n",
            "\n",
            "    # Logic\n",
            "    builder.add_edge(START, \"create_analysts\")\n",
            "    builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
            "    builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
            "    builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_report\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
            "    builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
            "    builder.add_edge(\"finalize_report\", END)\n",
            "\n",
            "    # Compile the graph\n",
            "    memory2 = MemorySaver()\n",
            "    graph = builder.compile(checkpointer=memory2)\n",
            "    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
            "\n",
            "    # Invoke the graph\n",
            "    graph.invoke(initial_state, thread)\n",
            "\n",
            "    # Retrieve the final report\n",
            "    final_state = graph.get_state(thread)\n",
            "    report = final_state.values.get('final_report')\n",
            "\n",
            "    persist_final_report_in_bot(bot, report)\n",
            "    return report\n",
            "\n",
            "from IPython.display import Image, display\n",
            "from langgraph.graph import START, END, StateGraph\n",
            "from langgraph.checkpoint.memory import MemorySaver\n",
            "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
            "from pydantic import BaseModel, Field\n",
            "from langgraph.graph import MessagesState\n",
            "import operator\n",
            "from typing import List, Annotated\n",
            "from typing_extensions import TypedDict\n",
            "from langchain_community.document_loaders import WikipediaLoader\n",
            "from langchain_core.messages import get_buffer_string\n",
            "from langgraph.constants import Send\n",
            "from typing import List\n",
            "from typing_extensions import TypedDict\n",
            "from pydantic import BaseModel, Field\n",
            "from IPython.display import Image, display\n",
            "from langgraph.graph import START, END, StateGraph\n",
            "from langgraph.checkpoint.memory import MemorySaver\n",
            "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
            "import operator\n",
            "from typing import  Annotated\n",
            "from langgraph.graph import MessagesState\n",
            "import datetime\n",
            "import os\n",
            "from langchain_openai import ChatOpenAI\n",
            "# Wikipedia search tool\n",
            "from langchain_community.document_loaders import WikipediaLoader\n",
            "from langchain_core.messages import get_buffer_string\n",
            "\n",
            "# os.environ['OPENAI_BASE_URL'] = 'https://api.openai.com/v1'\n",
            "# os.environ['OPENROUTER_API_KEY'] = '\n",
            "# os.environ['OPENAI_API_KEY'] = os.environ['OPENROUTER_API_KEY']\n",
            "\n",
            "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
            "\n",
            "class Analyst(BaseModel):\n",
            "    affiliation: str = Field(\n",
            "        description=\"Primary affiliation of the analyst.\",\n",
            "    )\n",
            "    name: str = Field(\n",
            "        description=\"Name of the analyst.\"\n",
            "    )\n",
            "    role: str = Field(\n",
            "        description=\"Role of the analyst in the context of the topic.\",\n",
            "    )\n",
            "    description: str = Field(\n",
            "        description=\"Description of the analyst focus, concerns, and motives.\",\n",
            "    )\n",
            "    @property\n",
            "    def persona(self) -> str:\n",
            "        return f\"Name: {self.name}\\nRole: {self.role}\\nAffiliation: {self.affiliation}\\nDescription: {self.description}\\n\"\n",
            "\n",
            "class Perspectives(BaseModel):\n",
            "    analysts: List[Analyst] = Field(\n",
            "        description=\"Comprehensive list of analysts with their roles and affiliations.\",\n",
            "    )\n",
            "\n",
            "class GenerateAnalystsState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "\n",
            "analyst_instructions=\"\"\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\n",
            "\n",
            "1. First, review the research topic:\n",
            "{topic}\n",
            "\n",
            "2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\n",
            "\n",
            "{human_analyst_feedback}\n",
            "\n",
            "3. Determine the most interesting themes based upon documents and / or feedback above.\n",
            "\n",
            "4. Pick the top {max_analysts} themes.\n",
            "\n",
            "5. Assign one analyst to each theme.\"\"\"\n",
            "\n",
            "def create_analysts_bot(state: GenerateAnalystsState):\n",
            "\n",
            "    \"\"\" Create analysts \"\"\"\n",
            "\n",
            "    topic=state['topic']\n",
            "    max_analysts=state['max_analysts']\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', '')\n",
            "    print(f\"Topic: {topic}\")\n",
            "    print(f\"Max analysts: {max_analysts}\")\n",
            "    print(f\"Human analyst feedback: {human_analyst_feedback}\")\n",
            "\n",
            "    # Enforce structured output\n",
            "    structured_llm = llm.with_structured_output(Perspectives)\n",
            "\n",
            "    # System message\n",
            "    system_message = analyst_instructions.format(topic=topic,\n",
            "                                                            human_analyst_feedback=human_analyst_feedback,\n",
            "                                                            max_analysts=max_analysts)\n",
            "\n",
            "    # Generate question\n",
            "    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\"Generate the set of analysts.\")])\n",
            "    print(f\"Generated analysts: {analysts}\")\n",
            "    # print type of analysts\n",
            "    print(f\"Type of analysts: {type(analysts)}\")\n",
            "    # Write the list of analysis to state\n",
            "    #return { \"analysts\": analysts.analysts, \"sections\": state.get(\"sections\", []), \"context\": state.get(\"context\", []) }\n",
            "    #return {\"analysts\": analysts.analysts, \"sections\": state.get(\"sections\", []), \"messages\": state.get(\"messages\", []), \"context\": state.get(\"context\", []), \"human_analyst_feedback\": state.get(\"human_analyst_feedback\", None)}\n",
            "    return {\"analysts\": analysts.analysts}\n",
            "\n",
            "def human_feedback_bot(state: GenerateAnalystsState):\n",
            "    \"\"\" No-op node that should be interrupted on \"\"\"\n",
            "    pass\n",
            "\n",
            "def should_continue(state: GenerateAnalystsState):\n",
            "    \"\"\" Return the next node to execute \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback', None)\n",
            "    if human_analyst_feedback:\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise end\n",
            "    return END\n",
            "\n",
            "#further_feedack = None\n",
            "#graph.update_state(thread, {\"human_analyst_feedback\":further_feedack}, as_node=\"human_feedback\")\n",
            "class InterviewState(MessagesState):\n",
            "    max_num_turns: int = 2  # Add default value\n",
            "    context: Annotated[list, operator.add] = []  # Add default value\n",
            "    analyst: Analyst\n",
            "    interview: str = \"\"  # Add default value\n",
            "    sections: Annotated[list, operator.add] = []  # Add default value\n",
            "    messages: list = []  # Add default value\n",
            "\n",
            "class SearchQuery(BaseModel):\n",
            "    search_query: str = Field(None, description=\"Search query for retrieval.\")\n",
            "\n",
            "question_instructions = \"\"\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\n",
            "\n",
            "Your goal is boil down to interesting and specific insights related to your topic.\n",
            "\n",
            "1. Interesting: Insights that people will find surprising or non-obvious.\n",
            "\n",
            "2. Specific: Insights that avoid generalities and include specific examples from the expert.\n",
            "\n",
            "Here is your topic of focus and set of goals: {goals}\n",
            "\n",
            "Begin by introducing yourself using a name that fits your persona, and then ask your question.\n",
            "\n",
            "Continue to ask questions to drill down and refine your understanding of the topic.\n",
            "\n",
            "When you are satisfied with your understanding, complete the interview with: \"Thank you so much for your help!\"\n",
            "\n",
            "Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\"\"\"\n",
            "\n",
            "def generate_question_bot(state: InterviewState):\n",
            "    \"\"\" Node to generate a question \"\"\"\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Generate question\n",
            "    system_message = question_instructions.format(goals=analyst.persona)\n",
            "    question = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Write messages to state\n",
            "    #return { \"messages\": [question], \"context\": state.get(\"context\", []), \"sections\": state.get(\"sections\", [])}\n",
            "    return {\"messages\": [question]}\n",
            "\n",
            "# Search query writing\n",
            "search_instructions = SystemMessage(content=f\"\"\"You will be given a conversation between an analyst and an expert.\n",
            "\n",
            "Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\n",
            "\n",
            "First, analyze the full conversation.\n",
            "\n",
            "Pay particular attention to the final question posed by the analyst.\n",
            "\n",
            "Convert this final question into a well-structured web search query\"\"\")\n",
            "\n",
            "def search_web_bot(state: InterviewState):\n",
            "    \"\"\"Enhanced web search with proper resource persistence\"\"\"\n",
            "    import requests\n",
            "    OPENALEX_API_URL = \"https://api.openalex.org/works\"\n",
            "    \n",
            "    # Get search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    search_query = structured_llm.invoke([search_instructions] + state['messages'])\n",
            "    \n",
            "    # Search OpenAlex\n",
            "    params = {\n",
            "        \"search\": search_query.search_query,\n",
            "        \"filter\": \"is_paratext:false\",\n",
            "        \"sort\": \"relevance_score:desc\",\n",
            "        \"per_page\": 5\n",
            "    }\n",
            "    \n",
            "    response = requests.get(OPENALEX_API_URL, params=params)\n",
            "    search_docs = []\n",
            "    \n",
            "    if response.status_code == 200:\n",
            "        data = response.json()\n",
            "        \n",
            "        # Prepare resources for bot persistence\n",
            "        resources_to_add = []\n",
            "        for result in data.get(\"results\", []):\n",
            "            doc_info = {\n",
            "                \"title\": result.get(\"title\", \"Unknown Title\"),\n",
            "                \"link\": result.get(\"id\", \"Unknown URL\"),\n",
            "                \"description\": {\n",
            "                    \"abstract\": result.get(\"abstract\", \"No abstract available\"),\n",
            "                    \"authors\": \", \".join([auth[\"author\"][\"display_name\"] for auth in result.get(\"authorships\", [])])\n",
            "                }\n",
            "            }\n",
            "            search_docs.append(doc_info)\n",
            "            resources_to_add.append({\n",
            "                \"name\": doc_info[\"title\"],\n",
            "                \"link\": doc_info[\"link\"],\n",
            "                \"content\": doc_info[\"description\"]\n",
            "            })\n",
            "\n",
            "        # Persist to bot resources with metadata\n",
            "        bot = get_bot()\n",
            "        if bot:\n",
            "            bot.add_or_update_results_in_resources(\n",
            "                results=resources_to_add,\n",
            "                metadatas_to_add={\n",
            "                    \"source\": \"OpenAlex\",\n",
            "                    \"query\": search_query.search_query,\n",
            "                    \"search_timestamp\": str(datetime.now())\n",
            "                }\n",
            "            )\n",
            "\n",
            "    # Format for LLM consumption\n",
            "    formatted_docs = \"\\n\\n---\\n\\n\".join([\n",
            "        f'<Document title=\"{doc[\"title\"]}\" href=\"{doc[\"link\"]}\">\\nAuthors: {doc[\"description\"][\"authors\"]}\\nAbstract: {doc[\"description\"][\"abstract\"]}\\n</Document>'\n",
            "        for doc in search_docs\n",
            "    ])\n",
            "    \n",
            "    return {\"context\": [formatted_docs]}\n",
            "\n",
            "\n",
            "def search_wikipedia_bot(state: InterviewState):\n",
            "\n",
            "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
            "\n",
            "    # Search query\n",
            "    structured_llm = llm.with_structured_output(SearchQuery)\n",
            "    search_query = structured_llm.invoke([search_instructions]+state['messages'])\n",
            "\n",
            "    # Search\n",
            "    search_docs = WikipediaLoader(query=search_query.search_query,\n",
            "                                  load_max_docs=2).load()\n",
            "\n",
            "     # Format\n",
            "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
            "        [\n",
            "            f'<Document source=\"{doc.metadata[\"source\"]}\" page=\"{doc.metadata.get(\"page\", \"\")}\"/>\\n{doc.page_content}\\n</Document>'\n",
            "            for doc in search_docs\n",
            "        ]\n",
            "    )\n",
            "\n",
            "    return {\"context\": [formatted_search_docs]}\n",
            "\n",
            "answer_instructions = \"\"\"You are an expert being interviewed by an analyst.\n",
            "\n",
            "Here is analyst area of focus: {goals}.\n",
            "\n",
            "You goal is to answer a question posed by the interviewer.\n",
            "\n",
            "To answer question, use this context:\n",
            "\n",
            "{context}\n",
            "\n",
            "When answering questions, follow these guidelines:\n",
            "\n",
            "1. Use only the information provided in the context.\n",
            "\n",
            "2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\n",
            "\n",
            "3. The context contain sources at the topic of each individual document.\n",
            "\n",
            "4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\n",
            "\n",
            "5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\n",
            "\n",
            "6. If the source is: <Document source=\"assistant/docs/llama3_1.pdf\" page=\"7\"/>' then just list:\n",
            "\n",
            "[1] assistant/docs/llama3_1.pdf, page 7\n",
            "\n",
            "And skip the addition of the brackets as well as the Document source preamble in your citation.\"\"\"\n",
            "\n",
            "def generate_answer_bot(state: InterviewState):\n",
            "\n",
            "    \"\"\" Node to answer a question \"\"\"\n",
            "\n",
            "    # Get state\n",
            "    analyst = state[\"analyst\"]\n",
            "    messages = state[\"messages\"]\n",
            "    context = state[\"context\"]\n",
            "\n",
            "    # Answer question\n",
            "    system_message = answer_instructions.format(goals=analyst.persona, context=context)\n",
            "    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\n",
            "\n",
            "    # Name the message as coming from the expert\n",
            "    answer.name = \"expert\"\n",
            "\n",
            "    # Append it to state\n",
            "    return {\"messages\": [answer]}\n",
            "\n",
            "def save_interview_bot(state: InterviewState):\n",
            "\n",
            "    \"\"\" Save interviews \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "\n",
            "    # Convert interview to a string\n",
            "    interview = get_buffer_string(messages)\n",
            "\n",
            "    # Save to interviews key\n",
            "    return {\"interview\": interview}\n",
            "\n",
            "def route_messages(state: InterviewState,\n",
            "                   name: str = \"expert\"):\n",
            "\n",
            "    \"\"\" Route between question and answer \"\"\"\n",
            "\n",
            "    # Get messages\n",
            "    messages = state[\"messages\"]\n",
            "    max_num_turns = state.get('max_num_turns',2)\n",
            "\n",
            "    # Check the number of expert answers\n",
            "    num_responses = len(\n",
            "        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\n",
            "    )\n",
            "\n",
            "    # End if expert has answered more than the max turns\n",
            "    if num_responses >= max_num_turns:\n",
            "        return 'save_interview'\n",
            "\n",
            "    # This router is run after each question - answer pair\n",
            "    # Get the last question asked to check if it signals the end of discussion\n",
            "    last_question = messages[-2]\n",
            "\n",
            "    if \"Thank you so much for your help\" in last_question.content:\n",
            "        return 'save_interview'\n",
            "    return \"ask_question\"\n",
            "\n",
            "section_writer_instructions = \"\"\"You are an expert technical writer.\n",
            "\n",
            "Your task is to create a short, easily digestible section of a report based on a set of source documents.\n",
            "\n",
            "1. Analyze the content of the source documents:\n",
            "- The name of each source document is at the start of the document, with the <Document tag.\n",
            "\n",
            "2. Create a report structure using markdown formatting:\n",
            "- Use ## for the section title\n",
            "- Use ### for sub-section headers\n",
            "\n",
            "3. Write the report following this structure:\n",
            "a. Title (## header)\n",
            "b. Summary (### header)\n",
            "c. Sources (### header)\n",
            "\n",
            "4. Make your title engaging based upon the focus area of the analyst:\n",
            "{focus}\n",
            "\n",
            "5. For the summary section:\n",
            "- Set up summary with general background / context related to the focus area of the analyst\n",
            "- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\n",
            "- Create a numbered list of source documents, as you use them\n",
            "- Do not mention the names of interviewers or experts\n",
            "- Aim for approximately 400 words maximum\n",
            "- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\n",
            "\n",
            "6. In the Sources section:\n",
            "- Include all sources used in your report\n",
            "- Provide full links to relevant websites or specific document paths\n",
            "- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\n",
            "- It will look like:\n",
            "\n",
            "### Sources\n",
            "[1] Link or Document name\n",
            "[2] Link or Document name\n",
            "\n",
            "7. Be sure to combine sources. For example this is not correct:\n",
            "\n",
            "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "[4] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "There should be no redundant sources. It should simply be:\n",
            "\n",
            "[3] https://ai.meta.com/blog/meta-llama-3-1/\n",
            "\n",
            "8. Final review:\n",
            "- Ensure the report follows the required structure\n",
            "- Include no preamble before the title of the report\n",
            "- Check that all guidelines have been followed\"\"\"\n",
            "\n",
            "def write_section_bot(state: InterviewState):\n",
            "    \"\"\"Enhanced section writing with proper structure persistence\"\"\"\n",
            "    interview = state[\"interview\"]\n",
            "    context = state[\"context\"]\n",
            "    analyst = state[\"analyst\"]\n",
            "    \n",
            "    section = llm.invoke([\n",
            "        SystemMessage(content=section_writer_instructions),\n",
            "        HumanMessage(content=f\"Write a section based on: {context}\")\n",
            "    ])\n",
            "    \n",
            "    bot = get_bot()\n",
            "    if bot:\n",
            "        try:\n",
            "            # Create main content section if doesn't exist\n",
            "            main_sections = bot.get_all_sections()\n",
            "            main_content_id = next(\n",
            "                (s.section_id for s in main_sections if s.title == \"Main Content\"), \n",
            "                None\n",
            "            )\n",
            "            \n",
            "            if not main_content_id:\n",
            "                main_content_id = bot.create_and_add_section_then_return_id(\n",
            "                    title=\"Main Content\",\n",
            "                    content=\"\",\n",
            "                    section_id=1  # Ensure it's first\n",
            "                )\n",
            "\n",
            "            # Add analyst's section as child\n",
            "            section_id = bot.create_and_add_section_then_return_id(\n",
            "                title=f\"Analysis by {analyst.name}\",\n",
            "                content=section.content,\n",
            "                parent_id=main_content_id\n",
            "            )\n",
            "            \n",
            "            # Store metadata about the section\n",
            "            bot.add_or_update_result_in_resources(\n",
            "                metadatas={\n",
            "                    \"section_id\": section_id,\n",
            "                    \"analyst\": analyst.name,\n",
            "                    \"analyst_role\": analyst.role,\n",
            "                    \"timestamp\": str(datetime.now())\n",
            "                },\n",
            "                name=f\"Section_{section_id}_Metadata\",\n",
            "                content={\"section_type\": \"analysis\", \"parent_section\": main_content_id}\n",
            "            )\n",
            "            \n",
            "        except Exception as e:\n",
            "            print(f\"Error persisting section: {e}\")\n",
            "            \n",
            "    return {\"sections\": [section.content]}\n",
            "\n",
            "\n",
            "class ResearchGraphState(TypedDict):\n",
            "    topic: str # Research topic\n",
            "    max_analysts: int # Number of analysts\n",
            "    human_analyst_feedback: str # Human feedback\n",
            "    analysts: List[Analyst] # Analyst asking questions\n",
            "    sections: Annotated[list, operator.add] # Send() API key\n",
            "    introduction: str # Introduction for the final report\n",
            "    content: str # Content for the final report\n",
            "    conclusion: str # Conclusion for the final report\n",
            "    final_report: str # Final report\n",
            "\n",
            "def initiate_all_interviews(state: ResearchGraphState):\n",
            "    \"\"\" This is the \"map\" step where we run each interview sub-graph using Send API \"\"\"\n",
            "\n",
            "    # Check if human feedback\n",
            "    human_analyst_feedback=state.get('human_analyst_feedback')\n",
            "    if human_analyst_feedback:\n",
            "        # Return to create_analysts\n",
            "        return \"create_analysts\"\n",
            "\n",
            "    # Otherwise kick off interviews in parallel via Send() API\n",
            "    else:\n",
            "        topic = state[\"topic\"]\n",
            "        # return [Send(\"conduct_interview\", {\"analyst\": analyst,\n",
            "        #                                    \"messages\": [HumanMessage(\n",
            "        #                                        content=f\"So you said you were writing an article on {topic}?\"\n",
            "        #                                    )\n",
            "        #                                                ]}) for analyst in state[\"analysts\"]]\n",
            "        return [Send(\"conduct_interview\", {\n",
            "                    \"analyst\": analyst, \"messages\": [ HumanMessage( content=f\"So you said you were writing an article on {topic}?\")],\n",
            "                    \"max_num_turns\": 2,  # Add explicit max_num_turns\n",
            "                    \"context\": [],  # Add empty context\n",
            "                    \"sections\": [],  # Add empty sections\n",
            "                    \"interview\": \"\"  # Add empty interview\n",
            "                }\n",
            "            ) for analyst in state[\"analysts\"]\n",
            "        ]\n",
            "report_writer_instructions = \"\"\"You are a technical writer creating a report on this overall topic:\n",
            "\n",
            "{topic}\n",
            "\n",
            "You have a team of analysts. Each analyst has done two things:\n",
            "\n",
            "1. They conducted an interview with an expert on a specific sub-topic.\n",
            "2. They write up their finding into a memo.\n",
            "\n",
            "Your task:\n",
            "\n",
            "1. You will be given a collection of memos from your analysts.\n",
            "2. Think carefully about the insights from each memo.\n",
            "3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\n",
            "4. Summarize the central points in each memo into a cohesive single narrative.\n",
            "\n",
            "To format your report:\n",
            "\n",
            "1. Use markdown formatting.\n",
            "2. Include no pre-amble for the report.\n",
            "3. Use no sub-heading.\n",
            "4. Start your report with a single title header: ## Insights\n",
            "5. Do not mention any analyst names in your report.\n",
            "6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\n",
            "7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\n",
            "8. List your sources in order and do not repeat.\n",
            "\n",
            "[1] Source 1\n",
            "[2] Source 2\n",
            "\n",
            "Here are the memos from your analysts to build your report from:\n",
            "\n",
            "{context}\"\"\"\n",
            "\n",
            "def write_report_bot(state: ResearchGraphState):\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\n",
            "    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\"Write a report based upon these memos.\")])\n",
            "    return {\"content\": report.content}\n",
            "\n",
            "intro_conclusion_instructions = \"\"\"You are a technical writer finishing a report on {topic}\n",
            "\n",
            "You will be given all of the sections of the report.\n",
            "\n",
            "You job is to write a crisp and compelling introduction or conclusion section.\n",
            "\n",
            "The user will instruct you whether to write the introduction or conclusion.\n",
            "\n",
            "Include no pre-amble for either section.\n",
            "\n",
            "Target around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\n",
            "\n",
            "Use markdown formatting.\n",
            "\n",
            "For your introduction, create a compelling title and use the # header for the title.\n",
            "\n",
            "For your introduction, use ## Introduction as the section header.\n",
            "\n",
            "For your conclusion, use ## Conclusion as the section header.\n",
            "\n",
            "Here are the sections to reflect on for writing: {formatted_str_sections}\"\"\"\n",
            "\n",
            "def write_introduction_bot(state: ResearchGraphState):\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    intro = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report introduction\")])\n",
            "    return {\"introduction\": intro.content}\n",
            "\n",
            "def write_conclusion_bot(state: ResearchGraphState):\n",
            "    # Full set of sections\n",
            "    sections = state[\"sections\"]\n",
            "    topic = state[\"topic\"]\n",
            "\n",
            "    # Concat all sections together\n",
            "    formatted_str_sections = \"\\n\\n\".join([f\"{section}\" for section in sections])\n",
            "\n",
            "    # Summarize the sections into a final report\n",
            "\n",
            "    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\n",
            "    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\"Write the report conclusion\")])\n",
            "    return {\"conclusion\": conclusion.content}\n",
            "\n",
            "def finalize_report_bot(state: ResearchGraphState):\n",
            "    \"\"\"Enhanced report finalization with proper structure\"\"\"\n",
            "    content = state[\"content\"]\n",
            "    introduction = state[\"introduction\"]\n",
            "    conclusion = state[\"conclusion\"]\n",
            "    \n",
            "    bot = get_bot()\n",
            "    if bot:\n",
            "        try:\n",
            "            # Organize sections in proper order\n",
            "            intro_id = bot.create_and_add_section_then_return_id(\n",
            "                title=\"Introduction\",\n",
            "                content=introduction,\n",
            "                section_id=1\n",
            "            )\n",
            "            \n",
            "            content_id = bot.create_and_add_section_then_return_id(\n",
            "                title=\"Main Findings\",\n",
            "                content=content,\n",
            "                section_id=2\n",
            "            )\n",
            "            \n",
            "            conclusion_id = bot.create_and_add_section_then_return_id(\n",
            "                title=\"Conclusion\",\n",
            "                content=conclusion,\n",
            "                section_id=3\n",
            "            )\n",
            "            \n",
            "            # Add metadata about report structure\n",
            "            bot.add_or_update_result_in_resources(\n",
            "                metadatas={\n",
            "                    \"report_structure\": {\n",
            "                        \"introduction_id\": intro_id,\n",
            "                        \"content_id\": content_id,\n",
            "                        \"conclusion_id\": conclusion_id\n",
            "                    },\n",
            "                    \"generation_timestamp\": str(datetime.now())\n",
            "                },\n",
            "                name=\"Final_Report_Structure\"\n",
            "            )\n",
            "            \n",
            "            # Combine for final report\n",
            "            final_report = f\"{introduction}\\n\\n---\\n\\n{content}\\n\\n---\\n\\n{conclusion}\"\n",
            "            \n",
            "            # Store final assembled version\n",
            "            bot.create_and_add_section_then_return_id(\n",
            "                title=\"Complete Report\",\n",
            "                content=final_report,\n",
            "                section_id=4\n",
            "            )\n",
            "            \n",
            "        except Exception as e:\n",
            "            print(f\"Error finalizing report: {e}\")\n",
            "            final_report = f\"{introduction}\\n\\n---\\n\\n{content}\\n\\n---\\n\\n{conclusion}\"\n",
            "            \n",
            "    return {\"final_report\": final_report}\n",
            "\n",
            "def multi_agent_research_generation_persist_each_agent(bot, max_analysts: int = 3):\n",
            "    \"\"\"\n",
            "    Generate a full research report using a multi-agent LangGraph workflow:  \n",
            "    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \n",
            "    Write report, Write introduction, Write conclusion, Finalize report.\n",
            "    Persist the document in the bot object through agent action.\n",
            "    \n",
            "    Args:\n",
            "        bot: The bot object with the necessary methods.\n",
            "        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\n",
            "    Returns:\n",
            "        str: The final markdown research report.\n",
            "    \"\"\"\n",
            "    title, topic = bot.document.title, bot.document.context\n",
            "\n",
            "    global get_bot\n",
            "    get_bot = lambda: bot\n",
            "\n",
            "    # Create initial state with topic and max_analysts\n",
            "    #initial_state: GenerateAnalystsState = { \"topic\": topic, \"max_analysts\": max_analysts, \"human_analyst_feedback\": None, \"analysts\": [], \"sections\": [],  \"messages\": [], \"context\": [] }\n",
            "    initial_state: GenerateAnalystsState = { \"topic\": topic, \"max_analysts\": max_analysts, \"human_analyst_feedback\": None, \"analysts\": []}\n",
            "    # Recreate the interview graph within the function\n",
            "    interview_builder = StateGraph(InterviewState)\n",
            "    interview_builder.add_node(\"ask_question\", generate_question_bot)\n",
            "    interview_builder.add_node(\"search_web\", search_web_bot)\n",
            "    interview_builder.add_node(\"search_wikipedia\", search_wikipedia_bot)\n",
            "    interview_builder.add_node(\"answer_question\", generate_answer_bot)\n",
            "    interview_builder.add_node(\"save_interview\", save_interview_bot)\n",
            "    interview_builder.add_node(\"write_section\", write_section_bot)\n",
            "\n",
            "    # Flow\n",
            "    interview_builder.add_edge(START, \"ask_question\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_web\")\n",
            "    interview_builder.add_edge(\"ask_question\", \"search_wikipedia\")\n",
            "    interview_builder.add_edge(\"search_web\", \"answer_question\")\n",
            "    interview_builder.add_edge(\"search_wikipedia\", \"answer_question\")\n",
            "    interview_builder.add_conditional_edges(\"answer_question\", route_messages,['ask_question','save_interview'])\n",
            "    interview_builder.add_edge(\"save_interview\", \"write_section\")\n",
            "    interview_builder.add_edge(\"write_section\", END)\n",
            "\n",
            "    # Compile interview graph\n",
            "    memory = MemorySaver()\n",
            "    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\"Conduct Interviews\")\n",
            "\n",
            "    # Set up the thread configuration\n",
            "    thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
            "\n",
            "    # Compile the research graph\n",
            "    builder = StateGraph(ResearchGraphState)\n",
            "    builder.add_node(\"create_analysts\", create_analysts_bot)\n",
            "    builder.add_node(\"human_feedback\", human_feedback_bot)\n",
            "    \n",
            "    # Use the interview_graph directly, without .compile()\n",
            "    builder.add_node(\"conduct_interview\", interview_graph)\n",
            "    builder.add_node(\"write_report\", write_report_bot)\n",
            "    builder.add_node(\"write_introduction\", write_introduction_bot)\n",
            "    builder.add_node(\"write_conclusion\", write_conclusion_bot)\n",
            "    builder.add_node(\"finalize_report\", finalize_report_bot)\n",
            "\n",
            "    # Logic\n",
            "    builder.add_edge(START, \"create_analysts\")\n",
            "    builder.add_edge(\"create_analysts\", \"human_feedback\")\n",
            "    builder.add_conditional_edges(\"human_feedback\", initiate_all_interviews, [\"create_analysts\", \"conduct_interview\"])\n",
            "    builder.add_edge(\"conduct_interview\", \"write_introduction\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_report\")\n",
            "    builder.add_edge(\"conduct_interview\", \"write_conclusion\")\n",
            "    builder.add_edge([\"write_conclusion\", \"write_report\", \"write_introduction\"], \"finalize_report\")\n",
            "    builder.add_edge(\"finalize_report\", END)\n",
            "\n",
            "    # Compile the graph\n",
            "    memory2 = MemorySaver()\n",
            "    graph = builder.compile(checkpointer=memory2)\n",
            "    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n",
            "\n",
            "    # Invoke the graph\n",
            "    try:\n",
            "        result = graph.invoke(initial_state, thread)\n",
            "        final_state = graph.get_state(thread)\n",
            "        report = final_state.values.get('final_report', '')\n",
            "    except Exception as e:\n",
            "        print(f\"Error in graph execution: {e}\")\n",
            "        print(f\"Current state: {graph.get_state(thread)}\")\n",
            "        raise\n",
            "\n",
            "    return report\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    from dataclasses import dataclass\n",
            "    from typing import List, Dict, Any, Optional\n",
            "    from datetime import datetime\n",
            "\n",
            "    @dataclass\n",
            "    class Section:\n",
            "        section_id: int\n",
            "        title: str\n",
            "        content: str\n",
            "        parent_id: Optional[int] = None\n",
            "\n",
            "    @dataclass\n",
            "    class Document:\n",
            "        title: str\n",
            "        context: str\n",
            "\n",
            "    class MockBot:\n",
            "        def __init__(self, title: str, context: str):\n",
            "            self.document = Document(title=title, context=context)\n",
            "            self.sections: List[Section] = []\n",
            "            self.resources: List[Dict] = []\n",
            "            self.next_section_id = 1\n",
            "            self.next_resource_id = 1\n",
            "            print(f\"MockBot initialized with title: {title} and context: {context}\")\n",
            "\n",
            "        def create_and_add_section_then_return_id(self, title: str, content: str, section_id: int = None, parent_id: int = None) -> int:\n",
            "            if section_id is None:\n",
            "                section_id = self.next_section_id\n",
            "                self.next_section_id += 1\n",
            "            \n",
            "            section = Section(section_id=section_id, title=title, content=content, parent_id=parent_id)\n",
            "            self.sections.append(section)\n",
            "            print(f\"Created section {section_id}: {title} (parent: {parent_id})\")\n",
            "            return section_id\n",
            "\n",
            "        def get_all_sections(self) -> List[Section]:\n",
            "            return self.sections\n",
            "\n",
            "        def get_sections(self, ids: List[int]) -> List[Section]:\n",
            "            return [s for s in self.sections if s.section_id in ids]\n",
            "\n",
            "        def edit_section(self, section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool:\n",
            "            for section in self.sections:\n",
            "                if section.section_id == section_id:\n",
            "                    if new_content is not None:\n",
            "                        section.content = new_content\n",
            "                    if new_title is not None:\n",
            "                        section.title = new_title\n",
            "                    if new_parent_id is not None:\n",
            "                        section.parent_id = new_parent_id\n",
            "                    print(f\"Edited section {section_id}\")\n",
            "                    return True\n",
            "            return False\n",
            "\n",
            "        def add_or_update_results_in_resources(self, results: List[Dict], metadatas_to_add: dict = None, store_linked_document_content: bool = False):\n",
            "            for result in results:\n",
            "                resource_id = self.next_resource_id\n",
            "                self.next_resource_id += 1\n",
            "                \n",
            "                resource = {\n",
            "                    'id': resource_id,\n",
            "                    'document': {\n",
            "                        'name': result.get('name', ''),\n",
            "                        'link': result.get('link', ''),\n",
            "                        'content': result.get('content', {})\n",
            "                    },\n",
            "                    'metadatas': metadatas_to_add or {}\n",
            "                }\n",
            "                \n",
            "                self.resources.append(resource)\n",
            "                print(f\"Added resource {resource_id}: {result.get('name', '')}\")\n",
            "            return self\n",
            "\n",
            "        def add_or_update_result_in_resources(self, metadatas: dict, name: str = None, content: dict = None, link: str = None, store_linked_document_content: bool = False):\n",
            "            resource_id = self.next_resource_id\n",
            "            self.next_resource_id += 1\n",
            "            \n",
            "            resource = {\n",
            "                'id': resource_id,\n",
            "                'document': {\n",
            "                    'name': name,\n",
            "                    'link': link,\n",
            "                    'content': content or {}\n",
            "                },\n",
            "                'metadatas': metadatas\n",
            "            }\n",
            "            \n",
            "            self.resources.append(resource)\n",
            "            print(f\"Added single resource {resource_id}: {name}\")\n",
            "            return self\n",
            "\n",
            "        def get_all_resources(self) -> List[Dict[str, Any]]:\n",
            "            return self.resources\n",
            "\n",
            "        def semantic_search_resources(self, query_texts, n_results=10):\n",
            "            print(f\"Mock semantic search for: {query_texts}\")\n",
            "            return []  # Mock empty results\n",
            "\n",
            "        def remove_resource(self, resource_id):\n",
            "            self.resources = [r for r in self.resources if r['id'] != resource_id]\n",
            "            print(f\"Removed resource {resource_id}\")\n",
            "            return self\n",
            "\n",
            "    # Test usage example:\n",
            "    def test_mock_bot():\n",
            "        # Initialize mock bot\n",
            "        mock_bot = MockBot(\n",
            "            title=\"Test Research\",\n",
            "            context=\"Testing the research assistant framework\"\n",
            "        )\n",
            "        \n",
            "        # Test section creation\n",
            "        section_id = mock_bot.create_and_add_section_then_return_id(\n",
            "            title=\"Introduction\",\n",
            "            content=\"This is a test introduction\"\n",
            "        )\n",
            "        \n",
            "        # Test resource addition\n",
            "        mock_bot.add_or_update_results_in_resources([\n",
            "            {\n",
            "                \"name\": \"Test Resource\",\n",
            "                \"link\": \"https://test.com\",\n",
            "                \"content\": {\"description\": \"Test content\"}\n",
            "            }\n",
            "        ], metadatas_to_add={\"source\": \"test\"})\n",
            "        \n",
            "        # Print current state\n",
            "        print(\"\\nCurrent sections:\")\n",
            "        for section in mock_bot.get_all_sections():\n",
            "            print(f\"Section {section.section_id}: {section.title}\")\n",
            "        \n",
            "        print(\"\\nCurrent resources:\")\n",
            "        for resource in mock_bot.get_all_resources():\n",
            "            print(f\"Resource {resource['id']}: {resource['document']['name']}\")\n",
            "\n",
            "        return mock_bot\n",
            "\n",
            "    mock_bot = MockBot(\n",
            "        title=\"Test Research @ Toulon M2 Master\",\n",
            "        context=\"Testing the research assistant framework in Toulon M2 Master\"\n",
            "    )\n",
            "\n",
            "    # Run with explicit error handling\n",
            "    if True: # try:\n",
            "        result = multi_agent_research_generation_persist_each_agent(mock_bot, max_analysts=2)\n",
            "        \n",
            "        print(\"\\nFinal Results:\")\n",
            "        print(\"Sections:\", len(mock_bot.get_all_sections()))\n",
            "        print(\"Resources:\", len(mock_bot.get_all_resources()))\n",
            "        \n",
            "        if result:\n",
            "            print(\"\\nReport preview:\", result[:200] + \"...\" if result else \"No report\")\n",
            "            \n",
            "    # except Exception as e:\n",
            "    #     print(f\"Error running research generation: {e}\")\n",
            "    #     print(\"\\nFinal bot state:\")\n",
            "    #     print(\"Sections:\", mock_bot.get_all_sections())\n",
            "    #     print(\"Resources:\", mock_bot.get_all_resources())]]]\n",
            "PREVIOUSLY SUCCESSFUL TASKS: [[[]]]\n",
            "PREVIOUSLY FAILED TASKS: [[[]]]\n",
            "PREVIOUS VALIDATION RESULTS: [[[]]]\n",
            "PREVIOUS ATTEMPTS TO CODE THE TASK: [[[]]]\n",
            "PREVIOUS ERRORS AND FIXES: [[[]]]\n",
            "****\n",
            "Attempting to decode few_shots tag:  {'num': 4, 'ranking_method': 'random', 'annotations': 'approve', 'summary': False, 'format': 'JSON'}\n",
            "Error decoding 'few_shots' tag: Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n",
            "Faulty JSON:  {'num': 4, 'ranking_method': 'random', 'annotations': 'approve', 'summary': False, 'format': 'JSON'}\n",
            "Adding agent data: {'agent_name': 'CodingAgent', 'data_key': 'saved_task'}\n",
            "User ID: 892DF7AA-1047-47EB-B871-D71BDC4B05B3\n",
            "2025-01-26 14:26:58 - {\"message\": \"[31mCANNOT SEND MESSAGE TO LLM:\\n\\n    CONTEXT:\\n    You are a helpful assistant that writes Python code exclusively to be executed to complete the task specified by me.\\n\\n    At each round of conversation, I will give you:\\n    - Reasoning: explanation of the task chosen...\\n    - Task: defined based on the current stage of progress\\n    - Plan: how to proceed and complete the current task\\n    - Tests: to validate that the task was correctly implemented and generates expected results\\n\\n    CURRENT STATE OF THE ENVIRONMENT:\\n    Document #.... : 1.title: ...; 2. abstract: ...; 3. table of content; 4. resources; 5. section progress; 6. events counted\\n\\n    TASK: You should respond with the best Python code to perform the task, i just want the code. no explanation, no reasoning, just the code.\\n\\n    INSTRUCTIONS:\\n    1) Reason and identify an ambitious and robust way to code the task.\\n    2) Write a function getting 'bot' as the first parameter which is an instance of the class SynthesisManager, containing all document resources.\\n     - it should comply with the test provided with no extra arguments\\n     - get title from bot.document.title, get abstract from bot.document.abstract\\n    3) Task performance is based on the semantic distance between a gold solution and the document you will modify using its sections/resources methods. If you generate great things but don't persist it using these methods below, the task score will be 0, be carreful. The main functions are:\\n        - class Section(section_id: int, title: str, content: str, parent_id: int)\\n        - Manipulate document sections: bot.create_and_add_section_then_return_id(title: str, content: str, section_id: int = None, parent_id: int = None) -> int, bot.get_all_sections() -> List[Section], bot.get_sections(ids: List[int]) -> List[Section], bot.edit_section(section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool, bot.remove_section(section_id: int) -> bool, bot.swap_sections(section_id_1: int, section_id_2: int) -> bool\\n        - Manipulate document resources: bot.add_or_update_results_in_resources(results, metadatas_to_add:dict=None, store_linked_document_content:bool=False), bot.add_or_update_result_in_resources(metadatas:dict, name:str=None, content:dict=None, link:str=None, store_linked_document_content:bool=False), bot.get_all_resources(self) -> List[Dict[str, Any]], bot.semantic_search_resources(query_texts, n_results=10), bot.add_or_update_results_in_resources(results, metadatas:dict=None, store_linked_document_content:bool=False), bot.get_and_store_link_content(link:str=None, parent_id=None, chaining:bool=True), bot.remove_resource(resource_id)\\n    4) Ensure the generated code adheres to reusability principles. The generated code should be modular and easy to maintain rather than specific to the task.\\n    5) Avoid hard-coding parameters. Pass necessary data as arguments to ensure reusability.\\n    6) The function should call existing helper functions as much as possible to focus on improving results, not redoing code.\\n    7) Ensure the code is executable with no placeholders and fully complete for immediate testing and deployment.\\n    8) Name your function meaningfully to reflect the task it is performing.\\n    9) Use the llm(prompt) function to generate answers based on a prompt to an LLM, it will return an object which will contain the text result in its .content porperty (result.content)\\n# Usage of llm:\\n# prompt = \\\"generate an outline for....\\\"\\nresponse = llm(prompt)\\n# print(response)\\n\\n    10) Your only allowed to research on free scientific API (e.g. Arxiv, Semantic Scholar, OpenAlex, Wikipedia...)\\n\\n    You should then respond with:\\n    - Reasoning: how to best implement the task with maximum efficiency\\n    - Code: fully executable Python code adhering to the task constraints\\n    \\n    \\nDOCUMENTATION OF AVAILABLE FUNCTIONS IN THE \\\"bot\\\" OBJECT (SynthesisManager class): {{{\\n# The following functions are available for use when generating code. Please leverage these pre-existing methods to avoid redundancy, maintain modularity, and ensure code reusability.\\n\\nclass SynthesisManager:\\n    def __init__(self, document: DocumentStructure, target_file_path: str = None):\\n        self.document = document\\n        self.min_cosine_similarity = cosine_similarity([self.document.embedding_model.embed_query(\\\".\\\")], [self.document.embedding_model.embed_query(\\\"If you can keep your head when all about you are losing theirs and blaming it on you, If you can trust yourself when all men doubt you, But make allowance for their doubting too ; If you can wait and not be tired by waiting, Or being lied about, dont deal in lies, Or being hated, dont give way to hating, And yet dont look too good, nor talk too wise\\\")])[0][0]\\n        if target_file_path:\\n            self.target_file_path = target_file_path\\n\\n    @staticmethod\\n    @method_call_counter\\n    def validate_section_format(section: Dict[str, Any]) -> bool:\\n        try:\\n            # This will try to instantiate a Section. If there's a problem with the data, an exception will be raised (e.g., a type error).\\n            Section(**section)\\n            return True\\n        except TypeError as e:\\n            print(e)\\n            return False\\n\\n    # add event using the document object add_event method add_event\\n    def add_event(self, event: str, data: Dict[str, Any]):\\n        self.document.add_event(event, data)\\n\\n    def normalized_cosine_similarity(self, a: List[float], b: List[float], min_cs: float = None) -> float:\\n        if min_cs is None:\\n            min_cs = self.min_cosine_similarity\\n        return (cosine_similarity([a], [b])[0][0] - min_cs) / (1 - min_cs)\\n\\n    def add_section(self, section: Section):\\n        if self.validate_section_format(asdict(section)):  # Convert dataclass to dict for validation\\n            self.document.document_content.sections_list.append(section)\\n            self.document.update_sections_embeddings([section.section_id])\\n            self.document.add_event({'action': 'add_section', 'section_id': section.section_id})\\n        else:\\n            print('Invalid section format.')\\n        return self\\n    \\n    def create_and_add_section_then_return_id(self, title: str, content: str, section_id: int = None, parent_id: int = None) -> int:\\n        if not section_id:\\n            # Generate section_id by using max section_id + 1\\n            section_id = (max([s.section_id for s in self.document.document_content.sections_list]) + 1) if len(self.document.document_content.sections_list) > 0 else 1\\n\\n        self.add_section(Section(section_id=section_id, parent_id=parent_id, title=title, content=content))\\n        return section_id\\n\\n    def get_sections(self, ids: List[int]) -> List[Section]:\\n        return [s for s in self.document.document_content.sections_list if s.section_id in ids]\\n    \\n    def get_all_sections(self) -> List[Section]:\\n        return self.document.document_content.sections_list\\n\\n    def remove_section(self, section_id: int) -> bool:\\n        section = next((s for s in self.document.document_content.sections_list if s.section_id == section_id), None)\\n        if section:\\n            self.document.document_content.sections_list = [s for s in self.document.document_content.sections_list if s.section_id != section_id]\\n            self.document.update_plan_embedding()\\n            self.document.add_event({'action': 'remove_section','section_id': section_id})\\n            return True\\n        else:\\n            return False\\n\\n    def edit_section(self, section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool:\\n        #section = next((s for s in self.document.document_content if s['id'] == section_id), None)\\n        section = next((s for s in self.document.document_content.sections_list if s.section_id == section_id), None)\\n        if section:\\n            action_event = {'action': 'edit_section','section_id': section_id}\\n            update_embeddings = False\\n            if new_content:\\n                section.content = new_content\\n                update_embeddings = True\\n                action_event['new_content'] = new_content\\n            if new_title:\\n                section.title = new_title\\n                update_embeddings = True\\n                action_event['new_title'] = new_title\\n            if new_parent_id:\\n                section.parent_id = new_parent_id\\n                action_event['new_parent_id'] = new_parent_id\\n            self.document.add_event('observation', action_event)\\n            if update_embeddings:\\n                self.document.update_sections_embeddings([section_id])\\n            return True\\n        else:\\n            return False\\n    \\n    def swap_sections(self, section_id_1: int, section_id_2: int) -> bool:\\n        section_1 = next((s for s in self.document.document_content.sections_list if s.section_id == section_id_1), None)\\n        section_2 = next((s for s in self.document.document_content.sections_list if s.section_id == section_id_2), None)\\n        if section_1 and section_2:\\n            section_1_index = self.document.document_content.sections_list.index(section_1)\\n            section_2_index = self.document.document_content.sections_list.index(section_2)\\n            self.document.document_content.sections_list[section_1_index], self.document.document_content.sections_list[section_2_index] = self.document.document_content.sections_list[section_2_index], self.document.document_content.sections_list[section_1_index]\\n            self.document.add_event('observation', {'action': 'swap_sections','section_id_1': section_id_1, 'section_id_2': section_id_2})\\n            return True\\n        else:\\n            return False\\n\\n    # search into resources stored in self.document.resources_vectordb and self.document.resources, return a list of resources\\n    def semantic_search_resources(self, query_embeddings = None, query_texts = None, n_results = 10, where = None, where_document = None, include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]):\\n        result = self.document.resources_vectordb.similarity_search_with_score( query_embeddings, k=n_results)\\n\\n    def get_all_resources(self) -> List[Dict[str, Any]]:\\n        return self.document.resources\\n\\n    def add_or_update_results_in_resources(self, results, metadatas_to_add: dict = {}, store_linked_document_content: bool = False):\\n        for result in results:\\n            content = {'description': result['description']} if isinstance(result['description'], str) else result['description']\\n            self.add_or_update_result_in_resources(metadatas=metadatas_to_add, name=result['title'], link=result['link'], content=content, store_linked_document_content=store_linked_document_content)\\n        return self\\n\\n    def add_or_update_result_in_resources(self, metadatas: dict, name: str=None, content: dict = None, link: str = None, store_linked_document_content: bool = False, chaining: bool = True):\\n        # Move metadatas to content if content data were provided into metadatas\\n        if metadatas.get('title') and not name:\\n            name = metadatas.get('title')\\n            metadatas.pop('title')\\n        if metadatas.get('link') and not link:\\n            link = metadatas.get('link')\\n            metadatas.pop('link')\\n        if metadatas.get('description') and not content:\\n            content = {'description': metadatas.get('description')}\\n            metadatas.pop('description')\\n\\n        # assert name or link are provided to identify the resource\\n        if not name and not link:\\n            raise ValueError(\\\"Either name or link must be provided\\\")\\n\\n        # Generate id using max\\n        id = max([r['id'] for r in self.document.resources]) + 1 if len(self.document.resources) > 0 else 1\\n        document = {'name': name, 'link': link, 'content': {'description': content} if isinstance(content, str) else content} # Convert content to dict if it's a string\\n        \\n        # Check for existing document\\n        existing_doc = next((doc for doc in self.document.resources if (doc['document']['name'] == name or (link and doc['document']['link'] == link))), None)\\n        \\n        if existing_doc:\\n            # Update the existing document\\n            updated_fields = []\\n            for key, value in document.items():\\n                if value and existing_doc['document'].get(key) != value:\\n                    existing_doc['document'][key] = value\\n                    updated_fields.append(key)\\n            \\n            # Log the event\\n            if updated_fields:\\n                # Update resources_vectordb\\n                self.document.resources_vectordb.add_texts([str(document)], metadatas=[metadatas], ids=[str(existing_doc['id'])])\\n                self.document.add_event('observation', {'action': 'modify_resource', 'document_name': name, 'updated_fields': updated_fields})\\n        else:\\n            # Add new document\\n            self.document.resources.append({\\n                'id': id,\\n                'metadatas': metadatas,\\n                'document': document,\\n            })\\n            if store_linked_document_content:\\n                childs_ids_list = self.get_and_store_link_content(link=link, parent_id=id, chaining=False)\\n                metadatas['childs_ids_list'] = childs_ids_list\\n            self.document.resources_vectordb.add_texts([str(document)], metadatas=[metadatas], ids=[str(id)])\\n            self.document.add_event('observation', {'action': 'add_resource', 'document_name': name})\\n\\n        return self if chaining else (existing_doc if existing_doc else self.document.resources[-1])\\n\\n    @method_call_counter\\n    def get_and_store_link_content(self, link: str = None, parent_id = None, chaining: bool = True):\\n            # Downloads an online document from the given link and stores it in the resources database.\\n            \\n            # Args:\\n            # link (str): The URL of the online document to download.\\n            # parent_id: The ID of the parent document, if any.\\n            # chaining (bool): Whether to return the current object or the IDs of the stored documents.\\n            \\n            # Returns:\\n            # If chaining is True, returns the current object. Otherwise, returns the IDs of the stored documents.\\n            from langchain.document_loaders import WebBaseLoader\\n            if link is None:\\n                raise ValueError(\\\"Please provide a link to download the document from\\\")\\n            loader = WebBaseLoader(link)\\n            data = loader.load()\\n            if parent_id is not None:\\n                for doc in data:\\n                    doc.metadata.extend([{'parent_id': parent_id}])\\n            from langchain.text_splitter import RecursiveCharacterTextSplitter\\n            splitter = RecursiveCharacterTextSplitter()\\n            all_splits = splitter.split_documents(data)\\n            splits_ids = self.document.resources_vectordb.db.add_documents(all_splits)\\n            if chaining:\\n                return self\\n            else:\\n                return splits_ids\\n\\n    def remove_resource(self, resource_id):\\n        # resource_id can be array or single int\\n        if isinstance(resource_id, list):\\n            self.document.resources = [r for r in self.document.resources if r['id'] not in resource_id]\\n        elif isinstance(resource_id, int):\\n            self.document.resources = [r for r in self.document.resources if r['id'] != resource_id]\\n        self.document.add_event('observation', {'action': 'remove_resources','resource_id': str(resource_id)})\\n        return self\\n    \\n    def remove_resources(self, resource_ids: List[int]):\\n        return self.remove_resource(resource_ids)\\n\\n    def restore_last_state(self):\\n        return self.document.restore_state()\\n\\n    def list_all_previous_document_events(self) -> List[Any]:\\n        return self.document.events\\n\\n    # function use to measure performance of the generated document\\n    def set_targetJSON_comparison(self, file_path: str, target_section_title_embedding_label: str = \\\"section_embedding_2\\\", target_section_content_embedding_label: str = \\\"content_embedding_2\\\", target_plan_embedding_label: str = \\\"plan_embedding_2\\\", normalize_embeddings: bool = True, min_cosine_similarity: float = None):\\n        self.target_file_path = file_path\\n        with open(file_path, 'r') as f:\\n            self.target_data = json.load(f)\\n        output_check = ''\\n        for section in self.target_data['plan']:\\n            output_check += section['section'] + \\\" /\\\"\\n        print(output_check)\\n        # Compute the total length for the target data (similar to the test method)\\n        self.target_total_content_length = sum(len(section['content']) for section in self.target_data['plan'])\\n        self.target_total_sections_count = len(self.target_data[\\\"plan\\\"])\\n\\n        self.target_plan_titles_embedding = np.mean([section[target_section_title_embedding_label] for section in self.target_data[\\\"plan\\\"]], axis=0)\\n        self.target_plan_contents_embedding = np.mean([section[target_section_content_embedding_label] for section in self.target_data[\\\"plan\\\"]], axis=0)\\n        self.target_plan_embedding = self.target_data[target_plan_embedding_label]\\n\\n        if normalize_embeddings:\\n            if min_cosine_similarity is None:\\n                dumb_embedding = self.document.dumb_embedding\\n                self.min_plan_titles_cosine_similarity = cosine_similarity([dumb_embedding], [self.target_plan_titles_embedding])[0][0]\\n                self.min_plan_contents_cosine_similarity = cosine_similarity([dumb_embedding], [self.target_plan_contents_embedding])[0][0]\\n                self.min_plan_cosine_similarity = cosine_similarity([dumb_embedding], [self.target_plan_embedding])[0][0]\\n            else:\\n                self.min_plan_titles_cosine_similarity = self.min_plan_contents_cosine_similarity = self.min_plan_cosine_similarity = min_cosine_similarity\\n        else:\\n            self.min_plan_titles_cosine_similarity = self.min_plan_contents_cosine_similarity = self.min_plan_cosine_similarity = 0 \\n\\n    def get_distance_to_targetJSON(self, target_section_title_embedding_label: str = \\\"section_embedding_2\\\", target_section_content_embedding_label: str = \\\"content_embedding_2\\\", target_plan_embedding_label: str = \\\"plan_embedding_2\\\", get_progress: bool = True):\\n        # if self does not have target_file_path\\n        if not hasattr(self, 'target_file_path'):\\n            raise ValueError(\\\"Please set target_file_path using set_targetJSON_comparison method\\\")\\n        if not hasattr(self, 'target_data'):\\n            section_embedding_key, content_embedding_key, plan_embedding_key = \\\"content_embedding_2\\\", \\\"section_embedding_2\\\", \\\"plan_embedding_2\\\"\\n            self.set_targetJSON_comparison(self.target_file_path, target_section_title_embedding_label = section_embedding_key, target_section_content_embedding_label = content_embedding_key, target_plan_embedding_label = plan_embedding_key)\\n            self.document.update_plan_embedding()\\n        elif not hasattr(self.document.document_content, 'sections_list_title_embedding'):\\n            self.document.update_plan_embedding()\\n        # Similar to what you did in the test\\n        current_sections_count = len(self.document.document_content.sections_list)\\n        # Count non empty section's content (not None and len > 1)\\n        current_plan_non_empty_sections_content_count = sum(1 for section in self.document.document_content.sections_list if section.content and len(section.content) > 1)\\n        current_plan_non_empty_sections_title_count = sum(1 for section in self.document.document_content.sections_list if section.title and len(section.title) > 1)\\n        current_content_length = sum(len(section.content) for section in self.document.document_content.sections_list)\\n\\n        plan_embedding = self.document.document_content.sections_list_embedding\\n        plan_titles_embedding = self.document.document_content.sections_list_title_embedding\\n        plan_contents_embedding = self.document.document_content.sections_list_content_embedding\\n        # compute embedding mean of all \\\"title\\\" in self.target_data[\\\"plan\\\"]\\n\\n        # Compute the similarity and content length percentage\\n        plan_embedding_similarity = self.normalized_cosine_similarity(plan_embedding, self.target_plan_embedding, self.min_plan_cosine_similarity)\\n        plan_titles_embedding_similarity = self.normalized_cosine_similarity(plan_titles_embedding, self.target_plan_titles_embedding, self.min_plan_titles_cosine_similarity)\\n        plan_contents_embedding_similarity = self.normalized_cosine_similarity(plan_contents_embedding, self.target_plan_contents_embedding, self.min_plan_contents_cosine_similarity)\\n\\n        content_length_ratio_to_target = round(current_content_length / self.target_total_content_length, 2)\\n        sections_count_ratio_to_target = round(current_sections_count / self.target_total_sections_count, 2)\\n        sections_content_non_empty_count_ratio_to_target = round(current_plan_non_empty_sections_content_count / self.target_total_sections_count, 2)\\n        sections_title_non_empty_count_ratio_to_target = round(current_plan_non_empty_sections_title_count / self.target_total_sections_count, 2)\\n\\n        distance_to_targetJSON = {\\n            \\\"plan_embedding_similarity\\\": round(plan_embedding_similarity, 6),\\n            \\\"plan_titles_embedding_similarity\\\": round(plan_titles_embedding_similarity, 6),\\n            \\\"plan_contents_embedding_similarity\\\": round(plan_contents_embedding_similarity, 6),\\n\\n            \\\"current_sections_count\\\": current_sections_count,\\n            \\\"sections_count_ratio_to_target\\\": sections_count_ratio_to_target,\\n\\n            \\\"title_non_empty_count_ratio_to_target\\\": sections_title_non_empty_count_ratio_to_target,\\n\\n            \\\"current_content_length\\\": current_content_length,\\n            \\\"content_length_ratio_to_target\\\": content_length_ratio_to_target,\\n\\n            \\\"content_non_empty_count_ratio_to_target\\\": sections_content_non_empty_count_ratio_to_target,\\n        }\\n\\n        if get_progress:\\n            # get ratio between same previous values and current values\\n            def get_ratio(previous_value, current_value):\\n                return round((previous_value - current_value) / (previous_value + 0.0000001)*100, 2) if previous_value else 0\\n            if hasattr(self, 'distance_to_targetJSON'):\\n                distance_to_targetJSON['plan_embedding_similarity_progress'] = get_ratio(plan_embedding_similarity, self.distance_to_targetJSON['plan_embedding_similarity'])\\n                distance_to_targetJSON['plan_titles_embedding_similarity_progress'] = get_ratio(plan_titles_embedding_similarity, self.distance_to_targetJSON['plan_titles_embedding_similarity'])\\n                distance_to_targetJSON['plan_contents_embedding_similarity_progress'] = get_ratio(plan_contents_embedding_similarity, self.distance_to_targetJSON['plan_contents_embedding_similarity'])\\n                distance_to_targetJSON['sections_count_ratio_to_target_progress'] = get_ratio(sections_count_ratio_to_target, self.distance_to_targetJSON['sections_count_ratio_to_target'])\\n                distance_to_targetJSON['title_non_empty_count_ratio_to_target_progress'] = get_ratio(sections_title_non_empty_count_ratio_to_target, self.distance_to_targetJSON['title_non_empty_count_ratio_to_target'])\\n                distance_to_targetJSON['content_length_ratio_to_target_progress'] = get_ratio(content_length_ratio_to_target, self.distance_to_targetJSON['content_length_ratio_to_target'])\\n                distance_to_targetJSON['content_non_empty_count_ratio_to_target_progress'] = get_ratio(sections_content_non_empty_count_ratio_to_target, self.distance_to_targetJSON['content_non_empty_count_ratio_to_target'])\\n\\n        self.distance_to_targetJSON = distance_to_targetJSON\\n\\n        return self.distance_to_targetJSON\\n\\n    # return the list of current sections with title, length of content, validation status, and feedback\\n    def get_plan_status(self, compact_string_format: bool = False, keys = [\\\"section_id\\\", \\\"title\\\", \\\"content_length\\\"]):\\n        #keys = [\\\"section_id\\\", \\\"title\\\", \\\"content_length\\\", \\\"validation_status\\\", \\\"feedback_to_process\\\", \\\"feedback_processed\\\"]\\n        plan_status = []\\n        for section in self.document.document_content.sections_list:\\n            status_data_full = [\\n                section.section_id,\\n                section.title,\\n                len(section.content),\\n                round(section.content_progress_validation_status, 1),\\n                section.local_feedback_to_process,\\n                section.local_feedback_processed,\\n            ]\\n            status_data = [data for key, data in zip(keys, status_data_full)]\\n\\n            if compact_string_format:\\n                plan_status.append(\\\"|\\\".join(map(str, status_data)))\\n            else:\\n                plan_status.append(dict(zip(keys, status_data)))\\n\\n        if compact_string_format and plan_status:\\n            if len(plan_status) == 0:\\n                return []\\n            header = \\\"|\\\".join(keys)\\n            plan_status.insert(0, header)\\n        \\n        return plan_status\\n\\n    def get_resources_status(self, compact_string_format: bool = False):\\n        resources_status = []\\n        content_info = {}\\n        for resource in self.document.resources:\\n            if resource['document']['content']:\\n                for key, value in resource['document']['content'].items():\\n                    content_info[f\\\"len(content['{key}'])\\\"] = len(str(value))\\n            \\n            status_data = [\\n                resource['id'],\\n                resource['metadatas'].get('search', 'unknown'),\\n                resource['document']['name'],\\n                len(resource['document']['link']) if (resource['document']['link'] and isinstance(resource['document']['link'], (list, tuple, np.ndarray))) else 0,\\n                *content_info.values()\\n            ]\\n            if compact_string_format:\\n                resources_status.append(\\\"|\\\".join(map(str, status_data)))\\n            else:\\n                keys = [\\\"id\\\", \\\"metadatas\\\", \\\"document_name\\\", \\\"document_link_length\\\"] + list(content_info.keys())\\n                resources_status.append(dict(zip(keys, status_data)))\\n        \\n        if compact_string_format:\\n            # if content_info is empty, it means that there is no resource in the document\\n            if len(content_info) == 0:\\n                return []\\n            header = \\\"id|metadatas|document_name|document_link_length|\\\" + \\\"|\\\".join(content_info.keys())\\n            resources_status.insert(0, header)\\n        \\n        return resources_status\\n\\n}}}\\n\\n    RESPONSE FORMAT:\\n    Reasoning: Your detailed thought process and why the chosen solution is optimal\\n    Code: Python implementation of the solution\\n    ```python\\n    # Example Python code here\\n    def your_function(bot):\\n        # implementation here...\\n    ```\\n    \\n    few_shots: {'num': 4, 'ranking_method': 'random', 'annotations': 'approve', 'summary': False, 'format': 'JSON'}\\n    \\nTASK DEFINITION: [[[1. **Reasoning**: \\n   - **Step 1**: The existing function `improve_multi_agent_research_generation` is designed to generate a full research report using a multi-agent workflow. However, it lacks a structured approach to writing sections and does not persist each section effectively.\\n   - **Step 2**: The current implementation merges sections except for the introduction and conclusion, which may lead to a lack of clarity and organization in the final report. Improving the section writing process and ensuring proper persistence can enhance the overall quality of the report.\\n   - **Step 3**: The goal is to enhance the function to ensure that each section is written and stored correctly, allowing for better organization and retrieval of information. This will also help in generating a more comprehensive and coherent report.\\n   - **Step 4**: By focusing on improving the writing and persistence of sections, we can challenge the LLM to create a more sophisticated workflow that includes detailed instructions for each step, ensuring that the report is well-structured and informative.\\n\\n2. **Next Best Task**:\\n   - **Function Name**: improve_multi_agent_research_generation\\n   - **Description**: Enhance the existing `improve_multi_agent_research_generation` function to include structured writing of sections, proper persistence of each section, and improved organization of the final report. This will involve creating distinct sections for each part of the research, ensuring that they are stored and retrieved effectively.\\n\\n3. **Performance Acceptance Criteria**:\\n   - The function should generate a report with clearly defined sections (e.g., introduction, methodology, results, discussion, conclusion).\\n   - Each section should be stored in the bot's resources for easy access and modification.\\n   - The final report should be coherent, well-organized, and formatted correctly in Markdown.\\n   - The function should handle errors gracefully and provide feedback if any step fails.\\n\\n4. **Development Plan**:\\n   - **Plan Depth**: 3\\n   - **Steps**:\\n     1. **Section Writing**:\\n        - 1.1. Create a function to write each section of the report.\\n        - 1.2. Ensure that each section is stored in the bot's resources.\\n        - 1.3. Implement a mechanism to retrieve and edit sections as needed.\\n     2. **Report Finalization**:\\n        - 2.1. Create a function to compile all sections into a final report.\\n        - 2.2. Ensure that the introduction and conclusion are written last, summarizing the content of the report.\\n        - 2.3. Format the final report in Markdown.\\n     3. **Error Handling and Feedback**:\\n        - 3.1. Implement error handling for each step of the process.\\n        - 3.2. Provide feedback to the user on the status of the report generation.\\n        - 3.3. Log any issues encountered during the process for future reference.\\n\\n5. **Tests**:\\n```python\\n# document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n# document #42252c6c-12f3-4edf-9045-8acd69bc3356 usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n```]]]\\nCURRENT STATE OF PROBLEM TO PERFORM/TEST TASK: [[[<<< Document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>\\n<<< Document #42252c6c-12f3-4edf-9045-8acd69bc3356 properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>]]]\\nRE-USABLE CODE PRIMITIVES: [[[from IPython.display import Image, display\\nfrom langgraph.graph import START, END, StateGraph\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\\nfrom pydantic import BaseModel, Field\\nfrom langgraph.graph import MessagesState\\nimport operator\\nfrom typing import List, Annotated\\nfrom typing_extensions import TypedDict\\nfrom langchain_community.document_loaders import WikipediaLoader\\nfrom langchain_core.messages import get_buffer_string\\nfrom langgraph.constants import Send\\n\\nfrom langchain_openai import ChatOpenAI\\nllm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\\nclass Analyst(BaseModel):\\n    affiliation: str = Field(\\n        description=\\\"Primary affiliation of the analyst.\\\",\\n    )\\n    name: str = Field(\\n        description=\\\"Name of the analyst.\\\"\\n    )\\n    role: str = Field(\\n        description=\\\"Role of the analyst in the context of the topic.\\\",\\n    )\\n    description: str = Field(\\n        description=\\\"Description of the analyst focus, concerns, and motives.\\\",\\n    )\\n    @property\\n    def persona(self) -> str:\\n        return f\\\"Name: {self.name}\\\\nRole: {self.role}\\\\nAffiliation: {self.affiliation}\\\\nDescription: {self.description}\\\\n\\\"\\n\\nclass Perspectives(BaseModel):\\n    analysts: List[Analyst] = Field(\\n        description=\\\"Comprehensive list of analysts with their roles and affiliations.\\\",\\n    )\\n\\nclass GenerateAnalystsState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n\\ndef create_analysts(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Create analysts \\\"\\\"\\\"\\n    if \\\"analyst_instructions\\\" not in state:\\n        state['analyst_instructions'] = \\\"\\\"\\\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n        1. First, review the research topic:\\n        {topic}\\n\\n        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\\n        {human_analyst_feedback}\\n\\n        3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n        4. Pick the top {max_analysts} themes.\\n\\n        5. Assign one analyst to each theme.\\n\\n        Respond with a JSON object containing a list of analysts, where each analyst has:\\n        - name: string\\n        - role: string\\n        - affiliation: string\\n        - description: string\\\"\\\"\\\"\\n    \\n    analyst_instructions = state[\\\"analyst_instructions\\\"]\\n\\n    topic=state['topic']\\n    max_analysts=state['max_analysts']\\n    human_analyst_feedback=state.get('human_analyst_feedback', '')\\n\\n    # Enforce structured output\\n    structured_llm = llm.with_structured_output(Perspectives)\\n\\n    # System message\\n    system_message = analyst_instructions.format(topic=topic,\\n                                                            human_analyst_feedback=human_analyst_feedback,\\n                                                            max_analysts=max_analysts)\\n\\n    print(system_message)\\n    # Generate question\\n    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\\\"Generate the set of analysts.\\\")])\\n    print(f\\\"Type of analysts: {type(analysts)}\\\")\\n\\n    # Write the list of analysis to state\\n    return {\\\"analysts\\\": analysts.analysts}\\n\\ndef create_analysts(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Create analysts \\\"\\\"\\\"\\n    if \\\"analyst_instructions\\\" not in state:\\n        state['analyst_instructions'] = \\\"\\\"\\\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n        1. First, review the research topic:\\n        {topic}\\n\\n        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\\n        {human_analyst_feedback}\\n\\n        3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n        4. Pick the top {max_analysts} themes.\\n\\n        5. Assign one analyst to each theme.\\n\\n        Respond with a JSON object containing a list of analysts, where each analyst has:\\n        - name: string\\n        - role: string\\n        - affiliation: string\\n        - description: string\\\"\\\"\\\"\\n    \\n    analyst_instructions = state[\\\"analyst_instructions\\\"]\\n    topic = state['topic']\\n    max_analysts = state['max_analysts']\\n    human_analyst_feedback = state.get('human_analyst_feedback', '')\\n\\n    # Enforce structured output\\n    structured_llm = llm.with_structured_output(Perspectives)\\n\\n    # System message\\n    system_message = analyst_instructions.format(\\n        topic=topic,\\n        human_analyst_feedback=human_analyst_feedback,\\n        max_analysts=max_analysts\\n    )\\n\\n    try:\\n        # Generate analysts\\n        analysts_response = structured_llm.invoke([\\n            SystemMessage(content=system_message),\\n            HumanMessage(content=\\\"Generate the set of analysts.\\\")\\n        ])\\n\\n        # Handle different possible return types\\n        if isinstance(analysts_response, Perspectives):\\n            # If it's already a Perspectives object\\n            generated_analysts = analysts_response.analysts\\n        elif isinstance(analysts_response, dict):\\n            # If it's a dict, try to extract analysts\\n            generated_analysts = analysts_response.get('analysts', [])\\n        elif hasattr(analysts_response, 'analysts'):\\n            # If it has an analysts attribute\\n            generated_analysts = analysts_response.analysts\\n        else:\\n            # Fallback to default analysts\\n            generated_analysts = [\\n                Analyst(\\n                    name=f\\\"Analyst {i+1}\\\", \\n                    role=f\\\"Research Specialist {i+1}\\\", \\n                    affiliation=\\\"Research Institute\\\", \\n                    description=f\\\"Analyzing aspects of {topic}\\\"\\n                ) for i in range(max_analysts)\\n            ]\\n\\n        # Ensure all are Analyst objects\\n        generated_analysts = [\\n            Analyst(**a.dict() if hasattr(a, 'dict') else a) \\n            for a in generated_analysts\\n        ]\\n\\n        return {\\\"analysts\\\": generated_analysts}\\n\\n    except Exception as e:\\n        print(f\\\"Error generating analysts: {e}\\\")\\n        # Fallback to default analysts\\n        default_analysts = [\\n            Analyst(\\n                name=f\\\"Analyst {i+1}\\\", \\n                role=f\\\"Research Specialist {i+1}\\\", \\n                affiliation=\\\"Research Institute\\\", \\n                description=f\\\"Analyzing aspects of {topic}\\\"\\n            ) for i in range(max_analysts)\\n        ]\\n        return {\\\"analysts\\\": default_analysts}\\n\\ndef human_feedback(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" No-op node that should be interrupted on \\\"\\\"\\\"\\n    pass\\n\\ndef should_continue(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Return the next node to execute \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback', None)\\n    if human_analyst_feedback:\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise end\\n    return END\\n\\nclass InterviewState(MessagesState):\\n    max_num_turns: int # Number turns of conversation\\n    context: Annotated[list, operator.add] # Source docs\\n    analyst: Analyst # Analyst asking questions\\n    interview: str # Interview transcript\\n    sections: list # Final key we duplicate in outer state for Send() API\\n\\nclass SearchQuery(BaseModel):\\n    search_query: str = Field(None, description=\\\"Search query for retrieval.\\\")\\n\\ndef generate_question(state: InterviewState):\\n    \\\"\\\"\\\" Node to generate a question \\\"\\\"\\\"\\n\\n    # Check if question_instructions is provided by state\\n    if \\\"question_instructions\\\" not in state:\\n        state[\\\"question_instructions\\\"] = \\\"\\\"\\\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\\n\\n        Your goal is boil down to interesting and specific insights related to your topic.\\n\\n        1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n        2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\n        Here is your topic of focus and set of goals: {goals}\\n\\n        Begin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\n        Continue to ask questions to drill down and refine your understanding of the topic.\\n\\n        When you are satisfied with your understanding, complete the interview with: \\\"Thank you so much for your help!\\\"\\n\\n        Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\\\"\\\"\\\"\\n\\n    question_instructions = state[\\\"question_instructions\\\"]\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n\\n    # Generate question\\n    system_message = question_instructions.format(goals=analyst.persona)\\n    question = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Write messages to state\\n    return {\\\"messages\\\": [question]}\\n\\ndef search_web(state: InterviewState):\\n    \\\"\\\"\\\" Retrieve academic papers from OpenAlex \\\"\\\"\\\"\\n    import requests\\n    OPENALEX_API_URL = \\\"https://api.openalex.org/works\\\"\\n\\n    # Search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    if \\\"search_instructions\\\" not in state:\\n        state[\\\"search_instructions\\\"] = SystemMessage(content=f\\\"\\\"\\\"You will be given a conversation between an analyst and an expert.\\n\\n        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\\n\\n        First, analyze the full conversation.\\n\\n        Pay particular attention to the final question posed by the analyst.\\n\\n        Convert this final question into a well-structured web search query\\\"\\\"\\\")\\n    search_instructions = state[\\\"search_instructions\\\"]\\n\\n    search_query = structured_llm.invoke([search_instructions] + state['messages'])\\n\\n    # Construct the OpenAlex API query parameters\\n    params = {\\n        \\\"search\\\": search_query.search_query,\\n        \\\"filter\\\": \\\"is_paratext:false\\\",  # Exclude non-research content\\n        \\\"sort\\\": \\\"relevance_score:desc\\\",\\n        \\\"per_page\\\": 5  # Limit to top 5 relevant results\\n    }\\n\\n    # Perform the request to OpenAlex\\n    response = requests.get(OPENALEX_API_URL, params=params)\\n    search_docs = []\\n    \\n    if response.status_code == 200:\\n        data = response.json()\\n        for result in data.get(\\\"results\\\", []):\\n            search_docs.append({\\n                \\\"title\\\": result.get(\\\"title\\\", \\\"Unknown Title\\\"),\\n                \\\"authors\\\": \\\", \\\".join([auth[\\\"author\\\"][\\\"display_name\\\"] for auth in result.get(\\\"authorships\\\", [])]),\\n                \\\"abstract\\\": result.get(\\\"abstract\\\", \\\"No abstract available\\\"),\\n                \\\"url\\\": result.get(\\\"id\\\", \\\"Unknown URL\\\")\\n            })\\n    else:\\n        print(f\\\"Error retrieving data from OpenAlex: {response.status_code}\\\")\\n\\n    # Format results\\n    formatted_search_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join(\\n        [\\n            f'<Document title=\\\"{doc[\\\"title\\\"]}\\\" href=\\\"{doc[\\\"url\\\"]}\\\">\\\\nAuthors: {doc[\\\"authors\\\"]}\\\\n\\\\nAbstract: {doc[\\\"abstract\\\"]}\\\\n</Document>'\\n            for doc in search_docs\\n        ]\\n    )\\n\\n    return {\\\"context\\\": [formatted_search_docs]}\\n\\ndef search_wikipedia(state: InterviewState):\\n    \\\"\\\"\\\" Retrieve docs from wikipedia \\\"\\\"\\\"\\n    # Check if search_instructions is provided by state\\n    if \\\"search_instructions\\\" not in state:\\n        state[\\\"search_instructions\\\"] = SystemMessage(content=f\\\"\\\"\\\"You will be given a conversation between an analyst and an expert.\\n        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\\n        First, analyze the full conversation.\\n        Pay particular attention to the final question posed by the analyst.\\n        Convert this final question into a well-structured web search query\\\"\\\"\\\")\\n\\n    search_instructions = state[\\\"search_instructions\\\"]\\n\\n    # Search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    search_query = structured_llm.invoke([search_instructions]+state['messages'])\\n\\n    # Search\\n    search_docs = WikipediaLoader(query=search_query.search_query,\\n                                  load_max_docs=2).load()\\n\\n     # Format\\n    formatted_search_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join(\\n        [\\n            f'<Document source=\\\"{doc.metadata[\\\"source\\\"]}\\\" page=\\\"{doc.metadata.get(\\\"page\\\", \\\"\\\")}\\\"/>\\\\n{doc.page_content}\\\\n</Document>'\\n            for doc in search_docs\\n        ]\\n    )\\n\\n    return {\\\"context\\\": [formatted_search_docs]}\\n\\ndef generate_answer(state: InterviewState):\\n    \\\"\\\"\\\" Node to answer a question \\\"\\\"\\\"\\n    # Check if answer_instructions is provided by state\\n    if \\\"answer_instructions\\\" not in state:\\n        state[\\\"answer_instructions\\\"] = \\\"\\\"\\\"You are an expert being interviewed by an analyst.\\n\\n        Here is analyst area of focus: {goals}.\\n\\n        You goal is to answer a question posed by the interviewer.\\n\\n        To answer question, use this context:\\n\\n        {context}\\n\\n        When answering questions, follow these guidelines:\\n\\n        1. Use only the information provided in the context.\\n\\n        2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\\n\\n        3. The context contain sources at the topic of each individual document.\\n\\n        4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\\n\\n        5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\\n\\n        6. If the source is: <Document source=\\\"assistant/docs/llama3_1.pdf\\\" page=\\\"7\\\"/>' then just list:\\n\\n        [1] assistant/docs/llama3_1.pdf, page 7\\n\\n        And skip the addition of the brackets as well as the Document source preamble in your citation.\\\"\\\"\\\"\\n\\n    answer_instructions = state[\\\"answer_instructions\\\"]\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n    context = state[\\\"context\\\"]\\n\\n    # Answer question\\n    system_message = answer_instructions.format(goals=analyst.persona, context=context)\\n    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Name the message as coming from the expert\\n    answer.name = \\\"expert\\\"\\n\\n    # Append it to state\\n    return {\\\"messages\\\": [answer]}\\n\\ndef save_interview(state: InterviewState):\\n\\n    \\\"\\\"\\\" Save interviews \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n\\n    # Convert interview to a string\\n    interview = get_buffer_string(messages)\\n\\n    # Save to interviews key\\n    return {\\\"interview\\\": interview}\\n\\ndef route_messages(state: InterviewState,\\n                   name: str = \\\"expert\\\"):\\n\\n    \\\"\\\"\\\" Route between question and answer \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n    max_num_turns = state.get('max_num_turns',2)\\n\\n    # Check the number of expert answers\\n    num_responses = len(\\n        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\\n    )\\n\\n    # End if expert has answered more than the max turns\\n    if num_responses >= max_num_turns:\\n        return 'save_interview'\\n\\n    # This router is run after each question - answer pair\\n    # Get the last question asked to check if it signals the end of discussion\\n    last_question = messages[-2]\\n\\n    if \\\"Thank you so much for your help\\\" in last_question.content:\\n        return 'save_interview'\\n    return \\\"ask_question\\\"\\n\\ndef write_section(state: InterviewState):\\n    \\\"\\\"\\\" Node to answer a question \\\"\\\"\\\"\\n    # Check if section_writer_instructions is provided by state\\n    if \\\"section_writer_instructions\\\" not in state:\\n        state[\\\"section_writer_instructions\\\"] = \\\"\\\"\\\"You are an expert technical writer.\\n\\n        Your task is to create a short, easily digestible section of a report based on a set of source documents.\\n\\n        1. Analyze the content of the source documents:\\n        - The name of each source document is at the start of the document, with the <Document tag.\\n\\n        2. Create a report structure using markdown formatting:\\n        - Use ## for the section title\\n        - Use ### for sub-section headers\\n\\n        3. Write the report following this structure:\\n        a. Title (## header)\\n        b. Summary (### header)\\n        c. Sources (### header)\\n\\n        4. Make your title engaging based upon the focus area of the analyst:\\n        {focus}\\n\\n        5. For the summary section:\\n        - Set up summary with general background / context related to the focus area of the analyst\\n        - Emphasize what is novel, interesting, or surprising about insights gathered from the interview\\n        - Create a numbered list of source documents, as you use them\\n        - Do not mention the names of interviewers or experts\\n        - Aim for approximately 400 words maximum\\n        - Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\\n\\n        6. In the Sources section:\\n        - Include all sources used in your report\\n        - Provide full links to relevant websites or specific document paths\\n        - Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\\n        - It will look like:\\n\\n        ### Sources\\n        [1] Link or Document name\\n        [2] Link or Document name\\n\\n        7. Be sure to combine sources. For example this is not correct:\\n\\n        [3] https://ai.meta.com/blog/meta-llama-3-1/\\n        [4] https://ai.meta.com/blog/meta-llama-3-1/\\n\\n        There should be no redundant sources. It should simply be:\\n\\n        [3] https://ai.meta.com/blog/meta-llama-3-1/\\n\\n        8. Final review:\\n        - Ensure the report follows the required structure\\n        - Include no preamble before the title of the report\\n        - Check that all guidelines have been followed\\\"\\\"\\\"\\n\\n    section_writer_instructions = state[\\\"section_writer_instructions\\\"]\\n\\n    # Get state\\n    interview = state[\\\"interview\\\"]\\n    context = state[\\\"context\\\"]\\n    analyst = state[\\\"analyst\\\"]\\n\\n    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\\n    system_message = section_writer_instructions.format(focus=analyst.description)\\n    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\\\"Use this source to write your section: {context}\\\")])\\n\\n    # Append it to state\\n    return {\\\"sections\\\": [section.content]}\\n\\nclass ResearchGraphState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n    sections: Annotated[list, operator.add] # Send() API key\\n    introduction: str # Introduction for the final report\\n    content: str # Content for the final report\\n    conclusion: str # Conclusion for the final report\\n    final_report: str # Final report\\n\\ndef initiate_all_interviews(state: ResearchGraphState):\\n    \\\"\\\"\\\" This is the \\\"map\\\" step where we run each interview sub-graph using Send API \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback')\\n    if human_analyst_feedback:\\n        # Return to create_analysts\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise kick off interviews in parallel via Send() API\\n    else:\\n        topic = state[\\\"topic\\\"]\\n        return [Send(\\\"conduct_interview\\\", {\\\"analyst\\\": analyst,\\n                                           \\\"messages\\\": [HumanMessage(\\n                                               content=f\\\"So you said you were writing an article on {topic}?\\\"\\n                                           )\\n                                                       ]}) for analyst in state[\\\"analysts\\\"]]\\n\\ndef write_report(state: ResearchGraphState):\\n    # Check if report_writer_instructions is provided by state\\n    if \\\"report_writer_instructions\\\" not in state:\\n        state['report_writer_instructions'] = \\\"\\\"\\\"You are a technical writer creating a report on this overall topic:\\n\\n{topic}\\n\\nYou have a team of analysts. Each analyst has done two things:\\n\\n1. They conducted an interview with an expert on a specific sub-topic.\\n2. They write up their finding into a memo.\\n\\nYour task:\\n\\n1. You will be given a collection of memos from your analysts.\\n2. Think carefully about the insights from each memo.\\n3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\\n4. Summarize the central points in each memo into a cohesive single narrative.\\n\\nTo format your report:\\n\\n1. Use markdown formatting.\\n2. Include no pre-amble for the report.\\n3. Use no sub-heading.\\n4. Start your report with a single title header: ## Insights\\n5. Do not mention any analyst names in your report.\\n6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\\n7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\\n8. List your sources in order and do not repeat.\\n\\n[1] Source 1\\n[2] Source 2\\n\\nHere are the memos from your analysts to build your report from:\\n\\n{context}\\\"\\\"\\\"\\n\\n    report_writer_instructions = state[\\\"report_writer_instructions\\\"]\\n\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\\n    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\\\"Write a report based upon these memos.\\\")])\\n    return {\\\"content\\\": report.content}\\n\\ndef write_introduction(state: ResearchGraphState):\\n    # Check if intro_conclusion_instructions is provided by state\\n    if \\\"intro_conclusion_instructions\\\" not in state:\\n        state['intro_conclusion_instructions'] = \\\"\\\"\\\"You are a technical writer finishing a report on {topic}\\n\\nYou will be given all of the sections of the report.\\n\\nYou job is to write a crisp and compelling introduction or conclusion section.\\n\\nThe user will instruct you whether to write the introduction or conclusion.\\n\\nInclude no pre-amble for either section.\\n\\nTarget around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\\n\\nUse markdown formatting.\\n\\nFor your introduction, create a compelling title and use the # header for the title.\\n\\nFor your introduction, use ## Introduction as the section header.\\n\\nFor your conclusion, use ## Conclusion as the section header.\\n\\nHere are the sections to reflect on for writing: {formatted_str_sections}\\\"\\\"\\\"\\n\\n    intro_conclusion_instructions = state[\\\"intro_conclusion_instructions\\\"]\\n\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    intro = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report introduction\\\")])\\n    return {\\\"introduction\\\": intro.content}\\n\\ndef write_conclusion(state: ResearchGraphState):\\n    # Check if intro_conclusion_instructions is provided by state\\n    if \\\"intro_conclusion_instructions\\\" not in state:\\n        state['intro_conclusion_instructions'] = \\\"\\\"\\\"You are a technical writer finishing a report on {topic}\\n\\nYou will be given all of the sections of the report.\\n\\nYou job is to write a crisp and compelling introduction or conclusion section.\\n\\nThe user will instruct you whether to write the introduction or conclusion.\\n\\nInclude no pre-amble for either section.\\n\\nTarget around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\\n\\nUse markdown formatting.\\n\\nFor your introduction, create a compelling title and use the # header for the title.\\n\\nFor your introduction, use ## Introduction as the section header.\\n\\nFor your conclusion, use ## Conclusion as the section header.\\n\\nHere are the sections to reflect on for writing: {formatted_str_sections}\\\"\\\"\\\"\\n\\n    intro_conclusion_instructions = state[\\\"intro_conclusion_instructions\\\"]        \\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report conclusion\\\")])\\n    return {\\\"conclusion\\\": conclusion.content}\\n\\ndef finalize_report(state: ResearchGraphState):\\n    \\\"\\\"\\\" This is the \\\"reduce\\\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion \\\"\\\"\\\"\\n    if not state:\\n        return {\\\"final_report\\\": \\\"\\\"}\\n        \\n    # Save full final report\\n    content = state.get(\\\"content\\\", \\\"\\\")\\n    introduction = state.get(\\\"introduction\\\", \\\"\\\")\\n    conclusion = state.get(\\\"conclusion\\\", \\\"\\\")\\n    \\n    if content.startswith(\\\"## Insights\\\"):\\n        content = content.strip(\\\"## Insights\\\")\\n    \\n    sources = None\\n    if \\\"## Sources\\\" in content:\\n        try:\\n            content, sources = content.split(\\\"\\\\n## Sources\\\\n\\\")\\n        except:\\n            sources = None\\n\\n    final_report = \\\"\\\"\\n    if introduction:\\n        final_report += introduction + \\\"\\\\n\\\\n---\\\\n\\\\n\\\"\\n    if content:\\n        final_report += content\\n    if conclusion:\\n        final_report += \\\"\\\\n\\\\n---\\\\n\\\\n\\\" + conclusion\\n    if sources:\\n        final_report += \\\"\\\\n\\\\n## Sources\\\\n\\\" + sources\\n\\n    return {\\\"final_report\\\": final_report}\\n\\ndef persist_final_report_in_bot(bot, final_report):\\n    \\\"\\\"\\\"\\n    Converts the final Markdown report into document sections,\\n    and extracts sources to store in bot.add_or_update_results_in_resources.\\n    \\\"\\\"\\\"\\n    # Handle None or empty input\\n    if final_report is None:\\n        final_report = {\\\"final_report\\\": \\\"\\\"}  # Create empty report instead of raising error\\n        \\n    # Handle dictionary input\\n    if isinstance(final_report, dict):\\n        final_report = final_report.get(\\\"final_report\\\", \\\"\\\")\\n    \\n    # Ensure we have a string\\n    final_report = str(final_report)\\n    \\n    # If empty report, create minimal section\\n    if not final_report.strip():\\n        bot.create_and_add_section_then_return_id(\\n            title=\\\"Empty Report\\\",\\n            content=\\\"No content was generated.\\\"\\n        )\\n        return\\n\\n    import re\\n    \\n    # The rest of the function remains the same...\\n    section_pattern = re.compile(r\\\"(##\\\\s+.+?)(?=##\\\\s|$)\\\", re.DOTALL)\\n    \\n    grand_titre_match = re.search(r\\\"^#\\\\s+(.*)\\\", final_report)\\n    if grand_titre_match:\\n        grand_titre = grand_titre_match.group(1).strip()\\n        bot.create_and_add_section_then_return_id(\\n            title=grand_titre,\\n            content=f\\\"(Main Title)\\\\n\\\\n{grand_titre}\\\"\\n        )\\n    \\n    sections = section_pattern.findall(final_report)\\n\\n    for section_md in sections:\\n        lines = section_md.split('\\\\n', 1)\\n        if len(lines) == 2:\\n            section_title_line, section_body = lines\\n        else:\\n            section_title_line = lines[0]\\n            section_body = \\\"\\\"\\n\\n        section_title = section_title_line.replace(\\\"##\\\", \\\"\\\").strip()\\n        bot.create_and_add_section_then_return_id(title=section_title, content=section_body)\\n\\n    sources_block_match = re.search(r\\\"(##\\\\s+Sources.*)\\\", final_report, re.IGNORECASE | re.DOTALL)\\n    if sources_block_match:\\n        sources_block = sources_block_match.group(1)\\n        \\n        lines = sources_block.split('\\\\n')\\n        resources_to_add = []\\n        for line in lines:\\n            m = re.match(r\\\"\\\\[(\\\\d+)\\\\]\\\\s+(.*)\\\", line.strip())\\n            if m:\\n                index = m.group(1)\\n                url_or_name = m.group(2)\\n                resource_item = {\\n                    \\\"name\\\": f\\\"Source_{index}\\\",\\n                    \\\"content\\\": {\\\"url\\\": url_or_name},\\n                    \\\"metadatas\\\": {\\\"index\\\": index}\\n                }\\n                resources_to_add.append(resource_item)\\n        \\n        if resources_to_add:\\n            bot.add_or_update_results_in_resources(\\n                results=resources_to_add, \\n                metadatas_to_add={\\\"type\\\": \\\"reference\\\"},\\n                store_linked_document_content=False\\n            )\\n\\ndef improve_multi_agent_research_generation(bot, max_analysts: int = 3):\\n    \\\"\\\"\\\"\\n    Generate a full research report using a multi-agent LangGraph workflow:  \\n    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\n    Write report, Write introduction, Write conclusion, Finalize report.\\n    Persist the document in the bot object through agent action.\\n    \\n    Args:\\n        bot: The bot object with the necessary methods.\\n        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\n    Returns:\\n        str: The final markdown research report.\\n    \\\"\\\"\\\"\\n    title, topic = bot.document.title, bot.document.context\\n    # Create initial state with topic and max_analysts\\n    initial_state: GenerateAnalystsState = { \\\"topic\\\": topic, \\\"max_analysts\\\": max_analysts, \\\"human_analyst_feedback\\\": None, \\\"analysts\\\": []}\\n\\n    # Recreate the interview graph within the function\\n    interview_builder = StateGraph(InterviewState)\\n    interview_builder.add_node(\\\"ask_question\\\", generate_question)\\n    interview_builder.add_node(\\\"search_web\\\", search_web)\\n    interview_builder.add_node(\\\"search_wikipedia\\\", search_wikipedia)\\n    interview_builder.add_node(\\\"answer_question\\\", generate_answer)\\n    interview_builder.add_node(\\\"save_interview\\\", save_interview)\\n    interview_builder.add_node(\\\"write_section\\\", write_section)\\n\\n    # Flow\\n    interview_builder.add_edge(START, \\\"ask_question\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_web\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_wikipedia\\\")\\n    interview_builder.add_edge(\\\"search_web\\\", \\\"answer_question\\\")\\n    interview_builder.add_edge(\\\"search_wikipedia\\\", \\\"answer_question\\\")\\n    interview_builder.add_conditional_edges(\\\"answer_question\\\", route_messages,['ask_question','save_interview'])\\n    interview_builder.add_edge(\\\"save_interview\\\", \\\"write_section\\\")\\n    interview_builder.add_edge(\\\"write_section\\\", END)\\n\\n    # Compile interview graph\\n    memory = MemorySaver()\\n    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\\\"Conduct Interviews\\\")\\n\\n    # Set up the thread configuration\\n    thread = {\\\"configurable\\\": {\\\"thread_id\\\": \\\"1\\\"}}\\n\\n    # Compile the research graph\\n    builder = StateGraph(ResearchGraphState)\\n    builder.add_node(\\\"create_analysts\\\", create_analysts)\\n    builder.add_node(\\\"human_feedback\\\", human_feedback)\\n    \\n    # Use the interview_graph directly, without .compile()\\n    builder.add_node(\\\"conduct_interview\\\", interview_graph)\\n    builder.add_node(\\\"write_report\\\", write_report)\\n    builder.add_node(\\\"write_introduction\\\", write_introduction)\\n    builder.add_node(\\\"write_conclusion\\\", write_conclusion)\\n    builder.add_node(\\\"finalize_report\\\", finalize_report)\\n\\n    # Logic\\n    builder.add_edge(START, \\\"create_analysts\\\")\\n    builder.add_edge(\\\"create_analysts\\\", \\\"human_feedback\\\")\\n    builder.add_conditional_edges(\\\"human_feedback\\\", initiate_all_interviews, [\\\"create_analysts\\\", \\\"conduct_interview\\\"])\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_introduction\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_report\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_conclusion\\\")\\n    builder.add_edge([\\\"write_conclusion\\\", \\\"write_report\\\", \\\"write_introduction\\\"], \\\"finalize_report\\\")\\n    builder.add_edge(\\\"finalize_report\\\", END)\\n\\n    # Compile the graph\\n    memory2 = MemorySaver()\\n    graph = builder.compile(checkpointer=memory2)\\n    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\\n\\n    # Invoke the graph\\n    graph.invoke(initial_state, thread)\\n\\n    # Retrieve the final report\\n    final_state = graph.get_state(thread)\\n    report = final_state.values.get('final_report')\\n\\n    persist_final_report_in_bot(bot, report)\\n    return report\\n\\nfrom IPython.display import Image, display\\nfrom langgraph.graph import START, END, StateGraph\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\\nfrom pydantic import BaseModel, Field\\nfrom langgraph.graph import MessagesState\\nimport operator\\nfrom typing import List, Annotated\\nfrom typing_extensions import TypedDict\\nfrom langchain_community.document_loaders import WikipediaLoader\\nfrom langchain_core.messages import get_buffer_string\\nfrom langgraph.constants import Send\\nfrom typing import List\\nfrom typing_extensions import TypedDict\\nfrom pydantic import BaseModel, Field\\nfrom IPython.display import Image, display\\nfrom langgraph.graph import START, END, StateGraph\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\\nimport operator\\nfrom typing import  Annotated\\nfrom langgraph.graph import MessagesState\\nimport datetime\\nimport os\\nfrom langchain_openai import ChatOpenAI\\n# Wikipedia search tool\\nfrom langchain_community.document_loaders import WikipediaLoader\\nfrom langchain_core.messages import get_buffer_string\\n\\n# os.environ['OPENAI_BASE_URL'] = 'https://api.openai.com/v1'\\n# os.environ['OPENROUTER_API_KEY'] = '\\n# os.environ['OPENAI_API_KEY'] = os.environ['OPENROUTER_API_KEY']\\n\\nllm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\\nclass Analyst(BaseModel):\\n    affiliation: str = Field(\\n        description=\\\"Primary affiliation of the analyst.\\\",\\n    )\\n    name: str = Field(\\n        description=\\\"Name of the analyst.\\\"\\n    )\\n    role: str = Field(\\n        description=\\\"Role of the analyst in the context of the topic.\\\",\\n    )\\n    description: str = Field(\\n        description=\\\"Description of the analyst focus, concerns, and motives.\\\",\\n    )\\n    @property\\n    def persona(self) -> str:\\n        return f\\\"Name: {self.name}\\\\nRole: {self.role}\\\\nAffiliation: {self.affiliation}\\\\nDescription: {self.description}\\\\n\\\"\\n\\nclass Perspectives(BaseModel):\\n    analysts: List[Analyst] = Field(\\n        description=\\\"Comprehensive list of analysts with their roles and affiliations.\\\",\\n    )\\n\\nclass GenerateAnalystsState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n\\nanalyst_instructions=\\\"\\\"\\\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n1. First, review the research topic:\\n{topic}\\n\\n2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\\n\\n{human_analyst_feedback}\\n\\n3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n4. Pick the top {max_analysts} themes.\\n\\n5. Assign one analyst to each theme.\\\"\\\"\\\"\\n\\ndef create_analysts_bot(state: GenerateAnalystsState):\\n\\n    \\\"\\\"\\\" Create analysts \\\"\\\"\\\"\\n\\n    topic=state['topic']\\n    max_analysts=state['max_analysts']\\n    human_analyst_feedback=state.get('human_analyst_feedback', '')\\n    print(f\\\"Topic: {topic}\\\")\\n    print(f\\\"Max analysts: {max_analysts}\\\")\\n    print(f\\\"Human analyst feedback: {human_analyst_feedback}\\\")\\n\\n    # Enforce structured output\\n    structured_llm = llm.with_structured_output(Perspectives)\\n\\n    # System message\\n    system_message = analyst_instructions.format(topic=topic,\\n                                                            human_analyst_feedback=human_analyst_feedback,\\n                                                            max_analysts=max_analysts)\\n\\n    # Generate question\\n    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\\\"Generate the set of analysts.\\\")])\\n    print(f\\\"Generated analysts: {analysts}\\\")\\n    # print type of analysts\\n    print(f\\\"Type of analysts: {type(analysts)}\\\")\\n    # Write the list of analysis to state\\n    #return { \\\"analysts\\\": analysts.analysts, \\\"sections\\\": state.get(\\\"sections\\\", []), \\\"context\\\": state.get(\\\"context\\\", []) }\\n    #return {\\\"analysts\\\": analysts.analysts, \\\"sections\\\": state.get(\\\"sections\\\", []), \\\"messages\\\": state.get(\\\"messages\\\", []), \\\"context\\\": state.get(\\\"context\\\", []), \\\"human_analyst_feedback\\\": state.get(\\\"human_analyst_feedback\\\", None)}\\n    return {\\\"analysts\\\": analysts.analysts}\\n\\ndef human_feedback_bot(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" No-op node that should be interrupted on \\\"\\\"\\\"\\n    pass\\n\\ndef should_continue(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Return the next node to execute \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback', None)\\n    if human_analyst_feedback:\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise end\\n    return END\\n\\n#further_feedack = None\\n#graph.update_state(thread, {\\\"human_analyst_feedback\\\":further_feedack}, as_node=\\\"human_feedback\\\")\\nclass InterviewState(MessagesState):\\n    max_num_turns: int = 2  # Add default value\\n    context: Annotated[list, operator.add] = []  # Add default value\\n    analyst: Analyst\\n    interview: str = \\\"\\\"  # Add default value\\n    sections: Annotated[list, operator.add] = []  # Add default value\\n    messages: list = []  # Add default value\\n\\nclass SearchQuery(BaseModel):\\n    search_query: str = Field(None, description=\\\"Search query for retrieval.\\\")\\n\\nquestion_instructions = \\\"\\\"\\\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\\n\\nYour goal is boil down to interesting and specific insights related to your topic.\\n\\n1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\nHere is your topic of focus and set of goals: {goals}\\n\\nBegin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\nContinue to ask questions to drill down and refine your understanding of the topic.\\n\\nWhen you are satisfied with your understanding, complete the interview with: \\\"Thank you so much for your help!\\\"\\n\\nRemember to stay in character throughout your response, reflecting the persona and goals provided to you.\\\"\\\"\\\"\\n\\ndef generate_question_bot(state: InterviewState):\\n    \\\"\\\"\\\" Node to generate a question \\\"\\\"\\\"\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n\\n    # Generate question\\n    system_message = question_instructions.format(goals=analyst.persona)\\n    question = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Write messages to state\\n    #return { \\\"messages\\\": [question], \\\"context\\\": state.get(\\\"context\\\", []), \\\"sections\\\": state.get(\\\"sections\\\", [])}\\n    return {\\\"messages\\\": [question]}\\n\\n# Search query writing\\nsearch_instructions = SystemMessage(content=f\\\"\\\"\\\"You will be given a conversation between an analyst and an expert.\\n\\nYour goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\\n\\nFirst, analyze the full conversation.\\n\\nPay particular attention to the final question posed by the analyst.\\n\\nConvert this final question into a well-structured web search query\\\"\\\"\\\")\\n\\ndef search_web_bot(state: InterviewState):\\n    \\\"\\\"\\\"Enhanced web search with proper resource persistence\\\"\\\"\\\"\\n    import requests\\n    OPENALEX_API_URL = \\\"https://api.openalex.org/works\\\"\\n    \\n    # Get search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    search_query = structured_llm.invoke([search_instructions] + state['messages'])\\n    \\n    # Search OpenAlex\\n    params = {\\n        \\\"search\\\": search_query.search_query,\\n        \\\"filter\\\": \\\"is_paratext:false\\\",\\n        \\\"sort\\\": \\\"relevance_score:desc\\\",\\n        \\\"per_page\\\": 5\\n    }\\n    \\n    response = requests.get(OPENALEX_API_URL, params=params)\\n    search_docs = []\\n    \\n    if response.status_code == 200:\\n        data = response.json()\\n        \\n        # Prepare resources for bot persistence\\n        resources_to_add = []\\n        for result in data.get(\\\"results\\\", []):\\n            doc_info = {\\n                \\\"title\\\": result.get(\\\"title\\\", \\\"Unknown Title\\\"),\\n                \\\"link\\\": result.get(\\\"id\\\", \\\"Unknown URL\\\"),\\n                \\\"description\\\": {\\n                    \\\"abstract\\\": result.get(\\\"abstract\\\", \\\"No abstract available\\\"),\\n                    \\\"authors\\\": \\\", \\\".join([auth[\\\"author\\\"][\\\"display_name\\\"] for auth in result.get(\\\"authorships\\\", [])])\\n                }\\n            }\\n            search_docs.append(doc_info)\\n            resources_to_add.append({\\n                \\\"name\\\": doc_info[\\\"title\\\"],\\n                \\\"link\\\": doc_info[\\\"link\\\"],\\n                \\\"content\\\": doc_info[\\\"description\\\"]\\n            })\\n\\n        # Persist to bot resources with metadata\\n        bot = get_bot()\\n        if bot:\\n            bot.add_or_update_results_in_resources(\\n                results=resources_to_add,\\n                metadatas_to_add={\\n                    \\\"source\\\": \\\"OpenAlex\\\",\\n                    \\\"query\\\": search_query.search_query,\\n                    \\\"search_timestamp\\\": str(datetime.now())\\n                }\\n            )\\n\\n    # Format for LLM consumption\\n    formatted_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join([\\n        f'<Document title=\\\"{doc[\\\"title\\\"]}\\\" href=\\\"{doc[\\\"link\\\"]}\\\">\\\\nAuthors: {doc[\\\"description\\\"][\\\"authors\\\"]}\\\\nAbstract: {doc[\\\"description\\\"][\\\"abstract\\\"]}\\\\n</Document>'\\n        for doc in search_docs\\n    ])\\n    \\n    return {\\\"context\\\": [formatted_docs]}\\n\\n\\ndef search_wikipedia_bot(state: InterviewState):\\n\\n    \\\"\\\"\\\" Retrieve docs from wikipedia \\\"\\\"\\\"\\n\\n    # Search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    search_query = structured_llm.invoke([search_instructions]+state['messages'])\\n\\n    # Search\\n    search_docs = WikipediaLoader(query=search_query.search_query,\\n                                  load_max_docs=2).load()\\n\\n     # Format\\n    formatted_search_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join(\\n        [\\n            f'<Document source=\\\"{doc.metadata[\\\"source\\\"]}\\\" page=\\\"{doc.metadata.get(\\\"page\\\", \\\"\\\")}\\\"/>\\\\n{doc.page_content}\\\\n</Document>'\\n            for doc in search_docs\\n        ]\\n    )\\n\\n    return {\\\"context\\\": [formatted_search_docs]}\\n\\nanswer_instructions = \\\"\\\"\\\"You are an expert being interviewed by an analyst.\\n\\nHere is analyst area of focus: {goals}.\\n\\nYou goal is to answer a question posed by the interviewer.\\n\\nTo answer question, use this context:\\n\\n{context}\\n\\nWhen answering questions, follow these guidelines:\\n\\n1. Use only the information provided in the context.\\n\\n2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\\n\\n3. The context contain sources at the topic of each individual document.\\n\\n4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\\n\\n5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\\n\\n6. If the source is: <Document source=\\\"assistant/docs/llama3_1.pdf\\\" page=\\\"7\\\"/>' then just list:\\n\\n[1] assistant/docs/llama3_1.pdf, page 7\\n\\nAnd skip the addition of the brackets as well as the Document source preamble in your citation.\\\"\\\"\\\"\\n\\ndef generate_answer_bot(state: InterviewState):\\n\\n    \\\"\\\"\\\" Node to answer a question \\\"\\\"\\\"\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n    context = state[\\\"context\\\"]\\n\\n    # Answer question\\n    system_message = answer_instructions.format(goals=analyst.persona, context=context)\\n    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Name the message as coming from the expert\\n    answer.name = \\\"expert\\\"\\n\\n    # Append it to state\\n    return {\\\"messages\\\": [answer]}\\n\\ndef save_interview_bot(state: InterviewState):\\n\\n    \\\"\\\"\\\" Save interviews \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n\\n    # Convert interview to a string\\n    interview = get_buffer_string(messages)\\n\\n    # Save to interviews key\\n    return {\\\"interview\\\": interview}\\n\\ndef route_messages(state: InterviewState,\\n                   name: str = \\\"expert\\\"):\\n\\n    \\\"\\\"\\\" Route between question and answer \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n    max_num_turns = state.get('max_num_turns',2)\\n\\n    # Check the number of expert answers\\n    num_responses = len(\\n        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\\n    )\\n\\n    # End if expert has answered more than the max turns\\n    if num_responses >= max_num_turns:\\n        return 'save_interview'\\n\\n    # This router is run after each question - answer pair\\n    # Get the last question asked to check if it signals the end of discussion\\n    last_question = messages[-2]\\n\\n    if \\\"Thank you so much for your help\\\" in last_question.content:\\n        return 'save_interview'\\n    return \\\"ask_question\\\"\\n\\nsection_writer_instructions = \\\"\\\"\\\"You are an expert technical writer.\\n\\nYour task is to create a short, easily digestible section of a report based on a set of source documents.\\n\\n1. Analyze the content of the source documents:\\n- The name of each source document is at the start of the document, with the <Document tag.\\n\\n2. Create a report structure using markdown formatting:\\n- Use ## for the section title\\n- Use ### for sub-section headers\\n\\n3. Write the report following this structure:\\na. Title (## header)\\nb. Summary (### header)\\nc. Sources (### header)\\n\\n4. Make your title engaging based upon the focus area of the analyst:\\n{focus}\\n\\n5. For the summary section:\\n- Set up summary with general background / context related to the focus area of the analyst\\n- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\\n- Create a numbered list of source documents, as you use them\\n- Do not mention the names of interviewers or experts\\n- Aim for approximately 400 words maximum\\n- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\\n\\n6. In the Sources section:\\n- Include all sources used in your report\\n- Provide full links to relevant websites or specific document paths\\n- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\\n- It will look like:\\n\\n### Sources\\n[1] Link or Document name\\n[2] Link or Document name\\n\\n7. Be sure to combine sources. For example this is not correct:\\n\\n[3] https://ai.meta.com/blog/meta-llama-3-1/\\n[4] https://ai.meta.com/blog/meta-llama-3-1/\\n\\nThere should be no redundant sources. It should simply be:\\n\\n[3] https://ai.meta.com/blog/meta-llama-3-1/\\n\\n8. Final review:\\n- Ensure the report follows the required structure\\n- Include no preamble before the title of the report\\n- Check that all guidelines have been followed\\\"\\\"\\\"\\n\\ndef write_section_bot(state: InterviewState):\\n    \\\"\\\"\\\"Enhanced section writing with proper structure persistence\\\"\\\"\\\"\\n    interview = state[\\\"interview\\\"]\\n    context = state[\\\"context\\\"]\\n    analyst = state[\\\"analyst\\\"]\\n    \\n    section = llm.invoke([\\n        SystemMessage(content=section_writer_instructions),\\n        HumanMessage(content=f\\\"Write a section based on: {context}\\\")\\n    ])\\n    \\n    bot = get_bot()\\n    if bot:\\n        try:\\n            # Create main content section if doesn't exist\\n            main_sections = bot.get_all_sections()\\n            main_content_id = next(\\n                (s.section_id for s in main_sections if s.title == \\\"Main Content\\\"), \\n                None\\n            )\\n            \\n            if not main_content_id:\\n                main_content_id = bot.create_and_add_section_then_return_id(\\n                    title=\\\"Main Content\\\",\\n                    content=\\\"\\\",\\n                    section_id=1  # Ensure it's first\\n                )\\n\\n            # Add analyst's section as child\\n            section_id = bot.create_and_add_section_then_return_id(\\n                title=f\\\"Analysis by {analyst.name}\\\",\\n                content=section.content,\\n                parent_id=main_content_id\\n            )\\n            \\n            # Store metadata about the section\\n            bot.add_or_update_result_in_resources(\\n                metadatas={\\n                    \\\"section_id\\\": section_id,\\n                    \\\"analyst\\\": analyst.name,\\n                    \\\"analyst_role\\\": analyst.role,\\n                    \\\"timestamp\\\": str(datetime.now())\\n                },\\n                name=f\\\"Section_{section_id}_Metadata\\\",\\n                content={\\\"section_type\\\": \\\"analysis\\\", \\\"parent_section\\\": main_content_id}\\n            )\\n            \\n        except Exception as e:\\n            print(f\\\"Error persisting section: {e}\\\")\\n            \\n    return {\\\"sections\\\": [section.content]}\\n\\n\\nclass ResearchGraphState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n    sections: Annotated[list, operator.add] # Send() API key\\n    introduction: str # Introduction for the final report\\n    content: str # Content for the final report\\n    conclusion: str # Conclusion for the final report\\n    final_report: str # Final report\\n\\ndef initiate_all_interviews(state: ResearchGraphState):\\n    \\\"\\\"\\\" This is the \\\"map\\\" step where we run each interview sub-graph using Send API \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback')\\n    if human_analyst_feedback:\\n        # Return to create_analysts\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise kick off interviews in parallel via Send() API\\n    else:\\n        topic = state[\\\"topic\\\"]\\n        # return [Send(\\\"conduct_interview\\\", {\\\"analyst\\\": analyst,\\n        #                                    \\\"messages\\\": [HumanMessage(\\n        #                                        content=f\\\"So you said you were writing an article on {topic}?\\\"\\n        #                                    )\\n        #                                                ]}) for analyst in state[\\\"analysts\\\"]]\\n        return [Send(\\\"conduct_interview\\\", {\\n                    \\\"analyst\\\": analyst, \\\"messages\\\": [ HumanMessage( content=f\\\"So you said you were writing an article on {topic}?\\\")],\\n                    \\\"max_num_turns\\\": 2,  # Add explicit max_num_turns\\n                    \\\"context\\\": [],  # Add empty context\\n                    \\\"sections\\\": [],  # Add empty sections\\n                    \\\"interview\\\": \\\"\\\"  # Add empty interview\\n                }\\n            ) for analyst in state[\\\"analysts\\\"]\\n        ]\\nreport_writer_instructions = \\\"\\\"\\\"You are a technical writer creating a report on this overall topic:\\n\\n{topic}\\n\\nYou have a team of analysts. Each analyst has done two things:\\n\\n1. They conducted an interview with an expert on a specific sub-topic.\\n2. They write up their finding into a memo.\\n\\nYour task:\\n\\n1. You will be given a collection of memos from your analysts.\\n2. Think carefully about the insights from each memo.\\n3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\\n4. Summarize the central points in each memo into a cohesive single narrative.\\n\\nTo format your report:\\n\\n1. Use markdown formatting.\\n2. Include no pre-amble for the report.\\n3. Use no sub-heading.\\n4. Start your report with a single title header: ## Insights\\n5. Do not mention any analyst names in your report.\\n6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\\n7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\\n8. List your sources in order and do not repeat.\\n\\n[1] Source 1\\n[2] Source 2\\n\\nHere are the memos from your analysts to build your report from:\\n\\n{context}\\\"\\\"\\\"\\n\\ndef write_report_bot(state: ResearchGraphState):\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\\n    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\\\"Write a report based upon these memos.\\\")])\\n    return {\\\"content\\\": report.content}\\n\\nintro_conclusion_instructions = \\\"\\\"\\\"You are a technical writer finishing a report on {topic}\\n\\nYou will be given all of the sections of the report.\\n\\nYou job is to write a crisp and compelling introduction or conclusion section.\\n\\nThe user will instruct you whether to write the introduction or conclusion.\\n\\nInclude no pre-amble for either section.\\n\\nTarget around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\\n\\nUse markdown formatting.\\n\\nFor your introduction, create a compelling title and use the # header for the title.\\n\\nFor your introduction, use ## Introduction as the section header.\\n\\nFor your conclusion, use ## Conclusion as the section header.\\n\\nHere are the sections to reflect on for writing: {formatted_str_sections}\\\"\\\"\\\"\\n\\ndef write_introduction_bot(state: ResearchGraphState):\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    intro = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report introduction\\\")])\\n    return {\\\"introduction\\\": intro.content}\\n\\ndef write_conclusion_bot(state: ResearchGraphState):\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report conclusion\\\")])\\n    return {\\\"conclusion\\\": conclusion.content}\\n\\ndef finalize_report_bot(state: ResearchGraphState):\\n    \\\"\\\"\\\"Enhanced report finalization with proper structure\\\"\\\"\\\"\\n    content = state[\\\"content\\\"]\\n    introduction = state[\\\"introduction\\\"]\\n    conclusion = state[\\\"conclusion\\\"]\\n    \\n    bot = get_bot()\\n    if bot:\\n        try:\\n            # Organize sections in proper order\\n            intro_id = bot.create_and_add_section_then_return_id(\\n                title=\\\"Introduction\\\",\\n                content=introduction,\\n                section_id=1\\n            )\\n            \\n            content_id = bot.create_and_add_section_then_return_id(\\n                title=\\\"Main Findings\\\",\\n                content=content,\\n                section_id=2\\n            )\\n            \\n            conclusion_id = bot.create_and_add_section_then_return_id(\\n                title=\\\"Conclusion\\\",\\n                content=conclusion,\\n                section_id=3\\n            )\\n            \\n            # Add metadata about report structure\\n            bot.add_or_update_result_in_resources(\\n                metadatas={\\n                    \\\"report_structure\\\": {\\n                        \\\"introduction_id\\\": intro_id,\\n                        \\\"content_id\\\": content_id,\\n                        \\\"conclusion_id\\\": conclusion_id\\n                    },\\n                    \\\"generation_timestamp\\\": str(datetime.now())\\n                },\\n                name=\\\"Final_Report_Structure\\\"\\n            )\\n            \\n            # Combine for final report\\n            final_report = f\\\"{introduction}\\\\n\\\\n---\\\\n\\\\n{content}\\\\n\\\\n---\\\\n\\\\n{conclusion}\\\"\\n            \\n            # Store final assembled version\\n            bot.create_and_add_section_then_return_id(\\n                title=\\\"Complete Report\\\",\\n                content=final_report,\\n                section_id=4\\n            )\\n            \\n        except Exception as e:\\n            print(f\\\"Error finalizing report: {e}\\\")\\n            final_report = f\\\"{introduction}\\\\n\\\\n---\\\\n\\\\n{content}\\\\n\\\\n---\\\\n\\\\n{conclusion}\\\"\\n            \\n    return {\\\"final_report\\\": final_report}\\n\\ndef multi_agent_research_generation_persist_each_agent(bot, max_analysts: int = 3):\\n    \\\"\\\"\\\"\\n    Generate a full research report using a multi-agent LangGraph workflow:  \\n    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\n    Write report, Write introduction, Write conclusion, Finalize report.\\n    Persist the document in the bot object through agent action.\\n    \\n    Args:\\n        bot: The bot object with the necessary methods.\\n        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\n    Returns:\\n        str: The final markdown research report.\\n    \\\"\\\"\\\"\\n    title, topic = bot.document.title, bot.document.context\\n\\n    global get_bot\\n    get_bot = lambda: bot\\n\\n    # Create initial state with topic and max_analysts\\n    #initial_state: GenerateAnalystsState = { \\\"topic\\\": topic, \\\"max_analysts\\\": max_analysts, \\\"human_analyst_feedback\\\": None, \\\"analysts\\\": [], \\\"sections\\\": [],  \\\"messages\\\": [], \\\"context\\\": [] }\\n    initial_state: GenerateAnalystsState = { \\\"topic\\\": topic, \\\"max_analysts\\\": max_analysts, \\\"human_analyst_feedback\\\": None, \\\"analysts\\\": []}\\n    # Recreate the interview graph within the function\\n    interview_builder = StateGraph(InterviewState)\\n    interview_builder.add_node(\\\"ask_question\\\", generate_question_bot)\\n    interview_builder.add_node(\\\"search_web\\\", search_web_bot)\\n    interview_builder.add_node(\\\"search_wikipedia\\\", search_wikipedia_bot)\\n    interview_builder.add_node(\\\"answer_question\\\", generate_answer_bot)\\n    interview_builder.add_node(\\\"save_interview\\\", save_interview_bot)\\n    interview_builder.add_node(\\\"write_section\\\", write_section_bot)\\n\\n    # Flow\\n    interview_builder.add_edge(START, \\\"ask_question\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_web\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_wikipedia\\\")\\n    interview_builder.add_edge(\\\"search_web\\\", \\\"answer_question\\\")\\n    interview_builder.add_edge(\\\"search_wikipedia\\\", \\\"answer_question\\\")\\n    interview_builder.add_conditional_edges(\\\"answer_question\\\", route_messages,['ask_question','save_interview'])\\n    interview_builder.add_edge(\\\"save_interview\\\", \\\"write_section\\\")\\n    interview_builder.add_edge(\\\"write_section\\\", END)\\n\\n    # Compile interview graph\\n    memory = MemorySaver()\\n    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\\\"Conduct Interviews\\\")\\n\\n    # Set up the thread configuration\\n    thread = {\\\"configurable\\\": {\\\"thread_id\\\": \\\"1\\\"}}\\n\\n    # Compile the research graph\\n    builder = StateGraph(ResearchGraphState)\\n    builder.add_node(\\\"create_analysts\\\", create_analysts_bot)\\n    builder.add_node(\\\"human_feedback\\\", human_feedback_bot)\\n    \\n    # Use the interview_graph directly, without .compile()\\n    builder.add_node(\\\"conduct_interview\\\", interview_graph)\\n    builder.add_node(\\\"write_report\\\", write_report_bot)\\n    builder.add_node(\\\"write_introduction\\\", write_introduction_bot)\\n    builder.add_node(\\\"write_conclusion\\\", write_conclusion_bot)\\n    builder.add_node(\\\"finalize_report\\\", finalize_report_bot)\\n\\n    # Logic\\n    builder.add_edge(START, \\\"create_analysts\\\")\\n    builder.add_edge(\\\"create_analysts\\\", \\\"human_feedback\\\")\\n    builder.add_conditional_edges(\\\"human_feedback\\\", initiate_all_interviews, [\\\"create_analysts\\\", \\\"conduct_interview\\\"])\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_introduction\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_report\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_conclusion\\\")\\n    builder.add_edge([\\\"write_conclusion\\\", \\\"write_report\\\", \\\"write_introduction\\\"], \\\"finalize_report\\\")\\n    builder.add_edge(\\\"finalize_report\\\", END)\\n\\n    # Compile the graph\\n    memory2 = MemorySaver()\\n    graph = builder.compile(checkpointer=memory2)\\n    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\\n\\n    # Invoke the graph\\n    try:\\n        result = graph.invoke(initial_state, thread)\\n        final_state = graph.get_state(thread)\\n        report = final_state.values.get('final_report', '')\\n    except Exception as e:\\n        print(f\\\"Error in graph execution: {e}\\\")\\n        print(f\\\"Current state: {graph.get_state(thread)}\\\")\\n        raise\\n\\n    return report\\n\\nif __name__ == \\\"__main__\\\":\\n    from dataclasses import dataclass\\n    from typing import List, Dict, Any, Optional\\n    from datetime import datetime\\n\\n    @dataclass\\n    class Section:\\n        section_id: int\\n        title: str\\n        content: str\\n        parent_id: Optional[int] = None\\n\\n    @dataclass\\n    class Document:\\n        title: str\\n        context: str\\n\\n    class MockBot:\\n        def __init__(self, title: str, context: str):\\n            self.document = Document(title=title, context=context)\\n            self.sections: List[Section] = []\\n            self.resources: List[Dict] = []\\n            self.next_section_id = 1\\n            self.next_resource_id = 1\\n            print(f\\\"MockBot initialized with title: {title} and context: {context}\\\")\\n\\n        def create_and_add_section_then_return_id(self, title: str, content: str, section_id: int = None, parent_id: int = None) -> int:\\n            if section_id is None:\\n                section_id = self.next_section_id\\n                self.next_section_id += 1\\n            \\n            section = Section(section_id=section_id, title=title, content=content, parent_id=parent_id)\\n            self.sections.append(section)\\n            print(f\\\"Created section {section_id}: {title} (parent: {parent_id})\\\")\\n            return section_id\\n\\n        def get_all_sections(self) -> List[Section]:\\n            return self.sections\\n\\n        def get_sections(self, ids: List[int]) -> List[Section]:\\n            return [s for s in self.sections if s.section_id in ids]\\n\\n        def edit_section(self, section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool:\\n            for section in self.sections:\\n                if section.section_id == section_id:\\n                    if new_content is not None:\\n                        section.content = new_content\\n                    if new_title is not None:\\n                        section.title = new_title\\n                    if new_parent_id is not None:\\n                        section.parent_id = new_parent_id\\n                    print(f\\\"Edited section {section_id}\\\")\\n                    return True\\n            return False\\n\\n        def add_or_update_results_in_resources(self, results: List[Dict], metadatas_to_add: dict = None, store_linked_document_content: bool = False):\\n            for result in results:\\n                resource_id = self.next_resource_id\\n                self.next_resource_id += 1\\n                \\n                resource = {\\n                    'id': resource_id,\\n                    'document': {\\n                        'name': result.get('name', ''),\\n                        'link': result.get('link', ''),\\n                        'content': result.get('content', {})\\n                    },\\n                    'metadatas': metadatas_to_add or {}\\n                }\\n                \\n                self.resources.append(resource)\\n                print(f\\\"Added resource {resource_id}: {result.get('name', '')}\\\")\\n            return self\\n\\n        def add_or_update_result_in_resources(self, metadatas: dict, name: str = None, content: dict = None, link: str = None, store_linked_document_content: bool = False):\\n            resource_id = self.next_resource_id\\n            self.next_resource_id += 1\\n            \\n            resource = {\\n                'id': resource_id,\\n                'document': {\\n                    'name': name,\\n                    'link': link,\\n                    'content': content or {}\\n                },\\n                'metadatas': metadatas\\n            }\\n            \\n            self.resources.append(resource)\\n            print(f\\\"Added single resource {resource_id}: {name}\\\")\\n            return self\\n\\n        def get_all_resources(self) -> List[Dict[str, Any]]:\\n            return self.resources\\n\\n        def semantic_search_resources(self, query_texts, n_results=10):\\n            print(f\\\"Mock semantic search for: {query_texts}\\\")\\n            return []  # Mock empty results\\n\\n        def remove_resource(self, resource_id):\\n            self.resources = [r for r in self.resources if r['id'] != resource_id]\\n            print(f\\\"Removed resource {resource_id}\\\")\\n            return self\\n\\n    # Test usage example:\\n    def test_mock_bot():\\n        # Initialize mock bot\\n        mock_bot = MockBot(\\n            title=\\\"Test Research\\\",\\n            context=\\\"Testing the research assistant framework\\\"\\n        )\\n        \\n        # Test section creation\\n        section_id = mock_bot.create_and_add_section_then_return_id(\\n            title=\\\"Introduction\\\",\\n            content=\\\"This is a test introduction\\\"\\n        )\\n        \\n        # Test resource addition\\n        mock_bot.add_or_update_results_in_resources([\\n            {\\n                \\\"name\\\": \\\"Test Resource\\\",\\n                \\\"link\\\": \\\"https://test.com\\\",\\n                \\\"content\\\": {\\\"description\\\": \\\"Test content\\\"}\\n            }\\n        ], metadatas_to_add={\\\"source\\\": \\\"test\\\"})\\n        \\n        # Print current state\\n        print(\\\"\\\\nCurrent sections:\\\")\\n        for section in mock_bot.get_all_sections():\\n            print(f\\\"Section {section.section_id}: {section.title}\\\")\\n        \\n        print(\\\"\\\\nCurrent resources:\\\")\\n        for resource in mock_bot.get_all_resources():\\n            print(f\\\"Resource {resource['id']}: {resource['document']['name']}\\\")\\n\\n        return mock_bot\\n\\n    mock_bot = MockBot(\\n        title=\\\"Test Research @ Toulon M2 Master\\\",\\n        context=\\\"Testing the research assistant framework in Toulon M2 Master\\\"\\n    )\\n\\n    # Run with explicit error handling\\n    if True: # try:\\n        result = multi_agent_research_generation_persist_each_agent(mock_bot, max_analysts=2)\\n        \\n        print(\\\"\\\\nFinal Results:\\\")\\n        print(\\\"Sections:\\\", len(mock_bot.get_all_sections()))\\n        print(\\\"Resources:\\\", len(mock_bot.get_all_resources()))\\n        \\n        if result:\\n            print(\\\"\\\\nReport preview:\\\", result[:200] + \\\"...\\\" if result else \\\"No report\\\")\\n            \\n    # except Exception as e:\\n    #     print(f\\\"Error running research generation: {e}\\\")\\n    #     print(\\\"\\\\nFinal bot state:\\\")\\n    #     print(\\\"Sections:\\\", mock_bot.get_all_sections())\\n    #     print(\\\"Resources:\\\", mock_bot.get_all_resources())]]]\\nPREVIOUSLY SUCCESSFUL TASKS: [[[]]]\\nPREVIOUSLY FAILED TASKS: [[[]]]\\nPREVIOUS VALIDATION RESULTS: [[[]]]\\nPREVIOUS ATTEMPTS TO CODE THE TASK: [[[]]]\\nPREVIOUS ERRORS AND FIXES: [[[]]]\\n\\n\\nToo many tokens in human message for LLM (20656). Fallback to manual feedback.[0m\", \"agent_name\": \"CodingAgent\", \"message_type\": null, \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": true, \"step_id\": 0}\n",
            "2025-01-26 14:26:58 - {\"message\": \"[32m***** CodingAgent->code_task_and_run_test  BEFORE *****\\nSYSTEM PROMPT:\\n\\n    CONTEXT:\\n    You are a helpful assistant that writes Python code exclusively to be executed to complete the task specified by me.\\n\\n    At each round of conversation, I will give you:\\n    - Reasoning: explanation of the task chosen...\\n    - Task: defined based on the current stage of progress\\n    - Plan: how to proceed and complete the current task\\n    - Tests: to validate that the task was correctly implemented and generates expected results\\n\\n    CURRENT STATE OF THE ENVIRONMENT:\\n    Document #.... : 1.title: ...; 2. abstract: ...; 3. table of content; 4. resources; 5. section progress; 6. events counted\\n\\n    TASK: You should respond with the best Python code to perform the task, i just want the code. no explanation, no reasoning, just the code.\\n\\n    INSTRUCTIONS:\\n    1) Reason and identify an ambitious and robust way to code the task.\\n    2) Write a function getting 'bot' as the first parameter which is an instance of the class SynthesisManager, containing all document resources.\\n     - it should comply with the test provided with no extra arguments\\n     - get title from bot.document.title, get abstract from bot.document.abstract\\n    3) Task performance is based on the semantic distance between a gold solution and the document you will modify using its sections/resources methods. If you generate great things but don't persist it using these methods below, the task score will be 0, be carreful. The main functions are:\\n        - class Section(section_id: int, title: str, content: str, parent_id: int)\\n        - Manipulate document sections: bot.create_and_add_section_then_return_id(title: str, content: str, section_id: int = None, parent_id: int = None) -> int, bot.get_all_sections() -> List[Section], bot.get_sections(ids: List[int]) -> List[Section], bot.edit_section(section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool, bot.remove_section(section_id: int) -> bool, bot.swap_sections(section_id_1: int, section_id_2: int) -> bool\\n        - Manipulate document resources: bot.add_or_update_results_in_resources(results, metadatas_to_add:dict=None, store_linked_document_content:bool=False), bot.add_or_update_result_in_resources(metadatas:dict, name:str=None, content:dict=None, link:str=None, store_linked_document_content:bool=False), bot.get_all_resources(self) -> List[Dict[str, Any]], bot.semantic_search_resources(query_texts, n_results=10), bot.add_or_update_results_in_resources(results, metadatas:dict=None, store_linked_document_content:bool=False), bot.get_and_store_link_content(link:str=None, parent_id=None, chaining:bool=True), bot.remove_resource(resource_id)\\n    4) Ensure the generated code adheres to reusability principles. The generated code should be modular and easy to maintain rather than specific to the task.\\n    5) Avoid hard-coding parameters. Pass necessary data as arguments to ensure reusability.\\n    6) The function should call existing helper functions as much as possible to focus on improving results, not redoing code.\\n    7) Ensure the code is executable with no placeholders and fully complete for immediate testing and deployment.\\n    8) Name your function meaningfully to reflect the task it is performing.\\n    9) Use the llm(prompt) function to generate answers based on a prompt to an LLM, it will return an object which will contain the text result in its .content porperty (result.content)\\n# Usage of llm:\\n# prompt = \\\"generate an outline for....\\\"\\nresponse = llm(prompt)\\n# print(response)\\n\\n    10) Your only allowed to research on free scientific API (e.g. Arxiv, Semantic Scholar, OpenAlex, Wikipedia...)\\n\\n    You should then respond with:\\n    - Reasoning: how to best implement the task with maximum efficiency\\n    - Code: fully executable Python code adhering to the task constraints\\n    \\n    \\nDOCUMENTATION OF AVAILABLE FUNCTIONS IN THE \\\"bot\\\" OBJECT (SynthesisManager class): {{{\\n# The following functions are available for use when generating code. Please leverage these pre-existing methods to avoid redundancy, maintain modularity, and ensure code reusability.\\n\\nclass SynthesisManager:\\n    def __init__(self, document: DocumentStructure, target_file_path: str = None):\\n        self.document = document\\n        self.min_cosine_similarity = cosine_similarity([self.document.embedding_model.embed_query(\\\".\\\")], [self.document.embedding_model.embed_query(\\\"If you can keep your head when all about you are losing theirs and blaming it on you, If you can trust yourself when all men doubt you, But make allowance for their doubting too ; If you can wait and not be tired by waiting, Or being lied about, dont deal in lies, Or being hated, dont give way to hating, And yet dont look too good, nor talk too wise\\\")])[0][0]\\n        if target_file_path:\\n            self.target_file_path = target_file_path\\n\\n    @staticmethod\\n    @method_call_counter\\n    def validate_section_format(section: Dict[str, Any]) -> bool:\\n        try:\\n            # This will try to instantiate a Section. If there's a problem with the data, an exception will be raised (e.g., a type error).\\n            Section(**section)\\n            return True\\n        except TypeError as e:\\n            print(e)\\n            return False\\n\\n    # add event using the document object add_event method add_event\\n    def add_event(self, event: str, data: Dict[str, Any]):\\n        self.document.add_event(event, data)\\n\\n    def normalized_cosine_similarity(self, a: List[float], b: List[float], min_cs: float = None) -> float:\\n        if min_cs is None:\\n            min_cs = self.min_cosine_similarity\\n        return (cosine_similarity([a], [b])[0][0] - min_cs) / (1 - min_cs)\\n\\n    def add_section(self, section: Section):\\n        if self.validate_section_format(asdict(section)):  # Convert dataclass to dict for validation\\n            self.document.document_content.sections_list.append(section)\\n            self.document.update_sections_embeddings([section.section_id])\\n            self.document.add_event({'action': 'add_section', 'section_id': section.section_id})\\n        else:\\n            print('Invalid section format.')\\n        return self\\n    \\n    def create_and_add_section_then_return_id(self, title: str, content: str, section_id: int = None, parent_id: int = None) -> int:\\n        if not section_id:\\n            # Generate section_id by using max section_id + 1\\n            section_id = (max([s.section_id for s in self.document.document_content.sections_list]) + 1) if len(self.document.document_content.sections_list) > 0 else 1\\n\\n        self.add_section(Section(section_id=section_id, parent_id=parent_id, title=title, content=content))\\n        return section_id\\n\\n    def get_sections(self, ids: List[int]) -> List[Section]:\\n        return [s for s in self.document.document_content.sections_list if s.section_id in ids]\\n    \\n    def get_all_sections(self) -> List[Section]:\\n        return self.document.document_content.sections_list\\n\\n    def remove_section(self, section_id: int) -> bool:\\n        section = next((s for s in self.document.document_content.sections_list if s.section_id == section_id), None)\\n        if section:\\n            self.document.document_content.sections_list = [s for s in self.document.document_content.sections_list if s.section_id != section_id]\\n            self.document.update_plan_embedding()\\n            self.document.add_event({'action': 'remove_section','section_id': section_id})\\n            return True\\n        else:\\n            return False\\n\\n    def edit_section(self, section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool:\\n        #section = next((s for s in self.document.document_content if s['id'] == section_id), None)\\n        section = next((s for s in self.document.document_content.sections_list if s.section_id == section_id), None)\\n        if section:\\n            action_event = {'action': 'edit_section','section_id': section_id}\\n            update_embeddings = False\\n            if new_content:\\n                section.content = new_content\\n                update_embeddings = True\\n                action_event['new_content'] = new_content\\n            if new_title:\\n                section.title = new_title\\n                update_embeddings = True\\n                action_event['new_title'] = new_title\\n            if new_parent_id:\\n                section.parent_id = new_parent_id\\n                action_event['new_parent_id'] = new_parent_id\\n            self.document.add_event('observation', action_event)\\n            if update_embeddings:\\n                self.document.update_sections_embeddings([section_id])\\n            return True\\n        else:\\n            return False\\n    \\n    def swap_sections(self, section_id_1: int, section_id_2: int) -> bool:\\n        section_1 = next((s for s in self.document.document_content.sections_list if s.section_id == section_id_1), None)\\n        section_2 = next((s for s in self.document.document_content.sections_list if s.section_id == section_id_2), None)\\n        if section_1 and section_2:\\n            section_1_index = self.document.document_content.sections_list.index(section_1)\\n            section_2_index = self.document.document_content.sections_list.index(section_2)\\n            self.document.document_content.sections_list[section_1_index], self.document.document_content.sections_list[section_2_index] = self.document.document_content.sections_list[section_2_index], self.document.document_content.sections_list[section_1_index]\\n            self.document.add_event('observation', {'action': 'swap_sections','section_id_1': section_id_1, 'section_id_2': section_id_2})\\n            return True\\n        else:\\n            return False\\n\\n    # search into resources stored in self.document.resources_vectordb and self.document.resources, return a list of resources\\n    def semantic_search_resources(self, query_embeddings = None, query_texts = None, n_results = 10, where = None, where_document = None, include = [\\\"metadatas\\\", \\\"documents\\\", \\\"distances\\\"]):\\n        result = self.document.resources_vectordb.similarity_search_with_score( query_embeddings, k=n_results)\\n\\n    def get_all_resources(self) -> List[Dict[str, Any]]:\\n        return self.document.resources\\n\\n    def add_or_update_results_in_resources(self, results, metadatas_to_add: dict = {}, store_linked_document_content: bool = False):\\n        for result in results:\\n            content = {'description': result['description']} if isinstance(result['description'], str) else result['description']\\n            self.add_or_update_result_in_resources(metadatas=metadatas_to_add, name=result['title'], link=result['link'], content=content, store_linked_document_content=store_linked_document_content)\\n        return self\\n\\n    def add_or_update_result_in_resources(self, metadatas: dict, name: str=None, content: dict = None, link: str = None, store_linked_document_content: bool = False, chaining: bool = True):\\n        # Move metadatas to content if content data were provided into metadatas\\n        if metadatas.get('title') and not name:\\n            name = metadatas.get('title')\\n            metadatas.pop('title')\\n        if metadatas.get('link') and not link:\\n            link = metadatas.get('link')\\n            metadatas.pop('link')\\n        if metadatas.get('description') and not content:\\n            content = {'description': metadatas.get('description')}\\n            metadatas.pop('description')\\n\\n        # assert name or link are provided to identify the resource\\n        if not name and not link:\\n            raise ValueError(\\\"Either name or link must be provided\\\")\\n\\n        # Generate id using max\\n        id = max([r['id'] for r in self.document.resources]) + 1 if len(self.document.resources) > 0 else 1\\n        document = {'name': name, 'link': link, 'content': {'description': content} if isinstance(content, str) else content} # Convert content to dict if it's a string\\n        \\n        # Check for existing document\\n        existing_doc = next((doc for doc in self.document.resources if (doc['document']['name'] == name or (link and doc['document']['link'] == link))), None)\\n        \\n        if existing_doc:\\n            # Update the existing document\\n            updated_fields = []\\n            for key, value in document.items():\\n                if value and existing_doc['document'].get(key) != value:\\n                    existing_doc['document'][key] = value\\n                    updated_fields.append(key)\\n            \\n            # Log the event\\n            if updated_fields:\\n                # Update resources_vectordb\\n                self.document.resources_vectordb.add_texts([str(document)], metadatas=[metadatas], ids=[str(existing_doc['id'])])\\n                self.document.add_event('observation', {'action': 'modify_resource', 'document_name': name, 'updated_fields': updated_fields})\\n        else:\\n            # Add new document\\n            self.document.resources.append({\\n                'id': id,\\n                'metadatas': metadatas,\\n                'document': document,\\n            })\\n            if store_linked_document_content:\\n                childs_ids_list = self.get_and_store_link_content(link=link, parent_id=id, chaining=False)\\n                metadatas['childs_ids_list'] = childs_ids_list\\n            self.document.resources_vectordb.add_texts([str(document)], metadatas=[metadatas], ids=[str(id)])\\n            self.document.add_event('observation', {'action': 'add_resource', 'document_name': name})\\n\\n        return self if chaining else (existing_doc if existing_doc else self.document.resources[-1])\\n\\n    @method_call_counter\\n    def get_and_store_link_content(self, link: str = None, parent_id = None, chaining: bool = True):\\n            # Downloads an online document from the given link and stores it in the resources database.\\n            \\n            # Args:\\n            # link (str): The URL of the online document to download.\\n            # parent_id: The ID of the parent document, if any.\\n            # chaining (bool): Whether to return the current object or the IDs of the stored documents.\\n            \\n            # Returns:\\n            # If chaining is True, returns the current object. Otherwise, returns the IDs of the stored documents.\\n            from langchain.document_loaders import WebBaseLoader\\n            if link is None:\\n                raise ValueError(\\\"Please provide a link to download the document from\\\")\\n            loader = WebBaseLoader(link)\\n            data = loader.load()\\n            if parent_id is not None:\\n                for doc in data:\\n                    doc.metadata.extend([{'parent_id': parent_id}])\\n            from langchain.text_splitter import RecursiveCharacterTextSplitter\\n            splitter = RecursiveCharacterTextSplitter()\\n            all_splits = splitter.split_documents(data)\\n            splits_ids = self.document.resources_vectordb.db.add_documents(all_splits)\\n            if chaining:\\n                return self\\n            else:\\n                return splits_ids\\n\\n    def remove_resource(self, resource_id):\\n        # resource_id can be array or single int\\n        if isinstance(resource_id, list):\\n            self.document.resources = [r for r in self.document.resources if r['id'] not in resource_id]\\n        elif isinstance(resource_id, int):\\n            self.document.resources = [r for r in self.document.resources if r['id'] != resource_id]\\n        self.document.add_event('observation', {'action': 'remove_resources','resource_id': str(resource_id)})\\n        return self\\n    \\n    def remove_resources(self, resource_ids: List[int]):\\n        return self.remove_resource(resource_ids)\\n\\n    def restore_last_state(self):\\n        return self.document.restore_state()\\n\\n    def list_all_previous_document_events(self) -> List[Any]:\\n        return self.document.events\\n\\n    # function use to measure performance of the generated document\\n    def set_targetJSON_comparison(self, file_path: str, target_section_title_embedding_label: str = \\\"section_embedding_2\\\", target_section_content_embedding_label: str = \\\"content_embedding_2\\\", target_plan_embedding_label: str = \\\"plan_embedding_2\\\", normalize_embeddings: bool = True, min_cosine_similarity: float = None):\\n        self.target_file_path = file_path\\n        with open(file_path, 'r') as f:\\n            self.target_data = json.load(f)\\n        output_check = ''\\n        for section in self.target_data['plan']:\\n            output_check += section['section'] + \\\" /\\\"\\n        print(output_check)\\n        # Compute the total length for the target data (similar to the test method)\\n        self.target_total_content_length = sum(len(section['content']) for section in self.target_data['plan'])\\n        self.target_total_sections_count = len(self.target_data[\\\"plan\\\"])\\n\\n        self.target_plan_titles_embedding = np.mean([section[target_section_title_embedding_label] for section in self.target_data[\\\"plan\\\"]], axis=0)\\n        self.target_plan_contents_embedding = np.mean([section[target_section_content_embedding_label] for section in self.target_data[\\\"plan\\\"]], axis=0)\\n        self.target_plan_embedding = self.target_data[target_plan_embedding_label]\\n\\n        if normalize_embeddings:\\n            if min_cosine_similarity is None:\\n                dumb_embedding = self.document.dumb_embedding\\n                self.min_plan_titles_cosine_similarity = cosine_similarity([dumb_embedding], [self.target_plan_titles_embedding])[0][0]\\n                self.min_plan_contents_cosine_similarity = cosine_similarity([dumb_embedding], [self.target_plan_contents_embedding])[0][0]\\n                self.min_plan_cosine_similarity = cosine_similarity([dumb_embedding], [self.target_plan_embedding])[0][0]\\n            else:\\n                self.min_plan_titles_cosine_similarity = self.min_plan_contents_cosine_similarity = self.min_plan_cosine_similarity = min_cosine_similarity\\n        else:\\n            self.min_plan_titles_cosine_similarity = self.min_plan_contents_cosine_similarity = self.min_plan_cosine_similarity = 0 \\n\\n    def get_distance_to_targetJSON(self, target_section_title_embedding_label: str = \\\"section_embedding_2\\\", target_section_content_embedding_label: str = \\\"content_embedding_2\\\", target_plan_embedding_label: str = \\\"plan_embedding_2\\\", get_progress: bool = True):\\n        # if self does not have target_file_path\\n        if not hasattr(self, 'target_file_path'):\\n            raise ValueError(\\\"Please set target_file_path using set_targetJSON_comparison method\\\")\\n        if not hasattr(self, 'target_data'):\\n            section_embedding_key, content_embedding_key, plan_embedding_key = \\\"content_embedding_2\\\", \\\"section_embedding_2\\\", \\\"plan_embedding_2\\\"\\n            self.set_targetJSON_comparison(self.target_file_path, target_section_title_embedding_label = section_embedding_key, target_section_content_embedding_label = content_embedding_key, target_plan_embedding_label = plan_embedding_key)\\n            self.document.update_plan_embedding()\\n        elif not hasattr(self.document.document_content, 'sections_list_title_embedding'):\\n            self.document.update_plan_embedding()\\n        # Similar to what you did in the test\\n        current_sections_count = len(self.document.document_content.sections_list)\\n        # Count non empty section's content (not None and len > 1)\\n        current_plan_non_empty_sections_content_count = sum(1 for section in self.document.document_content.sections_list if section.content and len(section.content) > 1)\\n        current_plan_non_empty_sections_title_count = sum(1 for section in self.document.document_content.sections_list if section.title and len(section.title) > 1)\\n        current_content_length = sum(len(section.content) for section in self.document.document_content.sections_list)\\n\\n        plan_embedding = self.document.document_content.sections_list_embedding\\n        plan_titles_embedding = self.document.document_content.sections_list_title_embedding\\n        plan_contents_embedding = self.document.document_content.sections_list_content_embedding\\n        # compute embedding mean of all \\\"title\\\" in self.target_data[\\\"plan\\\"]\\n\\n        # Compute the similarity and content length percentage\\n        plan_embedding_similarity = self.normalized_cosine_similarity(plan_embedding, self.target_plan_embedding, self.min_plan_cosine_similarity)\\n        plan_titles_embedding_similarity = self.normalized_cosine_similarity(plan_titles_embedding, self.target_plan_titles_embedding, self.min_plan_titles_cosine_similarity)\\n        plan_contents_embedding_similarity = self.normalized_cosine_similarity(plan_contents_embedding, self.target_plan_contents_embedding, self.min_plan_contents_cosine_similarity)\\n\\n        content_length_ratio_to_target = round(current_content_length / self.target_total_content_length, 2)\\n        sections_count_ratio_to_target = round(current_sections_count / self.target_total_sections_count, 2)\\n        sections_content_non_empty_count_ratio_to_target = round(current_plan_non_empty_sections_content_count / self.target_total_sections_count, 2)\\n        sections_title_non_empty_count_ratio_to_target = round(current_plan_non_empty_sections_title_count / self.target_total_sections_count, 2)\\n\\n        distance_to_targetJSON = {\\n            \\\"plan_embedding_similarity\\\": round(plan_embedding_similarity, 6),\\n            \\\"plan_titles_embedding_similarity\\\": round(plan_titles_embedding_similarity, 6),\\n            \\\"plan_contents_embedding_similarity\\\": round(plan_contents_embedding_similarity, 6),\\n\\n            \\\"current_sections_count\\\": current_sections_count,\\n            \\\"sections_count_ratio_to_target\\\": sections_count_ratio_to_target,\\n\\n            \\\"title_non_empty_count_ratio_to_target\\\": sections_title_non_empty_count_ratio_to_target,\\n\\n            \\\"current_content_length\\\": current_content_length,\\n            \\\"content_length_ratio_to_target\\\": content_length_ratio_to_target,\\n\\n            \\\"content_non_empty_count_ratio_to_target\\\": sections_content_non_empty_count_ratio_to_target,\\n        }\\n\\n        if get_progress:\\n            # get ratio between same previous values and current values\\n            def get_ratio(previous_value, current_value):\\n                return round((previous_value - current_value) / (previous_value + 0.0000001)*100, 2) if previous_value else 0\\n            if hasattr(self, 'distance_to_targetJSON'):\\n                distance_to_targetJSON['plan_embedding_similarity_progress'] = get_ratio(plan_embedding_similarity, self.distance_to_targetJSON['plan_embedding_similarity'])\\n                distance_to_targetJSON['plan_titles_embedding_similarity_progress'] = get_ratio(plan_titles_embedding_similarity, self.distance_to_targetJSON['plan_titles_embedding_similarity'])\\n                distance_to_targetJSON['plan_contents_embedding_similarity_progress'] = get_ratio(plan_contents_embedding_similarity, self.distance_to_targetJSON['plan_contents_embedding_similarity'])\\n                distance_to_targetJSON['sections_count_ratio_to_target_progress'] = get_ratio(sections_count_ratio_to_target, self.distance_to_targetJSON['sections_count_ratio_to_target'])\\n                distance_to_targetJSON['title_non_empty_count_ratio_to_target_progress'] = get_ratio(sections_title_non_empty_count_ratio_to_target, self.distance_to_targetJSON['title_non_empty_count_ratio_to_target'])\\n                distance_to_targetJSON['content_length_ratio_to_target_progress'] = get_ratio(content_length_ratio_to_target, self.distance_to_targetJSON['content_length_ratio_to_target'])\\n                distance_to_targetJSON['content_non_empty_count_ratio_to_target_progress'] = get_ratio(sections_content_non_empty_count_ratio_to_target, self.distance_to_targetJSON['content_non_empty_count_ratio_to_target'])\\n\\n        self.distance_to_targetJSON = distance_to_targetJSON\\n\\n        return self.distance_to_targetJSON\\n\\n    # return the list of current sections with title, length of content, validation status, and feedback\\n    def get_plan_status(self, compact_string_format: bool = False, keys = [\\\"section_id\\\", \\\"title\\\", \\\"content_length\\\"]):\\n        #keys = [\\\"section_id\\\", \\\"title\\\", \\\"content_length\\\", \\\"validation_status\\\", \\\"feedback_to_process\\\", \\\"feedback_processed\\\"]\\n        plan_status = []\\n        for section in self.document.document_content.sections_list:\\n            status_data_full = [\\n                section.section_id,\\n                section.title,\\n                len(section.content),\\n                round(section.content_progress_validation_status, 1),\\n                section.local_feedback_to_process,\\n                section.local_feedback_processed,\\n            ]\\n            status_data = [data for key, data in zip(keys, status_data_full)]\\n\\n            if compact_string_format:\\n                plan_status.append(\\\"|\\\".join(map(str, status_data)))\\n            else:\\n                plan_status.append(dict(zip(keys, status_data)))\\n\\n        if compact_string_format and plan_status:\\n            if len(plan_status) == 0:\\n                return []\\n            header = \\\"|\\\".join(keys)\\n            plan_status.insert(0, header)\\n        \\n        return plan_status\\n\\n    def get_resources_status(self, compact_string_format: bool = False):\\n        resources_status = []\\n        content_info = {}\\n        for resource in self.document.resources:\\n            if resource['document']['content']:\\n                for key, value in resource['document']['content'].items():\\n                    content_info[f\\\"len(content['{key}'])\\\"] = len(str(value))\\n            \\n            status_data = [\\n                resource['id'],\\n                resource['metadatas'].get('search', 'unknown'),\\n                resource['document']['name'],\\n                len(resource['document']['link']) if (resource['document']['link'] and isinstance(resource['document']['link'], (list, tuple, np.ndarray))) else 0,\\n                *content_info.values()\\n            ]\\n            if compact_string_format:\\n                resources_status.append(\\\"|\\\".join(map(str, status_data)))\\n            else:\\n                keys = [\\\"id\\\", \\\"metadatas\\\", \\\"document_name\\\", \\\"document_link_length\\\"] + list(content_info.keys())\\n                resources_status.append(dict(zip(keys, status_data)))\\n        \\n        if compact_string_format:\\n            # if content_info is empty, it means that there is no resource in the document\\n            if len(content_info) == 0:\\n                return []\\n            header = \\\"id|metadatas|document_name|document_link_length|\\\" + \\\"|\\\".join(content_info.keys())\\n            resources_status.insert(0, header)\\n        \\n        return resources_status\\n\\n}}}\\n\\n    RESPONSE FORMAT:\\n    Reasoning: Your detailed thought process and why the chosen solution is optimal\\n    Code: Python implementation of the solution\\n    ```python\\n    # Example Python code here\\n    def your_function(bot):\\n        # implementation here...\\n    ```\\n    \\n    few_shots: {'num': 4, 'ranking_method': 'random', 'annotations': 'approve', 'summary': False, 'format': 'JSON'}\\n    \\n\\nUSER MESSAGE:\\nTASK DEFINITION: [[[1. **Reasoning**: \\n   - **Step 1**: The existing function `improve_multi_agent_research_generation` is designed to generate a full research report using a multi-agent workflow. However, it lacks a structured approach to writing sections and does not persist each section effectively.\\n   - **Step 2**: The current implementation merges sections except for the introduction and conclusion, which may lead to a lack of clarity and organization in the final report. Improving the section writing process and ensuring proper persistence can enhance the overall quality of the report.\\n   - **Step 3**: The goal is to enhance the function to ensure that each section is written and stored correctly, allowing for better organization and retrieval of information. This will also help in generating a more comprehensive and coherent report.\\n   - **Step 4**: By focusing on improving the writing and persistence of sections, we can challenge the LLM to create a more sophisticated workflow that includes detailed instructions for each step, ensuring that the report is well-structured and informative.\\n\\n2. **Next Best Task**:\\n   - **Function Name**: improve_multi_agent_research_generation\\n   - **Description**: Enhance the existing `improve_multi_agent_research_generation` function to include structured writing of sections, proper persistence of each section, and improved organization of the final report. This will involve creating distinct sections for each part of the research, ensuring that they are stored and retrieved effectively.\\n\\n3. **Performance Acceptance Criteria**:\\n   - The function should generate a report with clearly defined sections (e.g., introduction, methodology, results, discussion, conclusion).\\n   - Each section should be stored in the bot's resources for easy access and modification.\\n   - The final report should be coherent, well-organized, and formatted correctly in Markdown.\\n   - The function should handle errors gracefully and provide feedback if any step fails.\\n\\n4. **Development Plan**:\\n   - **Plan Depth**: 3\\n   - **Steps**:\\n     1. **Section Writing**:\\n        - 1.1. Create a function to write each section of the report.\\n        - 1.2. Ensure that each section is stored in the bot's resources.\\n        - 1.3. Implement a mechanism to retrieve and edit sections as needed.\\n     2. **Report Finalization**:\\n        - 2.1. Create a function to compile all sections into a final report.\\n        - 2.2. Ensure that the introduction and conclusion are written last, summarizing the content of the report.\\n        - 2.3. Format the final report in Markdown.\\n     3. **Error Handling and Feedback**:\\n        - 3.1. Implement error handling for each step of the process.\\n        - 3.2. Provide feedback to the user on the status of the report generation.\\n        - 3.3. Log any issues encountered during the process for future reference.\\n\\n5. **Tests**:\\n```python\\n# document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n# document #42252c6c-12f3-4edf-9045-8acd69bc3356 usage test:\\nimprove_multi_agent_research_generation(bot, max_analysts=3)\\n```]]]\\nCURRENT STATE OF PROBLEM TO PERFORM/TEST TASK: [[[<<< Document #cf0d353c-b43b-4a79-88f9-42c2c84cf75e properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>\\n<<< Document #42252c6c-12f3-4edf-9045-8acd69bc3356 properties:\\n> Current table of content:\\nEmpty\\n> Current resources: Empty\\n>>>]]]\\nRE-USABLE CODE PRIMITIVES: [[[from IPython.display import Image, display\\nfrom langgraph.graph import START, END, StateGraph\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\\nfrom pydantic import BaseModel, Field\\nfrom langgraph.graph import MessagesState\\nimport operator\\nfrom typing import List, Annotated\\nfrom typing_extensions import TypedDict\\nfrom langchain_community.document_loaders import WikipediaLoader\\nfrom langchain_core.messages import get_buffer_string\\nfrom langgraph.constants import Send\\n\\nfrom langchain_openai import ChatOpenAI\\nllm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\\nclass Analyst(BaseModel):\\n    affiliation: str = Field(\\n        description=\\\"Primary affiliation of the analyst.\\\",\\n    )\\n    name: str = Field(\\n        description=\\\"Name of the analyst.\\\"\\n    )\\n    role: str = Field(\\n        description=\\\"Role of the analyst in the context of the topic.\\\",\\n    )\\n    description: str = Field(\\n        description=\\\"Description of the analyst focus, concerns, and motives.\\\",\\n    )\\n    @property\\n    def persona(self) -> str:\\n        return f\\\"Name: {self.name}\\\\nRole: {self.role}\\\\nAffiliation: {self.affiliation}\\\\nDescription: {self.description}\\\\n\\\"\\n\\nclass Perspectives(BaseModel):\\n    analysts: List[Analyst] = Field(\\n        description=\\\"Comprehensive list of analysts with their roles and affiliations.\\\",\\n    )\\n\\nclass GenerateAnalystsState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n\\ndef create_analysts(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Create analysts \\\"\\\"\\\"\\n    if \\\"analyst_instructions\\\" not in state:\\n        state['analyst_instructions'] = \\\"\\\"\\\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n        1. First, review the research topic:\\n        {topic}\\n\\n        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\\n        {human_analyst_feedback}\\n\\n        3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n        4. Pick the top {max_analysts} themes.\\n\\n        5. Assign one analyst to each theme.\\n\\n        Respond with a JSON object containing a list of analysts, where each analyst has:\\n        - name: string\\n        - role: string\\n        - affiliation: string\\n        - description: string\\\"\\\"\\\"\\n    \\n    analyst_instructions = state[\\\"analyst_instructions\\\"]\\n\\n    topic=state['topic']\\n    max_analysts=state['max_analysts']\\n    human_analyst_feedback=state.get('human_analyst_feedback', '')\\n\\n    # Enforce structured output\\n    structured_llm = llm.with_structured_output(Perspectives)\\n\\n    # System message\\n    system_message = analyst_instructions.format(topic=topic,\\n                                                            human_analyst_feedback=human_analyst_feedback,\\n                                                            max_analysts=max_analysts)\\n\\n    print(system_message)\\n    # Generate question\\n    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\\\"Generate the set of analysts.\\\")])\\n    print(f\\\"Type of analysts: {type(analysts)}\\\")\\n\\n    # Write the list of analysis to state\\n    return {\\\"analysts\\\": analysts.analysts}\\n\\ndef create_analysts(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Create analysts \\\"\\\"\\\"\\n    if \\\"analyst_instructions\\\" not in state:\\n        state['analyst_instructions'] = \\\"\\\"\\\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n        1. First, review the research topic:\\n        {topic}\\n\\n        2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\\n        {human_analyst_feedback}\\n\\n        3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n        4. Pick the top {max_analysts} themes.\\n\\n        5. Assign one analyst to each theme.\\n\\n        Respond with a JSON object containing a list of analysts, where each analyst has:\\n        - name: string\\n        - role: string\\n        - affiliation: string\\n        - description: string\\\"\\\"\\\"\\n    \\n    analyst_instructions = state[\\\"analyst_instructions\\\"]\\n    topic = state['topic']\\n    max_analysts = state['max_analysts']\\n    human_analyst_feedback = state.get('human_analyst_feedback', '')\\n\\n    # Enforce structured output\\n    structured_llm = llm.with_structured_output(Perspectives)\\n\\n    # System message\\n    system_message = analyst_instructions.format(\\n        topic=topic,\\n        human_analyst_feedback=human_analyst_feedback,\\n        max_analysts=max_analysts\\n    )\\n\\n    try:\\n        # Generate analysts\\n        analysts_response = structured_llm.invoke([\\n            SystemMessage(content=system_message),\\n            HumanMessage(content=\\\"Generate the set of analysts.\\\")\\n        ])\\n\\n        # Handle different possible return types\\n        if isinstance(analysts_response, Perspectives):\\n            # If it's already a Perspectives object\\n            generated_analysts = analysts_response.analysts\\n        elif isinstance(analysts_response, dict):\\n            # If it's a dict, try to extract analysts\\n            generated_analysts = analysts_response.get('analysts', [])\\n        elif hasattr(analysts_response, 'analysts'):\\n            # If it has an analysts attribute\\n            generated_analysts = analysts_response.analysts\\n        else:\\n            # Fallback to default analysts\\n            generated_analysts = [\\n                Analyst(\\n                    name=f\\\"Analyst {i+1}\\\", \\n                    role=f\\\"Research Specialist {i+1}\\\", \\n                    affiliation=\\\"Research Institute\\\", \\n                    description=f\\\"Analyzing aspects of {topic}\\\"\\n                ) for i in range(max_analysts)\\n            ]\\n\\n        # Ensure all are Analyst objects\\n        generated_analysts = [\\n            Analyst(**a.dict() if hasattr(a, 'dict') else a) \\n            for a in generated_analysts\\n        ]\\n\\n        return {\\\"analysts\\\": generated_analysts}\\n\\n    except Exception as e:\\n        print(f\\\"Error generating analysts: {e}\\\")\\n        # Fallback to default analysts\\n        default_analysts = [\\n            Analyst(\\n                name=f\\\"Analyst {i+1}\\\", \\n                role=f\\\"Research Specialist {i+1}\\\", \\n                affiliation=\\\"Research Institute\\\", \\n                description=f\\\"Analyzing aspects of {topic}\\\"\\n            ) for i in range(max_analysts)\\n        ]\\n        return {\\\"analysts\\\": default_analysts}\\n\\ndef human_feedback(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" No-op node that should be interrupted on \\\"\\\"\\\"\\n    pass\\n\\ndef should_continue(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Return the next node to execute \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback', None)\\n    if human_analyst_feedback:\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise end\\n    return END\\n\\nclass InterviewState(MessagesState):\\n    max_num_turns: int # Number turns of conversation\\n    context: Annotated[list, operator.add] # Source docs\\n    analyst: Analyst # Analyst asking questions\\n    interview: str # Interview transcript\\n    sections: list # Final key we duplicate in outer state for Send() API\\n\\nclass SearchQuery(BaseModel):\\n    search_query: str = Field(None, description=\\\"Search query for retrieval.\\\")\\n\\ndef generate_question(state: InterviewState):\\n    \\\"\\\"\\\" Node to generate a question \\\"\\\"\\\"\\n\\n    # Check if question_instructions is provided by state\\n    if \\\"question_instructions\\\" not in state:\\n        state[\\\"question_instructions\\\"] = \\\"\\\"\\\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\\n\\n        Your goal is boil down to interesting and specific insights related to your topic.\\n\\n        1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n        2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\n        Here is your topic of focus and set of goals: {goals}\\n\\n        Begin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\n        Continue to ask questions to drill down and refine your understanding of the topic.\\n\\n        When you are satisfied with your understanding, complete the interview with: \\\"Thank you so much for your help!\\\"\\n\\n        Remember to stay in character throughout your response, reflecting the persona and goals provided to you.\\\"\\\"\\\"\\n\\n    question_instructions = state[\\\"question_instructions\\\"]\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n\\n    # Generate question\\n    system_message = question_instructions.format(goals=analyst.persona)\\n    question = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Write messages to state\\n    return {\\\"messages\\\": [question]}\\n\\ndef search_web(state: InterviewState):\\n    \\\"\\\"\\\" Retrieve academic papers from OpenAlex \\\"\\\"\\\"\\n    import requests\\n    OPENALEX_API_URL = \\\"https://api.openalex.org/works\\\"\\n\\n    # Search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    if \\\"search_instructions\\\" not in state:\\n        state[\\\"search_instructions\\\"] = SystemMessage(content=f\\\"\\\"\\\"You will be given a conversation between an analyst and an expert.\\n\\n        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\\n\\n        First, analyze the full conversation.\\n\\n        Pay particular attention to the final question posed by the analyst.\\n\\n        Convert this final question into a well-structured web search query\\\"\\\"\\\")\\n    search_instructions = state[\\\"search_instructions\\\"]\\n\\n    search_query = structured_llm.invoke([search_instructions] + state['messages'])\\n\\n    # Construct the OpenAlex API query parameters\\n    params = {\\n        \\\"search\\\": search_query.search_query,\\n        \\\"filter\\\": \\\"is_paratext:false\\\",  # Exclude non-research content\\n        \\\"sort\\\": \\\"relevance_score:desc\\\",\\n        \\\"per_page\\\": 5  # Limit to top 5 relevant results\\n    }\\n\\n    # Perform the request to OpenAlex\\n    response = requests.get(OPENALEX_API_URL, params=params)\\n    search_docs = []\\n    \\n    if response.status_code == 200:\\n        data = response.json()\\n        for result in data.get(\\\"results\\\", []):\\n            search_docs.append({\\n                \\\"title\\\": result.get(\\\"title\\\", \\\"Unknown Title\\\"),\\n                \\\"authors\\\": \\\", \\\".join([auth[\\\"author\\\"][\\\"display_name\\\"] for auth in result.get(\\\"authorships\\\", [])]),\\n                \\\"abstract\\\": result.get(\\\"abstract\\\", \\\"No abstract available\\\"),\\n                \\\"url\\\": result.get(\\\"id\\\", \\\"Unknown URL\\\")\\n            })\\n    else:\\n        print(f\\\"Error retrieving data from OpenAlex: {response.status_code}\\\")\\n\\n    # Format results\\n    formatted_search_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join(\\n        [\\n            f'<Document title=\\\"{doc[\\\"title\\\"]}\\\" href=\\\"{doc[\\\"url\\\"]}\\\">\\\\nAuthors: {doc[\\\"authors\\\"]}\\\\n\\\\nAbstract: {doc[\\\"abstract\\\"]}\\\\n</Document>'\\n            for doc in search_docs\\n        ]\\n    )\\n\\n    return {\\\"context\\\": [formatted_search_docs]}\\n\\ndef search_wikipedia(state: InterviewState):\\n    \\\"\\\"\\\" Retrieve docs from wikipedia \\\"\\\"\\\"\\n    # Check if search_instructions is provided by state\\n    if \\\"search_instructions\\\" not in state:\\n        state[\\\"search_instructions\\\"] = SystemMessage(content=f\\\"\\\"\\\"You will be given a conversation between an analyst and an expert.\\n        Your goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\\n        First, analyze the full conversation.\\n        Pay particular attention to the final question posed by the analyst.\\n        Convert this final question into a well-structured web search query\\\"\\\"\\\")\\n\\n    search_instructions = state[\\\"search_instructions\\\"]\\n\\n    # Search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    search_query = structured_llm.invoke([search_instructions]+state['messages'])\\n\\n    # Search\\n    search_docs = WikipediaLoader(query=search_query.search_query,\\n                                  load_max_docs=2).load()\\n\\n     # Format\\n    formatted_search_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join(\\n        [\\n            f'<Document source=\\\"{doc.metadata[\\\"source\\\"]}\\\" page=\\\"{doc.metadata.get(\\\"page\\\", \\\"\\\")}\\\"/>\\\\n{doc.page_content}\\\\n</Document>'\\n            for doc in search_docs\\n        ]\\n    )\\n\\n    return {\\\"context\\\": [formatted_search_docs]}\\n\\ndef generate_answer(state: InterviewState):\\n    \\\"\\\"\\\" Node to answer a question \\\"\\\"\\\"\\n    # Check if answer_instructions is provided by state\\n    if \\\"answer_instructions\\\" not in state:\\n        state[\\\"answer_instructions\\\"] = \\\"\\\"\\\"You are an expert being interviewed by an analyst.\\n\\n        Here is analyst area of focus: {goals}.\\n\\n        You goal is to answer a question posed by the interviewer.\\n\\n        To answer question, use this context:\\n\\n        {context}\\n\\n        When answering questions, follow these guidelines:\\n\\n        1. Use only the information provided in the context.\\n\\n        2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\\n\\n        3. The context contain sources at the topic of each individual document.\\n\\n        4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\\n\\n        5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\\n\\n        6. If the source is: <Document source=\\\"assistant/docs/llama3_1.pdf\\\" page=\\\"7\\\"/>' then just list:\\n\\n        [1] assistant/docs/llama3_1.pdf, page 7\\n\\n        And skip the addition of the brackets as well as the Document source preamble in your citation.\\\"\\\"\\\"\\n\\n    answer_instructions = state[\\\"answer_instructions\\\"]\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n    context = state[\\\"context\\\"]\\n\\n    # Answer question\\n    system_message = answer_instructions.format(goals=analyst.persona, context=context)\\n    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Name the message as coming from the expert\\n    answer.name = \\\"expert\\\"\\n\\n    # Append it to state\\n    return {\\\"messages\\\": [answer]}\\n\\ndef save_interview(state: InterviewState):\\n\\n    \\\"\\\"\\\" Save interviews \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n\\n    # Convert interview to a string\\n    interview = get_buffer_string(messages)\\n\\n    # Save to interviews key\\n    return {\\\"interview\\\": interview}\\n\\ndef route_messages(state: InterviewState,\\n                   name: str = \\\"expert\\\"):\\n\\n    \\\"\\\"\\\" Route between question and answer \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n    max_num_turns = state.get('max_num_turns',2)\\n\\n    # Check the number of expert answers\\n    num_responses = len(\\n        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\\n    )\\n\\n    # End if expert has answered more than the max turns\\n    if num_responses >= max_num_turns:\\n        return 'save_interview'\\n\\n    # This router is run after each question - answer pair\\n    # Get the last question asked to check if it signals the end of discussion\\n    last_question = messages[-2]\\n\\n    if \\\"Thank you so much for your help\\\" in last_question.content:\\n        return 'save_interview'\\n    return \\\"ask_question\\\"\\n\\ndef write_section(state: InterviewState):\\n    \\\"\\\"\\\" Node to answer a question \\\"\\\"\\\"\\n    # Check if section_writer_instructions is provided by state\\n    if \\\"section_writer_instructions\\\" not in state:\\n        state[\\\"section_writer_instructions\\\"] = \\\"\\\"\\\"You are an expert technical writer.\\n\\n        Your task is to create a short, easily digestible section of a report based on a set of source documents.\\n\\n        1. Analyze the content of the source documents:\\n        - The name of each source document is at the start of the document, with the <Document tag.\\n\\n        2. Create a report structure using markdown formatting:\\n        - Use ## for the section title\\n        - Use ### for sub-section headers\\n\\n        3. Write the report following this structure:\\n        a. Title (## header)\\n        b. Summary (### header)\\n        c. Sources (### header)\\n\\n        4. Make your title engaging based upon the focus area of the analyst:\\n        {focus}\\n\\n        5. For the summary section:\\n        - Set up summary with general background / context related to the focus area of the analyst\\n        - Emphasize what is novel, interesting, or surprising about insights gathered from the interview\\n        - Create a numbered list of source documents, as you use them\\n        - Do not mention the names of interviewers or experts\\n        - Aim for approximately 400 words maximum\\n        - Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\\n\\n        6. In the Sources section:\\n        - Include all sources used in your report\\n        - Provide full links to relevant websites or specific document paths\\n        - Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\\n        - It will look like:\\n\\n        ### Sources\\n        [1] Link or Document name\\n        [2] Link or Document name\\n\\n        7. Be sure to combine sources. For example this is not correct:\\n\\n        [3] https://ai.meta.com/blog/meta-llama-3-1/\\n        [4] https://ai.meta.com/blog/meta-llama-3-1/\\n\\n        There should be no redundant sources. It should simply be:\\n\\n        [3] https://ai.meta.com/blog/meta-llama-3-1/\\n\\n        8. Final review:\\n        - Ensure the report follows the required structure\\n        - Include no preamble before the title of the report\\n        - Check that all guidelines have been followed\\\"\\\"\\\"\\n\\n    section_writer_instructions = state[\\\"section_writer_instructions\\\"]\\n\\n    # Get state\\n    interview = state[\\\"interview\\\"]\\n    context = state[\\\"context\\\"]\\n    analyst = state[\\\"analyst\\\"]\\n\\n    # Write section using either the gathered source docs from interview (context) or the interview itself (interview)\\n    system_message = section_writer_instructions.format(focus=analyst.description)\\n    section = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\\\"Use this source to write your section: {context}\\\")])\\n\\n    # Append it to state\\n    return {\\\"sections\\\": [section.content]}\\n\\nclass ResearchGraphState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n    sections: Annotated[list, operator.add] # Send() API key\\n    introduction: str # Introduction for the final report\\n    content: str # Content for the final report\\n    conclusion: str # Conclusion for the final report\\n    final_report: str # Final report\\n\\ndef initiate_all_interviews(state: ResearchGraphState):\\n    \\\"\\\"\\\" This is the \\\"map\\\" step where we run each interview sub-graph using Send API \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback')\\n    if human_analyst_feedback:\\n        # Return to create_analysts\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise kick off interviews in parallel via Send() API\\n    else:\\n        topic = state[\\\"topic\\\"]\\n        return [Send(\\\"conduct_interview\\\", {\\\"analyst\\\": analyst,\\n                                           \\\"messages\\\": [HumanMessage(\\n                                               content=f\\\"So you said you were writing an article on {topic}?\\\"\\n                                           )\\n                                                       ]}) for analyst in state[\\\"analysts\\\"]]\\n\\ndef write_report(state: ResearchGraphState):\\n    # Check if report_writer_instructions is provided by state\\n    if \\\"report_writer_instructions\\\" not in state:\\n        state['report_writer_instructions'] = \\\"\\\"\\\"You are a technical writer creating a report on this overall topic:\\n\\n{topic}\\n\\nYou have a team of analysts. Each analyst has done two things:\\n\\n1. They conducted an interview with an expert on a specific sub-topic.\\n2. They write up their finding into a memo.\\n\\nYour task:\\n\\n1. You will be given a collection of memos from your analysts.\\n2. Think carefully about the insights from each memo.\\n3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\\n4. Summarize the central points in each memo into a cohesive single narrative.\\n\\nTo format your report:\\n\\n1. Use markdown formatting.\\n2. Include no pre-amble for the report.\\n3. Use no sub-heading.\\n4. Start your report with a single title header: ## Insights\\n5. Do not mention any analyst names in your report.\\n6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\\n7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\\n8. List your sources in order and do not repeat.\\n\\n[1] Source 1\\n[2] Source 2\\n\\nHere are the memos from your analysts to build your report from:\\n\\n{context}\\\"\\\"\\\"\\n\\n    report_writer_instructions = state[\\\"report_writer_instructions\\\"]\\n\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\\n    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\\\"Write a report based upon these memos.\\\")])\\n    return {\\\"content\\\": report.content}\\n\\ndef write_introduction(state: ResearchGraphState):\\n    # Check if intro_conclusion_instructions is provided by state\\n    if \\\"intro_conclusion_instructions\\\" not in state:\\n        state['intro_conclusion_instructions'] = \\\"\\\"\\\"You are a technical writer finishing a report on {topic}\\n\\nYou will be given all of the sections of the report.\\n\\nYou job is to write a crisp and compelling introduction or conclusion section.\\n\\nThe user will instruct you whether to write the introduction or conclusion.\\n\\nInclude no pre-amble for either section.\\n\\nTarget around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\\n\\nUse markdown formatting.\\n\\nFor your introduction, create a compelling title and use the # header for the title.\\n\\nFor your introduction, use ## Introduction as the section header.\\n\\nFor your conclusion, use ## Conclusion as the section header.\\n\\nHere are the sections to reflect on for writing: {formatted_str_sections}\\\"\\\"\\\"\\n\\n    intro_conclusion_instructions = state[\\\"intro_conclusion_instructions\\\"]\\n\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    intro = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report introduction\\\")])\\n    return {\\\"introduction\\\": intro.content}\\n\\ndef write_conclusion(state: ResearchGraphState):\\n    # Check if intro_conclusion_instructions is provided by state\\n    if \\\"intro_conclusion_instructions\\\" not in state:\\n        state['intro_conclusion_instructions'] = \\\"\\\"\\\"You are a technical writer finishing a report on {topic}\\n\\nYou will be given all of the sections of the report.\\n\\nYou job is to write a crisp and compelling introduction or conclusion section.\\n\\nThe user will instruct you whether to write the introduction or conclusion.\\n\\nInclude no pre-amble for either section.\\n\\nTarget around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\\n\\nUse markdown formatting.\\n\\nFor your introduction, create a compelling title and use the # header for the title.\\n\\nFor your introduction, use ## Introduction as the section header.\\n\\nFor your conclusion, use ## Conclusion as the section header.\\n\\nHere are the sections to reflect on for writing: {formatted_str_sections}\\\"\\\"\\\"\\n\\n    intro_conclusion_instructions = state[\\\"intro_conclusion_instructions\\\"]        \\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report conclusion\\\")])\\n    return {\\\"conclusion\\\": conclusion.content}\\n\\ndef finalize_report(state: ResearchGraphState):\\n    \\\"\\\"\\\" This is the \\\"reduce\\\" step where we gather all the sections, combine them, and reflect on them to write the intro/conclusion \\\"\\\"\\\"\\n    if not state:\\n        return {\\\"final_report\\\": \\\"\\\"}\\n        \\n    # Save full final report\\n    content = state.get(\\\"content\\\", \\\"\\\")\\n    introduction = state.get(\\\"introduction\\\", \\\"\\\")\\n    conclusion = state.get(\\\"conclusion\\\", \\\"\\\")\\n    \\n    if content.startswith(\\\"## Insights\\\"):\\n        content = content.strip(\\\"## Insights\\\")\\n    \\n    sources = None\\n    if \\\"## Sources\\\" in content:\\n        try:\\n            content, sources = content.split(\\\"\\\\n## Sources\\\\n\\\")\\n        except:\\n            sources = None\\n\\n    final_report = \\\"\\\"\\n    if introduction:\\n        final_report += introduction + \\\"\\\\n\\\\n---\\\\n\\\\n\\\"\\n    if content:\\n        final_report += content\\n    if conclusion:\\n        final_report += \\\"\\\\n\\\\n---\\\\n\\\\n\\\" + conclusion\\n    if sources:\\n        final_report += \\\"\\\\n\\\\n## Sources\\\\n\\\" + sources\\n\\n    return {\\\"final_report\\\": final_report}\\n\\ndef persist_final_report_in_bot(bot, final_report):\\n    \\\"\\\"\\\"\\n    Converts the final Markdown report into document sections,\\n    and extracts sources to store in bot.add_or_update_results_in_resources.\\n    \\\"\\\"\\\"\\n    # Handle None or empty input\\n    if final_report is None:\\n        final_report = {\\\"final_report\\\": \\\"\\\"}  # Create empty report instead of raising error\\n        \\n    # Handle dictionary input\\n    if isinstance(final_report, dict):\\n        final_report = final_report.get(\\\"final_report\\\", \\\"\\\")\\n    \\n    # Ensure we have a string\\n    final_report = str(final_report)\\n    \\n    # If empty report, create minimal section\\n    if not final_report.strip():\\n        bot.create_and_add_section_then_return_id(\\n            title=\\\"Empty Report\\\",\\n            content=\\\"No content was generated.\\\"\\n        )\\n        return\\n\\n    import re\\n    \\n    # The rest of the function remains the same...\\n    section_pattern = re.compile(r\\\"(##\\\\s+.+?)(?=##\\\\s|$)\\\", re.DOTALL)\\n    \\n    grand_titre_match = re.search(r\\\"^#\\\\s+(.*)\\\", final_report)\\n    if grand_titre_match:\\n        grand_titre = grand_titre_match.group(1).strip()\\n        bot.create_and_add_section_then_return_id(\\n            title=grand_titre,\\n            content=f\\\"(Main Title)\\\\n\\\\n{grand_titre}\\\"\\n        )\\n    \\n    sections = section_pattern.findall(final_report)\\n\\n    for section_md in sections:\\n        lines = section_md.split('\\\\n', 1)\\n        if len(lines) == 2:\\n            section_title_line, section_body = lines\\n        else:\\n            section_title_line = lines[0]\\n            section_body = \\\"\\\"\\n\\n        section_title = section_title_line.replace(\\\"##\\\", \\\"\\\").strip()\\n        bot.create_and_add_section_then_return_id(title=section_title, content=section_body)\\n\\n    sources_block_match = re.search(r\\\"(##\\\\s+Sources.*)\\\", final_report, re.IGNORECASE | re.DOTALL)\\n    if sources_block_match:\\n        sources_block = sources_block_match.group(1)\\n        \\n        lines = sources_block.split('\\\\n')\\n        resources_to_add = []\\n        for line in lines:\\n            m = re.match(r\\\"\\\\[(\\\\d+)\\\\]\\\\s+(.*)\\\", line.strip())\\n            if m:\\n                index = m.group(1)\\n                url_or_name = m.group(2)\\n                resource_item = {\\n                    \\\"name\\\": f\\\"Source_{index}\\\",\\n                    \\\"content\\\": {\\\"url\\\": url_or_name},\\n                    \\\"metadatas\\\": {\\\"index\\\": index}\\n                }\\n                resources_to_add.append(resource_item)\\n        \\n        if resources_to_add:\\n            bot.add_or_update_results_in_resources(\\n                results=resources_to_add, \\n                metadatas_to_add={\\\"type\\\": \\\"reference\\\"},\\n                store_linked_document_content=False\\n            )\\n\\ndef improve_multi_agent_research_generation(bot, max_analysts: int = 3):\\n    \\\"\\\"\\\"\\n    Generate a full research report using a multi-agent LangGraph workflow:  \\n    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\n    Write report, Write introduction, Write conclusion, Finalize report.\\n    Persist the document in the bot object through agent action.\\n    \\n    Args:\\n        bot: The bot object with the necessary methods.\\n        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\n    Returns:\\n        str: The final markdown research report.\\n    \\\"\\\"\\\"\\n    title, topic = bot.document.title, bot.document.context\\n    # Create initial state with topic and max_analysts\\n    initial_state: GenerateAnalystsState = { \\\"topic\\\": topic, \\\"max_analysts\\\": max_analysts, \\\"human_analyst_feedback\\\": None, \\\"analysts\\\": []}\\n\\n    # Recreate the interview graph within the function\\n    interview_builder = StateGraph(InterviewState)\\n    interview_builder.add_node(\\\"ask_question\\\", generate_question)\\n    interview_builder.add_node(\\\"search_web\\\", search_web)\\n    interview_builder.add_node(\\\"search_wikipedia\\\", search_wikipedia)\\n    interview_builder.add_node(\\\"answer_question\\\", generate_answer)\\n    interview_builder.add_node(\\\"save_interview\\\", save_interview)\\n    interview_builder.add_node(\\\"write_section\\\", write_section)\\n\\n    # Flow\\n    interview_builder.add_edge(START, \\\"ask_question\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_web\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_wikipedia\\\")\\n    interview_builder.add_edge(\\\"search_web\\\", \\\"answer_question\\\")\\n    interview_builder.add_edge(\\\"search_wikipedia\\\", \\\"answer_question\\\")\\n    interview_builder.add_conditional_edges(\\\"answer_question\\\", route_messages,['ask_question','save_interview'])\\n    interview_builder.add_edge(\\\"save_interview\\\", \\\"write_section\\\")\\n    interview_builder.add_edge(\\\"write_section\\\", END)\\n\\n    # Compile interview graph\\n    memory = MemorySaver()\\n    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\\\"Conduct Interviews\\\")\\n\\n    # Set up the thread configuration\\n    thread = {\\\"configurable\\\": {\\\"thread_id\\\": \\\"1\\\"}}\\n\\n    # Compile the research graph\\n    builder = StateGraph(ResearchGraphState)\\n    builder.add_node(\\\"create_analysts\\\", create_analysts)\\n    builder.add_node(\\\"human_feedback\\\", human_feedback)\\n    \\n    # Use the interview_graph directly, without .compile()\\n    builder.add_node(\\\"conduct_interview\\\", interview_graph)\\n    builder.add_node(\\\"write_report\\\", write_report)\\n    builder.add_node(\\\"write_introduction\\\", write_introduction)\\n    builder.add_node(\\\"write_conclusion\\\", write_conclusion)\\n    builder.add_node(\\\"finalize_report\\\", finalize_report)\\n\\n    # Logic\\n    builder.add_edge(START, \\\"create_analysts\\\")\\n    builder.add_edge(\\\"create_analysts\\\", \\\"human_feedback\\\")\\n    builder.add_conditional_edges(\\\"human_feedback\\\", initiate_all_interviews, [\\\"create_analysts\\\", \\\"conduct_interview\\\"])\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_introduction\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_report\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_conclusion\\\")\\n    builder.add_edge([\\\"write_conclusion\\\", \\\"write_report\\\", \\\"write_introduction\\\"], \\\"finalize_report\\\")\\n    builder.add_edge(\\\"finalize_report\\\", END)\\n\\n    # Compile the graph\\n    memory2 = MemorySaver()\\n    graph = builder.compile(checkpointer=memory2)\\n    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\\n\\n    # Invoke the graph\\n    graph.invoke(initial_state, thread)\\n\\n    # Retrieve the final report\\n    final_state = graph.get_state(thread)\\n    report = final_state.values.get('final_report')\\n\\n    persist_final_report_in_bot(bot, report)\\n    return report\\n\\nfrom IPython.display import Image, display\\nfrom langgraph.graph import START, END, StateGraph\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\\nfrom pydantic import BaseModel, Field\\nfrom langgraph.graph import MessagesState\\nimport operator\\nfrom typing import List, Annotated\\nfrom typing_extensions import TypedDict\\nfrom langchain_community.document_loaders import WikipediaLoader\\nfrom langchain_core.messages import get_buffer_string\\nfrom langgraph.constants import Send\\nfrom typing import List\\nfrom typing_extensions import TypedDict\\nfrom pydantic import BaseModel, Field\\nfrom IPython.display import Image, display\\nfrom langgraph.graph import START, END, StateGraph\\nfrom langgraph.checkpoint.memory import MemorySaver\\nfrom langchain_core.messages import AIMessage, HumanMessage, SystemMessage\\nimport operator\\nfrom typing import  Annotated\\nfrom langgraph.graph import MessagesState\\nimport datetime\\nimport os\\nfrom langchain_openai import ChatOpenAI\\n# Wikipedia search tool\\nfrom langchain_community.document_loaders import WikipediaLoader\\nfrom langchain_core.messages import get_buffer_string\\n\\n# os.environ['OPENAI_BASE_URL'] = 'https://api.openai.com/v1'\\n# os.environ['OPENROUTER_API_KEY'] = '\\n# os.environ['OPENAI_API_KEY'] = os.environ['OPENROUTER_API_KEY']\\n\\nllm = ChatOpenAI(model=\\\"gpt-4o-mini\\\", temperature=0)\\n\\nclass Analyst(BaseModel):\\n    affiliation: str = Field(\\n        description=\\\"Primary affiliation of the analyst.\\\",\\n    )\\n    name: str = Field(\\n        description=\\\"Name of the analyst.\\\"\\n    )\\n    role: str = Field(\\n        description=\\\"Role of the analyst in the context of the topic.\\\",\\n    )\\n    description: str = Field(\\n        description=\\\"Description of the analyst focus, concerns, and motives.\\\",\\n    )\\n    @property\\n    def persona(self) -> str:\\n        return f\\\"Name: {self.name}\\\\nRole: {self.role}\\\\nAffiliation: {self.affiliation}\\\\nDescription: {self.description}\\\\n\\\"\\n\\nclass Perspectives(BaseModel):\\n    analysts: List[Analyst] = Field(\\n        description=\\\"Comprehensive list of analysts with their roles and affiliations.\\\",\\n    )\\n\\nclass GenerateAnalystsState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n\\nanalyst_instructions=\\\"\\\"\\\"You are tasked with creating a set of AI analyst personas. Follow these instructions carefully:\\n\\n1. First, review the research topic:\\n{topic}\\n\\n2. Examine any editorial feedback that has been optionally provided to guide creation of the analysts:\\n\\n{human_analyst_feedback}\\n\\n3. Determine the most interesting themes based upon documents and / or feedback above.\\n\\n4. Pick the top {max_analysts} themes.\\n\\n5. Assign one analyst to each theme.\\\"\\\"\\\"\\n\\ndef create_analysts_bot(state: GenerateAnalystsState):\\n\\n    \\\"\\\"\\\" Create analysts \\\"\\\"\\\"\\n\\n    topic=state['topic']\\n    max_analysts=state['max_analysts']\\n    human_analyst_feedback=state.get('human_analyst_feedback', '')\\n    print(f\\\"Topic: {topic}\\\")\\n    print(f\\\"Max analysts: {max_analysts}\\\")\\n    print(f\\\"Human analyst feedback: {human_analyst_feedback}\\\")\\n\\n    # Enforce structured output\\n    structured_llm = llm.with_structured_output(Perspectives)\\n\\n    # System message\\n    system_message = analyst_instructions.format(topic=topic,\\n                                                            human_analyst_feedback=human_analyst_feedback,\\n                                                            max_analysts=max_analysts)\\n\\n    # Generate question\\n    analysts = structured_llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=\\\"Generate the set of analysts.\\\")])\\n    print(f\\\"Generated analysts: {analysts}\\\")\\n    # print type of analysts\\n    print(f\\\"Type of analysts: {type(analysts)}\\\")\\n    # Write the list of analysis to state\\n    #return { \\\"analysts\\\": analysts.analysts, \\\"sections\\\": state.get(\\\"sections\\\", []), \\\"context\\\": state.get(\\\"context\\\", []) }\\n    #return {\\\"analysts\\\": analysts.analysts, \\\"sections\\\": state.get(\\\"sections\\\", []), \\\"messages\\\": state.get(\\\"messages\\\", []), \\\"context\\\": state.get(\\\"context\\\", []), \\\"human_analyst_feedback\\\": state.get(\\\"human_analyst_feedback\\\", None)}\\n    return {\\\"analysts\\\": analysts.analysts}\\n\\ndef human_feedback_bot(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" No-op node that should be interrupted on \\\"\\\"\\\"\\n    pass\\n\\ndef should_continue(state: GenerateAnalystsState):\\n    \\\"\\\"\\\" Return the next node to execute \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback', None)\\n    if human_analyst_feedback:\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise end\\n    return END\\n\\n#further_feedack = None\\n#graph.update_state(thread, {\\\"human_analyst_feedback\\\":further_feedack}, as_node=\\\"human_feedback\\\")\\nclass InterviewState(MessagesState):\\n    max_num_turns: int = 2  # Add default value\\n    context: Annotated[list, operator.add] = []  # Add default value\\n    analyst: Analyst\\n    interview: str = \\\"\\\"  # Add default value\\n    sections: Annotated[list, operator.add] = []  # Add default value\\n    messages: list = []  # Add default value\\n\\nclass SearchQuery(BaseModel):\\n    search_query: str = Field(None, description=\\\"Search query for retrieval.\\\")\\n\\nquestion_instructions = \\\"\\\"\\\"You are an analyst tasked with interviewing an expert to learn about a specific topic.\\n\\nYour goal is boil down to interesting and specific insights related to your topic.\\n\\n1. Interesting: Insights that people will find surprising or non-obvious.\\n\\n2. Specific: Insights that avoid generalities and include specific examples from the expert.\\n\\nHere is your topic of focus and set of goals: {goals}\\n\\nBegin by introducing yourself using a name that fits your persona, and then ask your question.\\n\\nContinue to ask questions to drill down and refine your understanding of the topic.\\n\\nWhen you are satisfied with your understanding, complete the interview with: \\\"Thank you so much for your help!\\\"\\n\\nRemember to stay in character throughout your response, reflecting the persona and goals provided to you.\\\"\\\"\\\"\\n\\ndef generate_question_bot(state: InterviewState):\\n    \\\"\\\"\\\" Node to generate a question \\\"\\\"\\\"\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n\\n    # Generate question\\n    system_message = question_instructions.format(goals=analyst.persona)\\n    question = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Write messages to state\\n    #return { \\\"messages\\\": [question], \\\"context\\\": state.get(\\\"context\\\", []), \\\"sections\\\": state.get(\\\"sections\\\", [])}\\n    return {\\\"messages\\\": [question]}\\n\\n# Search query writing\\nsearch_instructions = SystemMessage(content=f\\\"\\\"\\\"You will be given a conversation between an analyst and an expert.\\n\\nYour goal is to generate a well-structured query for use in retrieval and / or web-search related to the conversation.\\n\\nFirst, analyze the full conversation.\\n\\nPay particular attention to the final question posed by the analyst.\\n\\nConvert this final question into a well-structured web search query\\\"\\\"\\\")\\n\\ndef search_web_bot(state: InterviewState):\\n    \\\"\\\"\\\"Enhanced web search with proper resource persistence\\\"\\\"\\\"\\n    import requests\\n    OPENALEX_API_URL = \\\"https://api.openalex.org/works\\\"\\n    \\n    # Get search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    search_query = structured_llm.invoke([search_instructions] + state['messages'])\\n    \\n    # Search OpenAlex\\n    params = {\\n        \\\"search\\\": search_query.search_query,\\n        \\\"filter\\\": \\\"is_paratext:false\\\",\\n        \\\"sort\\\": \\\"relevance_score:desc\\\",\\n        \\\"per_page\\\": 5\\n    }\\n    \\n    response = requests.get(OPENALEX_API_URL, params=params)\\n    search_docs = []\\n    \\n    if response.status_code == 200:\\n        data = response.json()\\n        \\n        # Prepare resources for bot persistence\\n        resources_to_add = []\\n        for result in data.get(\\\"results\\\", []):\\n            doc_info = {\\n                \\\"title\\\": result.get(\\\"title\\\", \\\"Unknown Title\\\"),\\n                \\\"link\\\": result.get(\\\"id\\\", \\\"Unknown URL\\\"),\\n                \\\"description\\\": {\\n                    \\\"abstract\\\": result.get(\\\"abstract\\\", \\\"No abstract available\\\"),\\n                    \\\"authors\\\": \\\", \\\".join([auth[\\\"author\\\"][\\\"display_name\\\"] for auth in result.get(\\\"authorships\\\", [])])\\n                }\\n            }\\n            search_docs.append(doc_info)\\n            resources_to_add.append({\\n                \\\"name\\\": doc_info[\\\"title\\\"],\\n                \\\"link\\\": doc_info[\\\"link\\\"],\\n                \\\"content\\\": doc_info[\\\"description\\\"]\\n            })\\n\\n        # Persist to bot resources with metadata\\n        bot = get_bot()\\n        if bot:\\n            bot.add_or_update_results_in_resources(\\n                results=resources_to_add,\\n                metadatas_to_add={\\n                    \\\"source\\\": \\\"OpenAlex\\\",\\n                    \\\"query\\\": search_query.search_query,\\n                    \\\"search_timestamp\\\": str(datetime.now())\\n                }\\n            )\\n\\n    # Format for LLM consumption\\n    formatted_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join([\\n        f'<Document title=\\\"{doc[\\\"title\\\"]}\\\" href=\\\"{doc[\\\"link\\\"]}\\\">\\\\nAuthors: {doc[\\\"description\\\"][\\\"authors\\\"]}\\\\nAbstract: {doc[\\\"description\\\"][\\\"abstract\\\"]}\\\\n</Document>'\\n        for doc in search_docs\\n    ])\\n    \\n    return {\\\"context\\\": [formatted_docs]}\\n\\n\\ndef search_wikipedia_bot(state: InterviewState):\\n\\n    \\\"\\\"\\\" Retrieve docs from wikipedia \\\"\\\"\\\"\\n\\n    # Search query\\n    structured_llm = llm.with_structured_output(SearchQuery)\\n    search_query = structured_llm.invoke([search_instructions]+state['messages'])\\n\\n    # Search\\n    search_docs = WikipediaLoader(query=search_query.search_query,\\n                                  load_max_docs=2).load()\\n\\n     # Format\\n    formatted_search_docs = \\\"\\\\n\\\\n---\\\\n\\\\n\\\".join(\\n        [\\n            f'<Document source=\\\"{doc.metadata[\\\"source\\\"]}\\\" page=\\\"{doc.metadata.get(\\\"page\\\", \\\"\\\")}\\\"/>\\\\n{doc.page_content}\\\\n</Document>'\\n            for doc in search_docs\\n        ]\\n    )\\n\\n    return {\\\"context\\\": [formatted_search_docs]}\\n\\nanswer_instructions = \\\"\\\"\\\"You are an expert being interviewed by an analyst.\\n\\nHere is analyst area of focus: {goals}.\\n\\nYou goal is to answer a question posed by the interviewer.\\n\\nTo answer question, use this context:\\n\\n{context}\\n\\nWhen answering questions, follow these guidelines:\\n\\n1. Use only the information provided in the context.\\n\\n2. Do not introduce external information or make assumptions beyond what is explicitly stated in the context.\\n\\n3. The context contain sources at the topic of each individual document.\\n\\n4. Include these sources your answer next to any relevant statements. For example, for source # 1 use [1].\\n\\n5. List your sources in order at the bottom of your answer. [1] Source 1, [2] Source 2, etc\\n\\n6. If the source is: <Document source=\\\"assistant/docs/llama3_1.pdf\\\" page=\\\"7\\\"/>' then just list:\\n\\n[1] assistant/docs/llama3_1.pdf, page 7\\n\\nAnd skip the addition of the brackets as well as the Document source preamble in your citation.\\\"\\\"\\\"\\n\\ndef generate_answer_bot(state: InterviewState):\\n\\n    \\\"\\\"\\\" Node to answer a question \\\"\\\"\\\"\\n\\n    # Get state\\n    analyst = state[\\\"analyst\\\"]\\n    messages = state[\\\"messages\\\"]\\n    context = state[\\\"context\\\"]\\n\\n    # Answer question\\n    system_message = answer_instructions.format(goals=analyst.persona, context=context)\\n    answer = llm.invoke([SystemMessage(content=system_message)]+messages)\\n\\n    # Name the message as coming from the expert\\n    answer.name = \\\"expert\\\"\\n\\n    # Append it to state\\n    return {\\\"messages\\\": [answer]}\\n\\ndef save_interview_bot(state: InterviewState):\\n\\n    \\\"\\\"\\\" Save interviews \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n\\n    # Convert interview to a string\\n    interview = get_buffer_string(messages)\\n\\n    # Save to interviews key\\n    return {\\\"interview\\\": interview}\\n\\ndef route_messages(state: InterviewState,\\n                   name: str = \\\"expert\\\"):\\n\\n    \\\"\\\"\\\" Route between question and answer \\\"\\\"\\\"\\n\\n    # Get messages\\n    messages = state[\\\"messages\\\"]\\n    max_num_turns = state.get('max_num_turns',2)\\n\\n    # Check the number of expert answers\\n    num_responses = len(\\n        [m for m in messages if isinstance(m, AIMessage) and m.name == name]\\n    )\\n\\n    # End if expert has answered more than the max turns\\n    if num_responses >= max_num_turns:\\n        return 'save_interview'\\n\\n    # This router is run after each question - answer pair\\n    # Get the last question asked to check if it signals the end of discussion\\n    last_question = messages[-2]\\n\\n    if \\\"Thank you so much for your help\\\" in last_question.content:\\n        return 'save_interview'\\n    return \\\"ask_question\\\"\\n\\nsection_writer_instructions = \\\"\\\"\\\"You are an expert technical writer.\\n\\nYour task is to create a short, easily digestible section of a report based on a set of source documents.\\n\\n1. Analyze the content of the source documents:\\n- The name of each source document is at the start of the document, with the <Document tag.\\n\\n2. Create a report structure using markdown formatting:\\n- Use ## for the section title\\n- Use ### for sub-section headers\\n\\n3. Write the report following this structure:\\na. Title (## header)\\nb. Summary (### header)\\nc. Sources (### header)\\n\\n4. Make your title engaging based upon the focus area of the analyst:\\n{focus}\\n\\n5. For the summary section:\\n- Set up summary with general background / context related to the focus area of the analyst\\n- Emphasize what is novel, interesting, or surprising about insights gathered from the interview\\n- Create a numbered list of source documents, as you use them\\n- Do not mention the names of interviewers or experts\\n- Aim for approximately 400 words maximum\\n- Use numbered sources in your report (e.g., [1], [2]) based on information from source documents\\n\\n6. In the Sources section:\\n- Include all sources used in your report\\n- Provide full links to relevant websites or specific document paths\\n- Separate each source by a newline. Use two spaces at the end of each line to create a newline in Markdown.\\n- It will look like:\\n\\n### Sources\\n[1] Link or Document name\\n[2] Link or Document name\\n\\n7. Be sure to combine sources. For example this is not correct:\\n\\n[3] https://ai.meta.com/blog/meta-llama-3-1/\\n[4] https://ai.meta.com/blog/meta-llama-3-1/\\n\\nThere should be no redundant sources. It should simply be:\\n\\n[3] https://ai.meta.com/blog/meta-llama-3-1/\\n\\n8. Final review:\\n- Ensure the report follows the required structure\\n- Include no preamble before the title of the report\\n- Check that all guidelines have been followed\\\"\\\"\\\"\\n\\ndef write_section_bot(state: InterviewState):\\n    \\\"\\\"\\\"Enhanced section writing with proper structure persistence\\\"\\\"\\\"\\n    interview = state[\\\"interview\\\"]\\n    context = state[\\\"context\\\"]\\n    analyst = state[\\\"analyst\\\"]\\n    \\n    section = llm.invoke([\\n        SystemMessage(content=section_writer_instructions),\\n        HumanMessage(content=f\\\"Write a section based on: {context}\\\")\\n    ])\\n    \\n    bot = get_bot()\\n    if bot:\\n        try:\\n            # Create main content section if doesn't exist\\n            main_sections = bot.get_all_sections()\\n            main_content_id = next(\\n                (s.section_id for s in main_sections if s.title == \\\"Main Content\\\"), \\n                None\\n            )\\n            \\n            if not main_content_id:\\n                main_content_id = bot.create_and_add_section_then_return_id(\\n                    title=\\\"Main Content\\\",\\n                    content=\\\"\\\",\\n                    section_id=1  # Ensure it's first\\n                )\\n\\n            # Add analyst's section as child\\n            section_id = bot.create_and_add_section_then_return_id(\\n                title=f\\\"Analysis by {analyst.name}\\\",\\n                content=section.content,\\n                parent_id=main_content_id\\n            )\\n            \\n            # Store metadata about the section\\n            bot.add_or_update_result_in_resources(\\n                metadatas={\\n                    \\\"section_id\\\": section_id,\\n                    \\\"analyst\\\": analyst.name,\\n                    \\\"analyst_role\\\": analyst.role,\\n                    \\\"timestamp\\\": str(datetime.now())\\n                },\\n                name=f\\\"Section_{section_id}_Metadata\\\",\\n                content={\\\"section_type\\\": \\\"analysis\\\", \\\"parent_section\\\": main_content_id}\\n            )\\n            \\n        except Exception as e:\\n            print(f\\\"Error persisting section: {e}\\\")\\n            \\n    return {\\\"sections\\\": [section.content]}\\n\\n\\nclass ResearchGraphState(TypedDict):\\n    topic: str # Research topic\\n    max_analysts: int # Number of analysts\\n    human_analyst_feedback: str # Human feedback\\n    analysts: List[Analyst] # Analyst asking questions\\n    sections: Annotated[list, operator.add] # Send() API key\\n    introduction: str # Introduction for the final report\\n    content: str # Content for the final report\\n    conclusion: str # Conclusion for the final report\\n    final_report: str # Final report\\n\\ndef initiate_all_interviews(state: ResearchGraphState):\\n    \\\"\\\"\\\" This is the \\\"map\\\" step where we run each interview sub-graph using Send API \\\"\\\"\\\"\\n\\n    # Check if human feedback\\n    human_analyst_feedback=state.get('human_analyst_feedback')\\n    if human_analyst_feedback:\\n        # Return to create_analysts\\n        return \\\"create_analysts\\\"\\n\\n    # Otherwise kick off interviews in parallel via Send() API\\n    else:\\n        topic = state[\\\"topic\\\"]\\n        # return [Send(\\\"conduct_interview\\\", {\\\"analyst\\\": analyst,\\n        #                                    \\\"messages\\\": [HumanMessage(\\n        #                                        content=f\\\"So you said you were writing an article on {topic}?\\\"\\n        #                                    )\\n        #                                                ]}) for analyst in state[\\\"analysts\\\"]]\\n        return [Send(\\\"conduct_interview\\\", {\\n                    \\\"analyst\\\": analyst, \\\"messages\\\": [ HumanMessage( content=f\\\"So you said you were writing an article on {topic}?\\\")],\\n                    \\\"max_num_turns\\\": 2,  # Add explicit max_num_turns\\n                    \\\"context\\\": [],  # Add empty context\\n                    \\\"sections\\\": [],  # Add empty sections\\n                    \\\"interview\\\": \\\"\\\"  # Add empty interview\\n                }\\n            ) for analyst in state[\\\"analysts\\\"]\\n        ]\\nreport_writer_instructions = \\\"\\\"\\\"You are a technical writer creating a report on this overall topic:\\n\\n{topic}\\n\\nYou have a team of analysts. Each analyst has done two things:\\n\\n1. They conducted an interview with an expert on a specific sub-topic.\\n2. They write up their finding into a memo.\\n\\nYour task:\\n\\n1. You will be given a collection of memos from your analysts.\\n2. Think carefully about the insights from each memo.\\n3. Consolidate these into a crisp overall summary that ties together the central ideas from all of the memos.\\n4. Summarize the central points in each memo into a cohesive single narrative.\\n\\nTo format your report:\\n\\n1. Use markdown formatting.\\n2. Include no pre-amble for the report.\\n3. Use no sub-heading.\\n4. Start your report with a single title header: ## Insights\\n5. Do not mention any analyst names in your report.\\n6. Preserve any citations in the memos, which will be annotated in brackets, for example [1] or [2].\\n7. Create a final, consolidated list of sources and add to a Sources section with the `## Sources` header.\\n8. List your sources in order and do not repeat.\\n\\n[1] Source 1\\n[2] Source 2\\n\\nHere are the memos from your analysts to build your report from:\\n\\n{context}\\\"\\\"\\\"\\n\\ndef write_report_bot(state: ResearchGraphState):\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n    system_message = report_writer_instructions.format(topic=topic, context=formatted_str_sections)\\n    report = llm.invoke([SystemMessage(content=system_message)]+[HumanMessage(content=f\\\"Write a report based upon these memos.\\\")])\\n    return {\\\"content\\\": report.content}\\n\\nintro_conclusion_instructions = \\\"\\\"\\\"You are a technical writer finishing a report on {topic}\\n\\nYou will be given all of the sections of the report.\\n\\nYou job is to write a crisp and compelling introduction or conclusion section.\\n\\nThe user will instruct you whether to write the introduction or conclusion.\\n\\nInclude no pre-amble for either section.\\n\\nTarget around 100 words, crisply previewing (for introduction) or recapping (for conclusion) all of the sections of the report.\\n\\nUse markdown formatting.\\n\\nFor your introduction, create a compelling title and use the # header for the title.\\n\\nFor your introduction, use ## Introduction as the section header.\\n\\nFor your conclusion, use ## Conclusion as the section header.\\n\\nHere are the sections to reflect on for writing: {formatted_str_sections}\\\"\\\"\\\"\\n\\ndef write_introduction_bot(state: ResearchGraphState):\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    intro = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report introduction\\\")])\\n    return {\\\"introduction\\\": intro.content}\\n\\ndef write_conclusion_bot(state: ResearchGraphState):\\n    # Full set of sections\\n    sections = state[\\\"sections\\\"]\\n    topic = state[\\\"topic\\\"]\\n\\n    # Concat all sections together\\n    formatted_str_sections = \\\"\\\\n\\\\n\\\".join([f\\\"{section}\\\" for section in sections])\\n\\n    # Summarize the sections into a final report\\n\\n    instructions = intro_conclusion_instructions.format(topic=topic, formatted_str_sections=formatted_str_sections)\\n    conclusion = llm.invoke([instructions]+[HumanMessage(content=f\\\"Write the report conclusion\\\")])\\n    return {\\\"conclusion\\\": conclusion.content}\\n\\ndef finalize_report_bot(state: ResearchGraphState):\\n    \\\"\\\"\\\"Enhanced report finalization with proper structure\\\"\\\"\\\"\\n    content = state[\\\"content\\\"]\\n    introduction = state[\\\"introduction\\\"]\\n    conclusion = state[\\\"conclusion\\\"]\\n    \\n    bot = get_bot()\\n    if bot:\\n        try:\\n            # Organize sections in proper order\\n            intro_id = bot.create_and_add_section_then_return_id(\\n                title=\\\"Introduction\\\",\\n                content=introduction,\\n                section_id=1\\n            )\\n            \\n            content_id = bot.create_and_add_section_then_return_id(\\n                title=\\\"Main Findings\\\",\\n                content=content,\\n                section_id=2\\n            )\\n            \\n            conclusion_id = bot.create_and_add_section_then_return_id(\\n                title=\\\"Conclusion\\\",\\n                content=conclusion,\\n                section_id=3\\n            )\\n            \\n            # Add metadata about report structure\\n            bot.add_or_update_result_in_resources(\\n                metadatas={\\n                    \\\"report_structure\\\": {\\n                        \\\"introduction_id\\\": intro_id,\\n                        \\\"content_id\\\": content_id,\\n                        \\\"conclusion_id\\\": conclusion_id\\n                    },\\n                    \\\"generation_timestamp\\\": str(datetime.now())\\n                },\\n                name=\\\"Final_Report_Structure\\\"\\n            )\\n            \\n            # Combine for final report\\n            final_report = f\\\"{introduction}\\\\n\\\\n---\\\\n\\\\n{content}\\\\n\\\\n---\\\\n\\\\n{conclusion}\\\"\\n            \\n            # Store final assembled version\\n            bot.create_and_add_section_then_return_id(\\n                title=\\\"Complete Report\\\",\\n                content=final_report,\\n                section_id=4\\n            )\\n            \\n        except Exception as e:\\n            print(f\\\"Error finalizing report: {e}\\\")\\n            final_report = f\\\"{introduction}\\\\n\\\\n---\\\\n\\\\n{content}\\\\n\\\\n---\\\\n\\\\n{conclusion}\\\"\\n            \\n    return {\\\"final_report\\\": final_report}\\n\\ndef multi_agent_research_generation_persist_each_agent(bot, max_analysts: int = 3):\\n    \\\"\\\"\\\"\\n    Generate a full research report using a multi-agent LangGraph workflow:  \\n    Create a list of analysts, Conduct interviews, Write sections (no plan yet and sections except introduction and conclusion are merged into one section), \\n    Write report, Write introduction, Write conclusion, Finalize report.\\n    Persist the document in the bot object through agent action.\\n    \\n    Args:\\n        bot: The bot object with the necessary methods.\\n        max_analysts (int): OPTIONAL (default: 3) - The number of analysts to generate.\\n    Returns:\\n        str: The final markdown research report.\\n    \\\"\\\"\\\"\\n    title, topic = bot.document.title, bot.document.context\\n\\n    global get_bot\\n    get_bot = lambda: bot\\n\\n    # Create initial state with topic and max_analysts\\n    #initial_state: GenerateAnalystsState = { \\\"topic\\\": topic, \\\"max_analysts\\\": max_analysts, \\\"human_analyst_feedback\\\": None, \\\"analysts\\\": [], \\\"sections\\\": [],  \\\"messages\\\": [], \\\"context\\\": [] }\\n    initial_state: GenerateAnalystsState = { \\\"topic\\\": topic, \\\"max_analysts\\\": max_analysts, \\\"human_analyst_feedback\\\": None, \\\"analysts\\\": []}\\n    # Recreate the interview graph within the function\\n    interview_builder = StateGraph(InterviewState)\\n    interview_builder.add_node(\\\"ask_question\\\", generate_question_bot)\\n    interview_builder.add_node(\\\"search_web\\\", search_web_bot)\\n    interview_builder.add_node(\\\"search_wikipedia\\\", search_wikipedia_bot)\\n    interview_builder.add_node(\\\"answer_question\\\", generate_answer_bot)\\n    interview_builder.add_node(\\\"save_interview\\\", save_interview_bot)\\n    interview_builder.add_node(\\\"write_section\\\", write_section_bot)\\n\\n    # Flow\\n    interview_builder.add_edge(START, \\\"ask_question\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_web\\\")\\n    interview_builder.add_edge(\\\"ask_question\\\", \\\"search_wikipedia\\\")\\n    interview_builder.add_edge(\\\"search_web\\\", \\\"answer_question\\\")\\n    interview_builder.add_edge(\\\"search_wikipedia\\\", \\\"answer_question\\\")\\n    interview_builder.add_conditional_edges(\\\"answer_question\\\", route_messages,['ask_question','save_interview'])\\n    interview_builder.add_edge(\\\"save_interview\\\", \\\"write_section\\\")\\n    interview_builder.add_edge(\\\"write_section\\\", END)\\n\\n    # Compile interview graph\\n    memory = MemorySaver()\\n    interview_graph = interview_builder.compile(checkpointer=memory).with_config(run_name=\\\"Conduct Interviews\\\")\\n\\n    # Set up the thread configuration\\n    thread = {\\\"configurable\\\": {\\\"thread_id\\\": \\\"1\\\"}}\\n\\n    # Compile the research graph\\n    builder = StateGraph(ResearchGraphState)\\n    builder.add_node(\\\"create_analysts\\\", create_analysts_bot)\\n    builder.add_node(\\\"human_feedback\\\", human_feedback_bot)\\n    \\n    # Use the interview_graph directly, without .compile()\\n    builder.add_node(\\\"conduct_interview\\\", interview_graph)\\n    builder.add_node(\\\"write_report\\\", write_report_bot)\\n    builder.add_node(\\\"write_introduction\\\", write_introduction_bot)\\n    builder.add_node(\\\"write_conclusion\\\", write_conclusion_bot)\\n    builder.add_node(\\\"finalize_report\\\", finalize_report_bot)\\n\\n    # Logic\\n    builder.add_edge(START, \\\"create_analysts\\\")\\n    builder.add_edge(\\\"create_analysts\\\", \\\"human_feedback\\\")\\n    builder.add_conditional_edges(\\\"human_feedback\\\", initiate_all_interviews, [\\\"create_analysts\\\", \\\"conduct_interview\\\"])\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_introduction\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_report\\\")\\n    builder.add_edge(\\\"conduct_interview\\\", \\\"write_conclusion\\\")\\n    builder.add_edge([\\\"write_conclusion\\\", \\\"write_report\\\", \\\"write_introduction\\\"], \\\"finalize_report\\\")\\n    builder.add_edge(\\\"finalize_report\\\", END)\\n\\n    # Compile the graph\\n    memory2 = MemorySaver()\\n    graph = builder.compile(checkpointer=memory2)\\n    #display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\\n\\n    # Invoke the graph\\n    try:\\n        result = graph.invoke(initial_state, thread)\\n        final_state = graph.get_state(thread)\\n        report = final_state.values.get('final_report', '')\\n    except Exception as e:\\n        print(f\\\"Error in graph execution: {e}\\\")\\n        print(f\\\"Current state: {graph.get_state(thread)}\\\")\\n        raise\\n\\n    return report\\n\\nif __name__ == \\\"__main__\\\":\\n    from dataclasses import dataclass\\n    from typing import List, Dict, Any, Optional\\n    from datetime import datetime\\n\\n    @dataclass\\n    class Section:\\n        section_id: int\\n        title: str\\n        content: str\\n        parent_id: Optional[int] = None\\n\\n    @dataclass\\n    class Document:\\n        title: str\\n        context: str\\n\\n    class MockBot:\\n        def __init__(self, title: str, context: str):\\n            self.document = Document(title=title, context=context)\\n            self.sections: List[Section] = []\\n            self.resources: List[Dict] = []\\n            self.next_section_id = 1\\n            self.next_resource_id = 1\\n            print(f\\\"MockBot initialized with title: {title} and context: {context}\\\")\\n\\n        def create_and_add_section_then_return_id(self, title: str, content: str, section_id: int = None, parent_id: int = None) -> int:\\n            if section_id is None:\\n                section_id = self.next_section_id\\n                self.next_section_id += 1\\n            \\n            section = Section(section_id=section_id, title=title, content=content, parent_id=parent_id)\\n            self.sections.append(section)\\n            print(f\\\"Created section {section_id}: {title} (parent: {parent_id})\\\")\\n            return section_id\\n\\n        def get_all_sections(self) -> List[Section]:\\n            return self.sections\\n\\n        def get_sections(self, ids: List[int]) -> List[Section]:\\n            return [s for s in self.sections if s.section_id in ids]\\n\\n        def edit_section(self, section_id: int, new_content: str = None, new_title: str = None, new_parent_id: int = None) -> bool:\\n            for section in self.sections:\\n                if section.section_id == section_id:\\n                    if new_content is not None:\\n                        section.content = new_content\\n                    if new_title is not None:\\n                        section.title = new_title\\n                    if new_parent_id is not None:\\n                        section.parent_id = new_parent_id\\n                    print(f\\\"Edited section {section_id}\\\")\\n                    return True\\n            return False\\n\\n        def add_or_update_results_in_resources(self, results: List[Dict], metadatas_to_add: dict = None, store_linked_document_content: bool = False):\\n            for result in results:\\n                resource_id = self.next_resource_id\\n                self.next_resource_id += 1\\n                \\n                resource = {\\n                    'id': resource_id,\\n                    'document': {\\n                        'name': result.get('name', ''),\\n                        'link': result.get('link', ''),\\n                        'content': result.get('content', {})\\n                    },\\n                    'metadatas': metadatas_to_add or {}\\n                }\\n                \\n                self.resources.append(resource)\\n                print(f\\\"Added resource {resource_id}: {result.get('name', '')}\\\")\\n            return self\\n\\n        def add_or_update_result_in_resources(self, metadatas: dict, name: str = None, content: dict = None, link: str = None, store_linked_document_content: bool = False):\\n            resource_id = self.next_resource_id\\n            self.next_resource_id += 1\\n            \\n            resource = {\\n                'id': resource_id,\\n                'document': {\\n                    'name': name,\\n                    'link': link,\\n                    'content': content or {}\\n                },\\n                'metadatas': metadatas\\n            }\\n            \\n            self.resources.append(resource)\\n            print(f\\\"Added single resource {resource_id}: {name}\\\")\\n            return self\\n\\n        def get_all_resources(self) -> List[Dict[str, Any]]:\\n            return self.resources\\n\\n        def semantic_search_resources(self, query_texts, n_results=10):\\n            print(f\\\"Mock semantic search for: {query_texts}\\\")\\n            return []  # Mock empty results\\n\\n        def remove_resource(self, resource_id):\\n            self.resources = [r for r in self.resources if r['id'] != resource_id]\\n            print(f\\\"Removed resource {resource_id}\\\")\\n            return self\\n\\n    # Test usage example:\\n    def test_mock_bot():\\n        # Initialize mock bot\\n        mock_bot = MockBot(\\n            title=\\\"Test Research\\\",\\n            context=\\\"Testing the research assistant framework\\\"\\n        )\\n        \\n        # Test section creation\\n        section_id = mock_bot.create_and_add_section_then_return_id(\\n            title=\\\"Introduction\\\",\\n            content=\\\"This is a test introduction\\\"\\n        )\\n        \\n        # Test resource addition\\n        mock_bot.add_or_update_results_in_resources([\\n            {\\n                \\\"name\\\": \\\"Test Resource\\\",\\n                \\\"link\\\": \\\"https://test.com\\\",\\n                \\\"content\\\": {\\\"description\\\": \\\"Test content\\\"}\\n            }\\n        ], metadatas_to_add={\\\"source\\\": \\\"test\\\"})\\n        \\n        # Print current state\\n        print(\\\"\\\\nCurrent sections:\\\")\\n        for section in mock_bot.get_all_sections():\\n            print(f\\\"Section {section.section_id}: {section.title}\\\")\\n        \\n        print(\\\"\\\\nCurrent resources:\\\")\\n        for resource in mock_bot.get_all_resources():\\n            print(f\\\"Resource {resource['id']}: {resource['document']['name']}\\\")\\n\\n        return mock_bot\\n\\n    mock_bot = MockBot(\\n        title=\\\"Test Research @ Toulon M2 Master\\\",\\n        context=\\\"Testing the research assistant framework in Toulon M2 Master\\\"\\n    )\\n\\n    # Run with explicit error handling\\n    if True: # try:\\n        result = multi_agent_research_generation_persist_each_agent(mock_bot, max_analysts=2)\\n        \\n        print(\\\"\\\\nFinal Results:\\\")\\n        print(\\\"Sections:\\\", len(mock_bot.get_all_sections()))\\n        print(\\\"Resources:\\\", len(mock_bot.get_all_resources()))\\n        \\n        if result:\\n            print(\\\"\\\\nReport preview:\\\", result[:200] + \\\"...\\\" if result else \\\"No report\\\")\\n            \\n    # except Exception as e:\\n    #     print(f\\\"Error running research generation: {e}\\\")\\n    #     print(\\\"\\\\nFinal bot state:\\\")\\n    #     print(\\\"Sections:\\\", mock_bot.get_all_sections())\\n    #     print(\\\"Resources:\\\", mock_bot.get_all_resources())]]]\\nPREVIOUSLY SUCCESSFUL TASKS: [[[]]]\\nPREVIOUSLY FAILED TASKS: [[[]]]\\nPREVIOUS VALIDATION RESULTS: [[[]]]\\nPREVIOUS ATTEMPTS TO CODE THE TASK: [[[]]]\\nPREVIOUS ERRORS AND FIXES: [[[]]]\\n\\n***** CodingAgent->code_task_and_run_test BEFORE *****[0m\\nWARNING!!!! Max tokens exceeded, you should refactor user message or system prompt!\\n[A] Modify agent's system prompt\\n[B] Give instruction or information to agent\\n[C] Skip & set agent output (from recent or manually)\\n[D] Log comments (not used by the model, just for information)\\n[E] See previous results\\n[F] See MODIFIED/SCORED/COMMENTED results\\n[G] Skip for N rounds (auto mode)\\n[H] Change default agent\\n[I] Change premium agent\\n[J] Set num of parallel inferences (1, Synthesis=OFF)\\n[K] Exit\\n[P] Generate with a PREMIUM agent (default:False)\\n[R] Activate/Deactivate inferences checks\\n[Z] Continue\\n\", \"agent_name\": \"CodingAgent\", \"message_type\": \"BEFORE inference action MENU\", \"append\": false, \"column_id\": null, \"column_max\": null, \"optional\": false, \"step_id\": 0}\n",
            "2025-01-26 14:26:58 - {\"message\": \"\\u001b[32mBEFORE\\u001b[0m inference @ CodingAgent-> Choose an action (or hit Enter for inference) :\", \"agent_name\": \"CodingAgent\", \"message_type\": null, \"column_id\": null, \"column_max\": null, \"input\": true, \"optional\": false, \"step_id\": 0}\n",
            "SMART INPUT Waiting for response from WebSocket\n",
            "Executing function 'get_tasks' for monitor 'CodingAgent' with params: {'id_last_task': 'None'}\n",
            "Executing function 'get_tasks' for monitor 'CodingAgent' with params: {'id_last_task': 'None'}\n",
            "Executing function 'get_tasks' for monitor 'CodingAgent' with params: {'id_last_task': 'None'}\n",
            "Executing function 'get_tasks' for monitor 'CodingAgent' with params: {'id_last_task': 'None'}\n",
            "Executing function 'get_tasks' for monitor 'CodingAgent' with params: {'id_last_task': 'None'}\n",
            "Executing function 'goto_task' for monitor 'CodingAgent' with params: ['3cc929fd-df04-4c61-836e-20c856cbd25e', 'None', {'TaskIdentificationAgent#auto_n_rounds': 0, 'TaskIdentificationAgent#default_llm_choice': 'default_llm', 'TaskIdentificationAgent#recommend_critics': False, 'TaskIdentificationAgent#max_autofix': 0, 'TaskIdentificationAgent#num_parallel_inferences': 1, 'TaskIdentificationAgent#temperature_max': 0.5, 'TaskIdentificationAgent#replace_if_exists_function': False, 'CodingAgent#auto_n_rounds': 0, 'CodingAgent#default_llm_choice': 'default_llm', 'CodingAgent#recommend_critics': False, 'CodingAgent#max_autofix': 0, 'CodingAgent#num_parallel_inferences': 2, 'CodingAgent#temperature_max': 0.5, 'CodingAgent#replace_if_exists_function': False, 'ValidationAgent#auto_n_rounds': 0, 'ValidationAgent#default_llm_choice': 'default_llm', 'ValidationAgent#recommend_critics': False, 'ValidationAgent#max_autofix': 0, 'ValidationAgent#num_parallel_inferences': 0, 'ValidationAgent#temperature_max': 0.5, 'ValidationAgent#replace_if_exists_function': False, 'CapitalizationAgent#auto_n_rounds': 0, 'CapitalizationAgent#default_llm_choice': 'default_llm', 'CapitalizationAgent#recommend_critics': False, 'CapitalizationAgent#max_autofix': 0, 'CapitalizationAgent#num_parallel_inferences': 0, 'CapitalizationAgent#temperature_max': 0.5, 'CapitalizationAgent#replace_if_exists_function': False}, 'Adrien']\n",
            "Discord message: **XP ID:** XP_2025_01_15v1\n",
            "**User ID:** 892DF7AA-1047-47EB-B871-D71BDC4B05B3\n",
            "**Task Link:** https://doxav.github.io/CollabFunctionsGPTCreator/IHMv5-Monaco.html?wsUrl=https://tasty-dryers-wink.loca.lt?secret=77ef8f8b-2b07-42ba-b415-8bc2\n",
            "**Task Details:** Adrien\n",
            "Message sent to Discord successfully.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CollabFunctionsGPTCreator/utils/llm_utils.py\", line 217, in smart_input\n",
            "    loop = asyncio.get_running_loop()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/CollabFunctionsGPTCreator/learn_graph.py\", line 691, in <module>\n",
            "    run_4agents_learning_loop_graph(default_llm_key=\"default_llm\", # ALTERNATIVES: run_4agents_learning_loop, run_planner, run_4agents_learning_loop\n",
            "  File \"/content/CollabFunctionsGPTCreator/learn_graph.py\", line 468, in run_4agents_learning_loop_graph\n",
            "    result = app.invoke(initial_state)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 1535, in invoke\n",
            "    for chunk in self.stream(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/__init__.py\", line 1273, in stream\n",
            "    for _ in runner.tick(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/runner.py\", line 56, in tick\n",
            "    run_with_retry(t, retry_policy)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/pregel/retry.py\", line 29, in run_with_retry\n",
            "    task.proc.invoke(task.input, config)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 410, in invoke\n",
            "    input = context.run(step.invoke, input, config, **kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/langgraph/utils/runnable.py\", line 184, in invoke\n",
            "    ret = context.run(self.func, input, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/CollabFunctionsGPTCreator/learn_graph.py\", line 377, in create_coding_agent\n",
            "    parsed_code, validation, scores = coding_and_validation_loop(\n",
            "                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/CollabFunctionsGPTCreator/learn.py\", line 1789, in coding_and_validation_loop\n",
            "    results = agent_coding.code_task_and_run_test(task_description)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/CollabFunctionsGPTCreator/learn.py\", line 704, in code_task_and_run_test\n",
            "    codes = self.human_llm_code_task.CallHumanLLM(**kwargs)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/CollabFunctionsGPTCreator/utils/llm_utils.py\", line 2945, in CallHumanLLM\n",
            "    llm_input_messages, input_comments, skip_inference, use_premium_llm, default_llm_function, premium_llm_function, function_calling = self._before_inference(\n",
            "                                                                                                                                        ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/CollabFunctionsGPTCreator/utils/llm_utils.py\", line 1739, in _before_inference\n",
            "    action = smart_input(\n",
            "             ^^^^^^^^^^^^\n",
            "  File \"/content/CollabFunctionsGPTCreator/utils/llm_utils.py\", line 223, in smart_input\n",
            "    return asyncio.run(receive_message())\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 190, in run\n",
            "    return runner.run(main)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 118, in run\n",
            "    return self._loop.run_until_complete(task)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 641, in run_until_complete\n",
            "    self.run_forever()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1898, in _run_once\n",
            "    event_list = self._selector.select(timeout)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/selectors.py\", line 468, in select\n",
            "    fd_event_list = self._selector.poll(timeout, max_ev)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/asyncio/runners.py\", line 157, in _on_sigint\n",
            "    raise KeyboardInterrupt()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!cd /content/CollabFunctionsGPTCreator && python learn_graph.py --proxy --secret"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdWibxphhQD4",
      "metadata": {
        "id": "fdWibxphhQD4"
      },
      "source": [
        "# BONUS:\n",
        "\n",
        "1.   Amélioration du TaskIdentifier dans user_message pour meilleure prise en compte de la reprise de fonction (utiliser ou s'inspirer de summarize_repo de CollabFunctionsGPTCreator/env/SWEBench/env.py)\n",
        "2.   Tout bug important dont la solution est partagée rapidement avec tous les autres étudiants et via une Pull Request acceptée\n",
        "\n",
        "# BONUS mais probablement non accessible à l'issue de ce TP:\n",
        "1.   Dev Enrichissement d'un agent avec model context protocol (MCP) pour des tools ou resources augmentant le score de performance\n",
        "2.   Dev Optimisation des agents par max 4 itérations par Trace/OptoPrime\n",
        "3.   Dev Inférences multiples dans HumanLLMMonitor: générer en séquence l'un par rapport à l'autre pour s'assurer de la diversité des solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1r0rZF1p0ijJ",
      "metadata": {
        "id": "1r0rZF1p0ijJ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}